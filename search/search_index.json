{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nevermined Documentation \u00b6 Nevermined is a data ecosystem solution that provides the capabilities of building bespoke networks where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. With the explosion of the data and AI market, entities have the necessity of organizing, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing & Data in situ Computation solutions allowing to unlock data for AI. Nevermined enables a \u201cData in situ Computation\u201d solution, meaning the data never moves, is the algorithm the one moving where the data is. It allows data owners or providers to define the conditions in which they allow others to make use of their data without giving direct access to it. Nevermined is designed to be integrated in Big Data environments. It enables monetizing the data without migration. It\u2019s also designed for GDPR compliance, it never stores any personal information on-chain (encrypted or in plain text). Nevermined is the product powered by Keyko . Data Ecosystem Principles \u00b6 During the design and construction of Nevermined, we identified 6 key factors for the adoption and usage of a data ecosystem and its continued growth: Culture - Culture & Organization help to establish how each ecosystem actor interact with others. We promote it giving a user centric approach User Experience (UX) - The ecosystems should provide an excellent User eXperience, facilitating the participation of all the partners and users Trust - Data ecosystems must promote trustful environments where untrusted parties can collaborate Integrity - Data integrity and provenance as first class citizens where the ecosystem users can validate that data doesn't change and from where is coming Compliance - Data first approach compliance with all the data regulatory requirements Incentives - We promote the usage and retention of data ecosystems via gamification and providing additional value Use Cases \u00b6 Nevermined is a platform agnostic solution enabling data use cases where different parties don't trust each other. It allows to provide data ecosystems where DATA OWNERS need to share and monetize their data with third-party people, but they want to keep the privacy and the control of their data. Typical use cases for sector are: Banking - Data Sharing with the regulator or internal across different jurisdictions Telco - Anonymized Data Sharing with the regulator and partners. AI within moving the data Health & Pharma - AI over medical results of different hospitals without revealing PI Supply Chain - Provenance, integrity and tracking of goods Automotive - Data Sharing for AI to promote the autonomous cars Others - Real estate, digital assets tokenization, ..","title":"Home"},{"location":"#nevermined-documentation","text":"Nevermined is a data ecosystem solution that provides the capabilities of building bespoke networks where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. With the explosion of the data and AI market, entities have the necessity of organizing, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing & Data in situ Computation solutions allowing to unlock data for AI. Nevermined enables a \u201cData in situ Computation\u201d solution, meaning the data never moves, is the algorithm the one moving where the data is. It allows data owners or providers to define the conditions in which they allow others to make use of their data without giving direct access to it. Nevermined is designed to be integrated in Big Data environments. It enables monetizing the data without migration. It\u2019s also designed for GDPR compliance, it never stores any personal information on-chain (encrypted or in plain text). Nevermined is the product powered by Keyko .","title":"Nevermined Documentation"},{"location":"#data-ecosystem-principles","text":"During the design and construction of Nevermined, we identified 6 key factors for the adoption and usage of a data ecosystem and its continued growth: Culture - Culture & Organization help to establish how each ecosystem actor interact with others. We promote it giving a user centric approach User Experience (UX) - The ecosystems should provide an excellent User eXperience, facilitating the participation of all the partners and users Trust - Data ecosystems must promote trustful environments where untrusted parties can collaborate Integrity - Data integrity and provenance as first class citizens where the ecosystem users can validate that data doesn't change and from where is coming Compliance - Data first approach compliance with all the data regulatory requirements Incentives - We promote the usage and retention of data ecosystems via gamification and providing additional value","title":"Data Ecosystem Principles"},{"location":"#use-cases","text":"Nevermined is a platform agnostic solution enabling data use cases where different parties don't trust each other. It allows to provide data ecosystems where DATA OWNERS need to share and monetize their data with third-party people, but they want to keep the privacy and the control of their data. Typical use cases for sector are: Banking - Data Sharing with the regulator or internal across different jurisdictions Telco - Anonymized Data Sharing with the regulator and partners. AI within moving the data Health & Pharma - AI over medical results of different hospitals without revealing PI Supply Chain - Provenance, integrity and tracking of goods Automotive - Data Sharing for AI to promote the autonomous cars Others - Real estate, digital assets tokenization, ..","title":"Use Cases"},{"location":"Blog/","text":"Nevermined Blog Posts \u00b6 We use Medium for publishing about Nevermined product and technology. You can find all this content in our Nevermined Medium space. If you want to know more about any topic, please drop us a line on Discord . We will be happy to chat about it. This is a list of the most relevant blog posts we published: Title Topic Author Introducing Nevermined Nevermined Announcement @clem Nevermined Tech: Nuts & Bolts Technical introduction @aitor_argomaniz Using Nevermined to Commercialize Your Organization\u2019s Data Use Case @don_gossen Provenance\u200a\u2014\u200aEverything has a story behind Technical @aitor_argomaniz What decentralized building blocks exist to build your digital ecosystem? Technical @aitor_argomaniz Nevermined & Credit Card Fraud Detection Use Case @rodmar Why use Nevermined? Use Case @aitor_argomaniz Why do we use blockchain? Technical @aitor_argomaniz Facilitating asset tokenization with NFTs Use Case @aitor_argomaniz","title":"Blog posts"},{"location":"Blog/#nevermined-blog-posts","text":"We use Medium for publishing about Nevermined product and technology. You can find all this content in our Nevermined Medium space. If you want to know more about any topic, please drop us a line on Discord . We will be happy to chat about it. This is a list of the most relevant blog posts we published: Title Topic Author Introducing Nevermined Nevermined Announcement @clem Nevermined Tech: Nuts & Bolts Technical introduction @aitor_argomaniz Using Nevermined to Commercialize Your Organization\u2019s Data Use Case @don_gossen Provenance\u200a\u2014\u200aEverything has a story behind Technical @aitor_argomaniz What decentralized building blocks exist to build your digital ecosystem? Technical @aitor_argomaniz Nevermined & Credit Card Fraud Detection Use Case @rodmar Why use Nevermined? Use Case @aitor_argomaniz Why do we use blockchain? Technical @aitor_argomaniz Facilitating asset tokenization with NFTs Use Case @aitor_argomaniz","title":"Nevermined Blog Posts"},{"location":"BuildingBlocks/","text":"Building Blocks \u00b6 Nevermined is based in three core building blocks: Data Sharing \u00b6 It enables the data sharing capabilities between unstructured parties. The main users involved in this scenario are: Organizations with data that need to share and monetize ( Data Owners ). Organizations or individuals looking for data sets to train their models ( Data Consumers ). Typically Data Owners & Consumers don't know or trust each other. Nevermined provides a generic solution where both can share data in a decentralized and secure way. The main benefits for them are: Data Owners can get some benefit of their existing data Data Consumers can get access to datasets they couldn't get access in other conditions Nevermined Data Sharing flow In this use case the CONSUMERS can get access to the datasets, so it's ideal for problems with low data privacy constraints. The main capabilities are: Allowing data monetization. Data owners can make available their data and get some rewards/benefits when others get access to it. Allows an easy data publishing or data access from the users. Provides a Decentralized Access Control where untrusted members can feel confident that other members of the system will play honestly Supports free or paid access scenarios All the interactions related with the assets or services (when are created in the system, who has access, when the access was granted, etc.) is tracked The decentralized access control can be used in public or private blockchain networks You can find more details about the technical implementation of the Data Sharing use case in the ACCESS SPEC . Data in situ Computation (DISC) \u00b6 It facilitates the use cases where data owners allow third parties to execute some algorithms where the data is. For the use cases with more privacy restrictions in which the Data Owner never wants to lose control of their data, and this source data can't be accessed directly, Nevermined provides a Data in situ Computation (DISC) solution. This scenario is based on the premise that data doesn't want to be moved. Moving data of their existing premises is a liability. The data can be leaked in transit and because the private nature of the data, moving it implies some regulatory issues. In that case, Nevermined provides a solution where the Data Owner allows the execution of an algorithm (tensorflow, spark, etc.) in the infrastructure where the data is. It means the Data Consumer provides the algorithm to execute, and this is moved to the Data Owner infrastructure where the data is being kept. The Data Consumer receives the result of the execution of the algorithm on top of the data. Data in situ Computation You can find more details about the technical implementation of the Data in situ Computation use case in the COMPUTE SPEC . The main capabilities of the Data in situ Computation building block are: Solution designed to support different computation or backend paradigms Implemented 2 different backends, one of them orchestrating Kubernetes containers in the Data Provider environment. Other via the integration of a Federated Learning framework Framework or programming language independent The data never moves, algorithm goes where data is Consumer never get access to the real data The algorithm is moved where the data is. An ephemeral environment is created to support the computation It supports the orchestration of computing pipelines All the access control and execution is controlled via the integration with the service agreements Can be run in cloud providers or on-premise Permits the monitoring of the workflows execution Compute backends \u00b6 Nevermined supports to plug different compute backends that could be more convenient depending on the use cases. The rest of the ecosystem keeps the same (services, api\u2019s, applications on top, etc.), but depending on how the use case is, Nevermined will orchestrate the compute jobs in different ways. At this point in time Nevermined integrates 2 different compute backends: Kubernetes backend \u00b6 This backend is perfect for compute jobs that can be executed in the data provider data center and don\u2019t have high privacy constraints. In this scenario the Client can implement the algorithm using different languages or frameworks, and the Nevermined Compute solution will be in charge of orchestrating the infrastructure for moving the algorithm where the data is. Kubernetes orchestration As you can see in the above diagram, the Compute API will be in charge of triggering the compute workflow interacting with the Kubernetes infrastructure via Argo . This includes: Download the algorithm provided by the Data Scientist/Engineer Starts the right Docker container in the infrastructure Mount as volume with the data Execute the algorithm passing as parameter the path where the data is mounted Stop the Compute pod where the algorithm is running Publishing the result as a new asset Destroy all the ephemeral environment Federated Learning backend \u00b6 This backend fits for the execution of federated learning jobs using the data of providers having federated environments. In this scenario the Client can implement the data training model using a generic federated learning framework, and the Nevermined Compute solution will be in charge of orchestrating the execution across all the participants. In this scenario the Compute backend starts two independent tasks, the coordinator and the aggregator. The coordinator will do all the management of the participants as part of a federated job. The aggregator will do the secure aggregation of the trained models. Both the coordinator and aggregator are ephemeral nodes created by demand, so after the job is executed they will be stopped till a new execution request is triggered. Federated Learning backend Data Marketplace and Cataloging \u00b6 It facilitates the search, discovery and management of the existing assets in the data ecosystem. The main capabilities are: Improved User Experience Integration with the Data Governance and Data Catalog tools Easy search and discovery Native integration with the data sharing and data in situ computation building blocks Internal data catalog and APIs Tokenization and incentives","title":"Building Blocks"},{"location":"BuildingBlocks/#building-blocks","text":"Nevermined is based in three core building blocks:","title":"Building Blocks"},{"location":"BuildingBlocks/#data-sharing","text":"It enables the data sharing capabilities between unstructured parties. The main users involved in this scenario are: Organizations with data that need to share and monetize ( Data Owners ). Organizations or individuals looking for data sets to train their models ( Data Consumers ). Typically Data Owners & Consumers don't know or trust each other. Nevermined provides a generic solution where both can share data in a decentralized and secure way. The main benefits for them are: Data Owners can get some benefit of their existing data Data Consumers can get access to datasets they couldn't get access in other conditions Nevermined Data Sharing flow In this use case the CONSUMERS can get access to the datasets, so it's ideal for problems with low data privacy constraints. The main capabilities are: Allowing data monetization. Data owners can make available their data and get some rewards/benefits when others get access to it. Allows an easy data publishing or data access from the users. Provides a Decentralized Access Control where untrusted members can feel confident that other members of the system will play honestly Supports free or paid access scenarios All the interactions related with the assets or services (when are created in the system, who has access, when the access was granted, etc.) is tracked The decentralized access control can be used in public or private blockchain networks You can find more details about the technical implementation of the Data Sharing use case in the ACCESS SPEC .","title":"Data Sharing"},{"location":"BuildingBlocks/#data-in-situ-computation-disc","text":"It facilitates the use cases where data owners allow third parties to execute some algorithms where the data is. For the use cases with more privacy restrictions in which the Data Owner never wants to lose control of their data, and this source data can't be accessed directly, Nevermined provides a Data in situ Computation (DISC) solution. This scenario is based on the premise that data doesn't want to be moved. Moving data of their existing premises is a liability. The data can be leaked in transit and because the private nature of the data, moving it implies some regulatory issues. In that case, Nevermined provides a solution where the Data Owner allows the execution of an algorithm (tensorflow, spark, etc.) in the infrastructure where the data is. It means the Data Consumer provides the algorithm to execute, and this is moved to the Data Owner infrastructure where the data is being kept. The Data Consumer receives the result of the execution of the algorithm on top of the data. Data in situ Computation You can find more details about the technical implementation of the Data in situ Computation use case in the COMPUTE SPEC . The main capabilities of the Data in situ Computation building block are: Solution designed to support different computation or backend paradigms Implemented 2 different backends, one of them orchestrating Kubernetes containers in the Data Provider environment. Other via the integration of a Federated Learning framework Framework or programming language independent The data never moves, algorithm goes where data is Consumer never get access to the real data The algorithm is moved where the data is. An ephemeral environment is created to support the computation It supports the orchestration of computing pipelines All the access control and execution is controlled via the integration with the service agreements Can be run in cloud providers or on-premise Permits the monitoring of the workflows execution","title":"Data in situ Computation (DISC)"},{"location":"BuildingBlocks/#compute-backends","text":"Nevermined supports to plug different compute backends that could be more convenient depending on the use cases. The rest of the ecosystem keeps the same (services, api\u2019s, applications on top, etc.), but depending on how the use case is, Nevermined will orchestrate the compute jobs in different ways. At this point in time Nevermined integrates 2 different compute backends:","title":"Compute backends"},{"location":"BuildingBlocks/#kubernetes-backend","text":"This backend is perfect for compute jobs that can be executed in the data provider data center and don\u2019t have high privacy constraints. In this scenario the Client can implement the algorithm using different languages or frameworks, and the Nevermined Compute solution will be in charge of orchestrating the infrastructure for moving the algorithm where the data is. Kubernetes orchestration As you can see in the above diagram, the Compute API will be in charge of triggering the compute workflow interacting with the Kubernetes infrastructure via Argo . This includes: Download the algorithm provided by the Data Scientist/Engineer Starts the right Docker container in the infrastructure Mount as volume with the data Execute the algorithm passing as parameter the path where the data is mounted Stop the Compute pod where the algorithm is running Publishing the result as a new asset Destroy all the ephemeral environment","title":"Kubernetes backend"},{"location":"BuildingBlocks/#federated-learning-backend","text":"This backend fits for the execution of federated learning jobs using the data of providers having federated environments. In this scenario the Client can implement the data training model using a generic federated learning framework, and the Nevermined Compute solution will be in charge of orchestrating the execution across all the participants. In this scenario the Compute backend starts two independent tasks, the coordinator and the aggregator. The coordinator will do all the management of the participants as part of a federated job. The aggregator will do the secure aggregation of the trained models. Both the coordinator and aggregator are ephemeral nodes created by demand, so after the job is executed they will be stopped till a new execution request is triggered. Federated Learning backend","title":"Federated Learning backend"},{"location":"BuildingBlocks/#data-marketplace-and-cataloging","text":"It facilitates the search, discovery and management of the existing assets in the data ecosystem. The main capabilities are: Improved User Experience Integration with the Data Governance and Data Catalog tools Easy search and discovery Native integration with the data sharing and data in situ computation building blocks Internal data catalog and APIs Tokenization and incentives","title":"Data Marketplace and Cataloging"},{"location":"Licensing/","text":"Software Licenses \u00b6 Nevermined is a solution that includes Open & Private source components. The core of the functionality is Open Source Software using the very open Apache v2 . In addition to that, we provide some additional management tools that can help to operate and monitor a Nevermined based Digital Ecosystem deployment. Nevermined is offered for free from a Source Code point of view. In addition we provide a subscription model where people can get access to additional documentation, support, binaries, docker images, advanced tools, etc. The artifacts provided in the subscription model package all the components and allow an easy deployment, orchestration, operation and monitoring of a complete data ecosystem platform providing enterprise level quality. Why a subcription model? \u00b6 Nevermined is adapted to enterprise requirements to facilitate the development, integration & deployment of complex data solutions. It automatically orchestrates, operates & monitors complete enterprise data ecosystems. Nevermined components are offered with a dual Open Source/Private License. The source code is provided under an Open Source Apache v2 License providing the foundations of your Data Ecosystem: Smart Contracts Metadata API Data Gateway SDK's and Libraries Documentation & Specifications Additionally, Keyko offers an Enterprise & Digital Ecosystem subscription-based License for users with extended capabilities on top of the Open Source components: Integrated Access Control Operational & Development tools Containerization of the whole platform Service Execution Agreements Ecosystem Monitoring Extended Knowledge base If you want to know more, please send us a message to info@nevermined.io","title":"Software Licenses"},{"location":"Licensing/#software-licenses","text":"Nevermined is a solution that includes Open & Private source components. The core of the functionality is Open Source Software using the very open Apache v2 . In addition to that, we provide some additional management tools that can help to operate and monitor a Nevermined based Digital Ecosystem deployment. Nevermined is offered for free from a Source Code point of view. In addition we provide a subscription model where people can get access to additional documentation, support, binaries, docker images, advanced tools, etc. The artifacts provided in the subscription model package all the components and allow an easy deployment, orchestration, operation and monitoring of a complete data ecosystem platform providing enterprise level quality.","title":"Software Licenses"},{"location":"Licensing/#why-a-subcription-model","text":"Nevermined is adapted to enterprise requirements to facilitate the development, integration & deployment of complex data solutions. It automatically orchestrates, operates & monitors complete enterprise data ecosystems. Nevermined components are offered with a dual Open Source/Private License. The source code is provided under an Open Source Apache v2 License providing the foundations of your Data Ecosystem: Smart Contracts Metadata API Data Gateway SDK's and Libraries Documentation & Specifications Additionally, Keyko offers an Enterprise & Digital Ecosystem subscription-based License for users with extended capabilities on top of the Open Source components: Integrated Access Control Operational & Development tools Containerization of the whole platform Service Execution Agreements Ecosystem Monitoring Extended Knowledge base If you want to know more, please send us a message to info@nevermined.io","title":"Why a subcription model?"},{"location":"Specs/","text":"Nevermined Specifications \u00b6 The core of the platform is documented in detail in Specification documents (aka SPECs ). Here you can find a list of the most relevant SPECs: Short Name Title Version Status Editor DID Decentralized Identifiers 0.1 Valid @aaitor META Metadata 0.1 Valid @aaitor ACCESS Decentralized Access Control 0.1 Valid @aaitor COMPUTE Decentralized Data in situ Computation 0.1 Valid @aaitor FL Federated Learning integration 0.1 Draft @r-marques PROV Decentralized Data Provenance 0.2 Valid @aaitor IDM Identity management with on-chain access control 0.1 Valid @aaitor NFT NFTs Engine 0.1 Draft @aaitor Attribution \u00b6 Some of the Specs are an evolution of Ocean Protocol Enhancement Proposals - OEPs .","title":"Overview"},{"location":"Specs/#nevermined-specifications","text":"The core of the platform is documented in detail in Specification documents (aka SPECs ). Here you can find a list of the most relevant SPECs: Short Name Title Version Status Editor DID Decentralized Identifiers 0.1 Valid @aaitor META Metadata 0.1 Valid @aaitor ACCESS Decentralized Access Control 0.1 Valid @aaitor COMPUTE Decentralized Data in situ Computation 0.1 Valid @aaitor FL Federated Learning integration 0.1 Draft @r-marques PROV Decentralized Data Provenance 0.2 Valid @aaitor IDM Identity management with on-chain access control 0.1 Valid @aaitor NFT NFTs Engine 0.1 Draft @aaitor","title":"Nevermined Specifications"},{"location":"Specs/#attribution","text":"Some of the Specs are an evolution of Ocean Protocol Enhancement Proposals - OEPs .","title":"Attribution"},{"location":"api/","text":"Nevermined APIs \u00b6 Nevermined offers different capabilities built on top of some technical components . Each of team play a different role and allow their integration in different ways. Software Development Kits (SDK's) \u00b6 The main entry point for using Nevermined are the Software Development Kits (SDKs). SDK's are the software libraries encapsulating the Nevermined business logic. They are used to interact with all the components & APIs of the system. Nevermined provides 3 different Open Source implementation of SDK's allowing the integration and implementation of complex use cases on top of the Nevermined Data Ecosystems. Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. All the three implementations are very similar from a design and interface point of view. It means that beyond the language differences, the concepts and the way the API is exposed from a user point of view is the same. If you want to know more, you can explore the Nevermined Reference API and it's implementation in the SDKs API documentation . Metadata API \u00b6 The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . The Metadata API is wrapped by the SDKs, so you don't need to integrate directly this API. Gateway \u00b6 The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway API is wrapped by the SDKs, so you don't need to integrate directly this API.","title":"Overview"},{"location":"api/#nevermined-apis","text":"Nevermined offers different capabilities built on top of some technical components . Each of team play a different role and allow their integration in different ways.","title":"Nevermined APIs"},{"location":"api/#software-development-kits-sdks","text":"The main entry point for using Nevermined are the Software Development Kits (SDKs). SDK's are the software libraries encapsulating the Nevermined business logic. They are used to interact with all the components & APIs of the system. Nevermined provides 3 different Open Source implementation of SDK's allowing the integration and implementation of complex use cases on top of the Nevermined Data Ecosystems. Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. All the three implementations are very similar from a design and interface point of view. It means that beyond the language differences, the concepts and the way the API is exposed from a user point of view is the same. If you want to know more, you can explore the Nevermined Reference API and it's implementation in the SDKs API documentation .","title":"Software Development Kits (SDK's)"},{"location":"api/#metadata-api","text":"The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . The Metadata API is wrapped by the SDKs, so you don't need to integrate directly this API.","title":"Metadata API"},{"location":"api/#gateway","text":"The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway API is wrapped by the SDKs, so you don't need to integrate directly this API.","title":"Gateway"},{"location":"api/SDK/","text":"Software Development Kits (SDKs) \u00b6 The SDKs, independently of their programming language, allow the interaction with the multiple Nevermined components. The SDKs integrate: The Nevermined Smart Contracts, where is kept all the assets registry, token, service execution agreements, etc. The Metadata API, where is kept the metadata associated to assets (title, description, tags, etc). The Gateway, that is the component that make data and computation available via the integration with data repositories and compute apis The Faucet, an optional component that allow users to request Ether for paying on-chain transactions The Secret Store, an optional component existing in some Nevermined deploments, it allows multi-party encryption and decryption of secrets Language Implementations \u00b6 There are different language implementations of the SDKs: Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. SDK Documentation \u00b6 Nevermined SDK JS Documentation - Javascript documentation is included as part of the project repository. Nevermined SDK PY Documentation - Python documentation is included as part of the project repository. Nevermined SDK JAVA Documentation - The Java documentation is generated automatically using javadoc . All the documentation can be found in javadoc.io . API Reference \u00b6 All the SDKs implement the same Nevermined reference API. This can be found in the Nevermined Reference API Document . Modules \u00b6 The SDK implement different the following modules: Module Topic Assets Managing of data assets on Nevermined networks Accounts Managing accounts Agreements Interacting with Service Execution Agreements (aka SEAs) Conditions Interacting with agreement conditions Provenance Tracking & retrieving data provenance Tokens Request and transfer Nevermined tokens Providers Manage of asset providers Secret Store Encryption and Decryption secrets","title":"Software Development Kits (SDKs)"},{"location":"api/SDK/#software-development-kits-sdks","text":"The SDKs, independently of their programming language, allow the interaction with the multiple Nevermined components. The SDKs integrate: The Nevermined Smart Contracts, where is kept all the assets registry, token, service execution agreements, etc. The Metadata API, where is kept the metadata associated to assets (title, description, tags, etc). The Gateway, that is the component that make data and computation available via the integration with data repositories and compute apis The Faucet, an optional component that allow users to request Ether for paying on-chain transactions The Secret Store, an optional component existing in some Nevermined deploments, it allows multi-party encryption and decryption of secrets","title":"Software Development Kits (SDKs)"},{"location":"api/SDK/#language-implementations","text":"There are different language implementations of the SDKs: Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers.","title":"Language Implementations"},{"location":"api/SDK/#sdk-documentation","text":"Nevermined SDK JS Documentation - Javascript documentation is included as part of the project repository. Nevermined SDK PY Documentation - Python documentation is included as part of the project repository. Nevermined SDK JAVA Documentation - The Java documentation is generated automatically using javadoc . All the documentation can be found in javadoc.io .","title":"SDK Documentation"},{"location":"api/SDK/#api-reference","text":"All the SDKs implement the same Nevermined reference API. This can be found in the Nevermined Reference API Document .","title":"API Reference"},{"location":"api/SDK/#modules","text":"The SDK implement different the following modules: Module Topic Assets Managing of data assets on Nevermined networks Accounts Managing accounts Agreements Interacting with Service Execution Agreements (aka SEAs) Conditions Interacting with agreement conditions Provenance Tracking & retrieving data provenance Tokens Request and transfer Nevermined tokens Providers Manage of asset providers Secret Store Encryption and Decryption secrets","title":"Modules"},{"location":"api/cli/","text":"Nevermined Command Line Interface (CLI) \u00b6 The Nevermined CLI tool enables to connect to the Nevermined Data Ecosystem and interact with it using the command line interface. It orchestrates all the components allowing to: Publish assets Get access to assets Search and discovery Running remote compute jobs Checking the state of Service Agreements Tracking provenance Manage NFTs and Nevermined tokens You can find all the CLI documentation and the commands available in the CLI docs website : https://nevermined-io.github.io/cli/","title":"Command Line Interface"},{"location":"api/cli/#nevermined-command-line-interface-cli","text":"The Nevermined CLI tool enables to connect to the Nevermined Data Ecosystem and interact with it using the command line interface. It orchestrates all the components allowing to: Publish assets Get access to assets Search and discovery Running remote compute jobs Checking the state of Service Agreements Tracking provenance Manage NFTs and Nevermined tokens You can find all the CLI documentation and the commands available in the CLI docs website : https://nevermined-io.github.io/cli/","title":"Nevermined Command Line Interface (CLI)"},{"location":"api/gateway/","text":"Nevermined Gateway \u00b6 The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway allows also the encryption and decryption of components using the following mechanisms: RSA ECDSA Parity Secret Store Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters. Gateway API Reference \u00b6 You can find a complete API reference documented in Swagger format in the docs folder of the metadata api repository.","title":"Gateway API"},{"location":"api/gateway/#nevermined-gateway","text":"The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway allows also the encryption and decryption of components using the following mechanisms: RSA ECDSA Parity Secret Store Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters.","title":"Nevermined Gateway"},{"location":"api/gateway/#gateway-api-reference","text":"You can find a complete API reference documented in Swagger format in the docs folder of the metadata api repository.","title":"Gateway API Reference"},{"location":"api/metadata/","text":"Nevermined Metadata API \u00b6 The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters. Metadata API Reference \u00b6 You can find a complete API reference documented in Swagger format in the docs folder of the metadata api repository.","title":"Metadata API"},{"location":"api/metadata/#nevermined-metadata-api","text":"The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters.","title":"Nevermined Metadata API"},{"location":"api/metadata/#metadata-api-reference","text":"You can find a complete API reference documented in Swagger format in the docs folder of the metadata api repository.","title":"Metadata API Reference"},{"location":"api/reference/Accounts/","text":"Nevermined Accounts API \u00b6 Exposes the Public API related with the management of Accounts Get account balance \u00b6 It returns the tokens balance of an account. Parameters: account Public address of the account Example: balance ( 0xaabb ) Get account balance \u00b6 It returns the accounts registered in a blockchain node. Example: list ()","title":"Accounts"},{"location":"api/reference/Accounts/#nevermined-accounts-api","text":"Exposes the Public API related with the management of Accounts","title":"Nevermined Accounts API"},{"location":"api/reference/Accounts/#get-account-balance","text":"It returns the tokens balance of an account. Parameters: account Public address of the account Example: balance ( 0xaabb )","title":"Get account balance"},{"location":"api/reference/Accounts/#get-account-balance_1","text":"It returns the accounts registered in a blockchain node. Example: list ()","title":"Get account balance"},{"location":"api/reference/Agreements/","text":"Agreements API Reference \u00b6 Nevermined Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") are contracts between parties interacting in a transaction. They provide the capacity of defining on-chain validation of conditions as a previous step of providing a service. The most classical scenarios in Nevermined are Service Agreements allowing Data Sharing or Remote Computation. The SEAs are used here to facilitate: A publisher defining a service that is offered and what a the conditions to obtaining that service A consumer or user that needs to fulfill the publisher conditions to getting access to that service You can find more information about the implementation of the SEAs in the access Spec and the compute Spec . Every execution by an user of a service agreement can be referenced by the agreementId . That is a unique identifier of the agreement execution and it is used across this api reference document. Create a Service Agreement \u00b6 Creates an on-chain Service Agreement instance. Parameters: did Identifier of the asset associated to the service agreement index The service index of the agreement in the DDO agreementId the unique identifier of the execution of an agreement signature the signature of the agreementId provided by the consumer of the agreement consumerAccount The Public address of the consumer account Example: create ( \"did:nv:1234\" , 0 , \"8181818\" , \"fdfdfdfd\" , 0xaabb ) Get the status of a Service Agreement \u00b6 Get the status of a service agreement instance. Parameters: agreementId the unique identifier of the execution of an agreement Example: status ( \"8181818\" ) Is a Service Agreement granted? \u00b6 Return if a service agreement is granted. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement consumerAccount The Public address of the consumer account Example: isAccessGranted ( \"8181818\" , \"did:nv:1234\" , 0xaabb )","title":"Agreements"},{"location":"api/reference/Agreements/#agreements-api-reference","text":"Nevermined Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") are contracts between parties interacting in a transaction. They provide the capacity of defining on-chain validation of conditions as a previous step of providing a service. The most classical scenarios in Nevermined are Service Agreements allowing Data Sharing or Remote Computation. The SEAs are used here to facilitate: A publisher defining a service that is offered and what a the conditions to obtaining that service A consumer or user that needs to fulfill the publisher conditions to getting access to that service You can find more information about the implementation of the SEAs in the access Spec and the compute Spec . Every execution by an user of a service agreement can be referenced by the agreementId . That is a unique identifier of the agreement execution and it is used across this api reference document.","title":"Agreements API Reference"},{"location":"api/reference/Agreements/#create-a-service-agreement","text":"Creates an on-chain Service Agreement instance. Parameters: did Identifier of the asset associated to the service agreement index The service index of the agreement in the DDO agreementId the unique identifier of the execution of an agreement signature the signature of the agreementId provided by the consumer of the agreement consumerAccount The Public address of the consumer account Example: create ( \"did:nv:1234\" , 0 , \"8181818\" , \"fdfdfdfd\" , 0xaabb )","title":"Create a Service Agreement"},{"location":"api/reference/Agreements/#get-the-status-of-a-service-agreement","text":"Get the status of a service agreement instance. Parameters: agreementId the unique identifier of the execution of an agreement Example: status ( \"8181818\" )","title":"Get the status of a Service Agreement"},{"location":"api/reference/Agreements/#is-a-service-agreement-granted","text":"Return if a service agreement is granted. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement consumerAccount The Public address of the consumer account Example: isAccessGranted ( \"8181818\" , \"did:nv:1234\" , 0xaabb )","title":"Is a Service Agreement granted?"},{"location":"api/reference/Assets/","text":"Nevermined Assets API \u00b6 Every entity object in Nevermined is encapsulated in an asset . Typically the abstract things like datasets, algorithms, services, workflows, etc. But technically can abstract any entity with services provided by an user to the rest network under some conditions. Any asset has 2 main components: A Decentralized Identifier or DID. A unique id that reference the asset. This is recorded on-chain when the asset is registered in a Nevermined network Metadata. A DID Document describing the asset and the services (access, compute, etc.) associated to that asset. This is recorded off-chain. An on-chain DID can be used to resolve the metadata associated to it. You can find more information about the implementation of the SEAs and the services associated to Nevermined assets in the access Spec and the compute Spec . Assets Management \u00b6 Create an asset \u00b6 It registers a new asset on Nevermined. It Creates a new DID, registering it on-chain through DIDRegistry contract and off-chain in Metadata. Parameters: metadata the metadata describing the asset (full metadata specification ) publisherAccount Public address of the account publishing the asset providers List of public addresses that can act on behalf of the asset publisher, typically for providing some services like access associated to it authorization Type of encryption used to validate authorization ( PSK_RSA , PSK_ECDSA , SecretStore ) activityId Provenance identifier of the activity doing the creation action attributes Optional attributes associated with the provenance creation Example: create ( \"{ddo metadata}\" , 0xaabb , [ 0xccdd ] , \"PSK_RSA\" , \"creation\" , \"+ attributes\" ) Create a compute service \u00b6 It registers a new asset on Nevermined with a compute service associated to it. This function creates a new DID, registering it on-chain through DIDRegistry contract and off-chain in Metadata. Parameters: metadata the metadata describing the asset (full metadata specification ) publisherAccount Public address of the account publishing the asset providers List of public addresses that can act on behalf of the asset publisher, typically for providing some services like access associated to it authorization Type of encryption used to validate authorization ( PSK_RSA , PSK_ECDSA , SecretStore ) activityId Provenance identifier of the activity doing the creation action attributes Optional attributes associated with the provenance creation Example: createCompute ( \"{ddo metadata}\" , 0xaabb , [ 0xccdd ] , \"PSK_RSA\" , \"creation\" , \"+ attributes\" ) Order an asset \u00b6 This function orders an Asset represented by a DID. It implies to initialize a Service Agreement on-chain between publisher and consumer. For lower level details you can take a look at access Specs . As a result of an order the function will return an agreementId . This unique identifier about the Service Agreement just created can be used for further consumption of the access or compute service associated to it. Parameters: did Identifier of the asset to order index The service index of the agreement in the DDO to order consumerAccount The Public address of the consumer account executing the order Example: order ( \"did:nv:1234\" , 0 , 0xaabb ) Download assets \u00b6 This function downloads an Asset previously ordered (using the order function). Parameters: agreementId Identifier of the service agreement between the consumer and the publisher did Identifier of the asset to download index The service index to the access service in the DDO to download path Destination folder where the asset files will be downloaded Example: download ( \"8594385934\" , \"did:nv:1234\" , 0 , 0xaabb , \"/path/to/destination\" ) Execute \u00b6 This function executes a compute service of an Asset previously ordered (using the order function). Parameters: agreementId Identifier of the service agreement between the consumer and the publisher did Identifier of the asset to execute index The service index to the compute service in the DDO to execute workflowDid Identifier of the compute workflow to execute Example: execute ( \"8594385934\" , \"did:nv:1234\" , 0 , 0xaabb , \"did:nv:ccdd\" ) Transfer asset ownership \u00b6 It transfer the on-chain ownership of one asset from the original owner to a different account. Parameters: did Identifier of the asset to execute newAccountOwner The Public address of account belonging to the new owner Example: transferOwnership ( \"did:nv:1234\" , 0xddee ) Fetch assets associated information \u00b6 This functions allow retrieve information related with assets. Assets information can be in two different places: On-chain. As part of the assets registry ( DIDRegistry ). There is stored the did and the url resolving to the did document or ddo . Off-chain. As part of marketplaces, the metadata api services keep all the metadata information (in ddo format) Resolve a DID into a DDO \u00b6 A Nevermined network is composed by only one source of truth, the decentralized logic and storage provided by the blockchain and the Smart Contracts. A part of that, the network can be composed by many different marketplaces or metada repositories. This function resolves a did existing in the unique source of truth (blockchain) into the ddo (metadata) that can be stored in any of the multiple metadata servers existing in a Nevermined network deployment. This function will return the metadata of an asset in DDO format. More information about the contents of this document can be found in the metadata specification page. Parameters: did Identifier of the asset to resolve in a DDO that is off-chain Example: resolve ( \"did:nv:1234\" ) Search for assets \u00b6 This function search in a metadata api instance all the DDO that match the search criteria. This function will return a list of assets metadata matching the criteria. Parameters: text the search query sort Key or list of keys to sort the result offset Number of records per page page Page showed Example: search ( \"weather in Berlin\" , \"price\" , 0 , 1 ) Get assets owned by an account \u00b6 This function retrieves the list of assets owned by an account. Parameters: account The Public address of account owning assets Example: ownerAssets ( 0xaabb ) Get assets purchased by an account \u00b6 This function retrieves the list of assets purchased by an account. Parameters: account The Public address of account that purchased the assets Example: consumerAssets ( 0xaabb ) Get the computation logs of a workflow execution \u00b6 When a user triggers a compute execution via the execute function, this execution is scheduled and de-attached of the api method triggering it. This function returns the logs generated during the execution of the multiple stages of a workflow in the data publisher infrastructure. This function requires the executionId and agreementId for getting the logs. Parameters: agreementId Identifier of the service agreement between the consumer and the publisher executionId Identifier of the execution related with the agreement executed account The Public address of account used to execute the computation Example: computeLogs ( \"8974328\" , \"ababacc\" , 0xaabb ) compute status \u00b6 When a user triggers a compute execution via the execute function, this execution is scheduled and de-attached of the api method triggering it. This function returns status of the jobs executed in the data publisher infrastructure. This function requires the executionId and agreementId for getting the logs. Parameters: agreementId Identifier of the service agreement between the consumer and the publisher executionId Identifier of the execution related with the agreement executed account The Public address of account used to execute the computation Example: computeStatus ( \"8974328\" , \"ababacc\" , 0xaabb ) Non-Fungible Tokens (NFTs) associated to assets \u00b6 A Decentralized Identifier (DID) that digitally represents some physical stuff, aligns quite well with the concept of a Non-Fungible Token (NFT). The implication is that, if you are an asset owner in Nevermined, you can mint NFTs associated with your DID and distribute them amongst your customers or users. Mint a NFT associated to an asset \u00b6 This function allows to a DID owner to mint NFTs associated to the DID. Parameters: did Identifier of the asset where the NFTs will be minted amount the amount of NFTs to mint associated to the DID Example: mint ( \"did:nv:1234\" , 5 ) Burn NFTs associated to an asset \u00b6 This function allows to burn existing NFTs associated to a DID. Parameters: did Identifier of the asset where the NFTs will be burned amount the amount of NFTs to burn associated to the DID Example: burn ( \"did:nv:1234\" , 1 ) Transfer NFTs associated to an asset \u00b6 This function allows to transfer NFTs associated to a DID between accounts. Parameters: did Identifier of the asset where the NFTs will be burned account Public address of the account where the NFTs will be transferred amount the amount of NFTs to burn associated to the DID Example: transfer ( \"did:nv:1234\" , 0xabab , 2 ) Get NFTs balance associated to an asset \u00b6 This function allows to get the NFTs balance of an account for a DID. Parameters: account Public address of the account did Identifier of the asset with NFTs associated Example: balance ( 0xabab , \"did:nv:1234\" )","title":"Assets"},{"location":"api/reference/Assets/#nevermined-assets-api","text":"Every entity object in Nevermined is encapsulated in an asset . Typically the abstract things like datasets, algorithms, services, workflows, etc. But technically can abstract any entity with services provided by an user to the rest network under some conditions. Any asset has 2 main components: A Decentralized Identifier or DID. A unique id that reference the asset. This is recorded on-chain when the asset is registered in a Nevermined network Metadata. A DID Document describing the asset and the services (access, compute, etc.) associated to that asset. This is recorded off-chain. An on-chain DID can be used to resolve the metadata associated to it. You can find more information about the implementation of the SEAs and the services associated to Nevermined assets in the access Spec and the compute Spec .","title":"Nevermined Assets API"},{"location":"api/reference/Assets/#assets-management","text":"","title":"Assets Management"},{"location":"api/reference/Assets/#create-an-asset","text":"It registers a new asset on Nevermined. It Creates a new DID, registering it on-chain through DIDRegistry contract and off-chain in Metadata. Parameters: metadata the metadata describing the asset (full metadata specification ) publisherAccount Public address of the account publishing the asset providers List of public addresses that can act on behalf of the asset publisher, typically for providing some services like access associated to it authorization Type of encryption used to validate authorization ( PSK_RSA , PSK_ECDSA , SecretStore ) activityId Provenance identifier of the activity doing the creation action attributes Optional attributes associated with the provenance creation Example: create ( \"{ddo metadata}\" , 0xaabb , [ 0xccdd ] , \"PSK_RSA\" , \"creation\" , \"+ attributes\" )","title":"Create an asset"},{"location":"api/reference/Assets/#create-a-compute-service","text":"It registers a new asset on Nevermined with a compute service associated to it. This function creates a new DID, registering it on-chain through DIDRegistry contract and off-chain in Metadata. Parameters: metadata the metadata describing the asset (full metadata specification ) publisherAccount Public address of the account publishing the asset providers List of public addresses that can act on behalf of the asset publisher, typically for providing some services like access associated to it authorization Type of encryption used to validate authorization ( PSK_RSA , PSK_ECDSA , SecretStore ) activityId Provenance identifier of the activity doing the creation action attributes Optional attributes associated with the provenance creation Example: createCompute ( \"{ddo metadata}\" , 0xaabb , [ 0xccdd ] , \"PSK_RSA\" , \"creation\" , \"+ attributes\" )","title":"Create a compute service"},{"location":"api/reference/Assets/#order-an-asset","text":"This function orders an Asset represented by a DID. It implies to initialize a Service Agreement on-chain between publisher and consumer. For lower level details you can take a look at access Specs . As a result of an order the function will return an agreementId . This unique identifier about the Service Agreement just created can be used for further consumption of the access or compute service associated to it. Parameters: did Identifier of the asset to order index The service index of the agreement in the DDO to order consumerAccount The Public address of the consumer account executing the order Example: order ( \"did:nv:1234\" , 0 , 0xaabb )","title":"Order an asset"},{"location":"api/reference/Assets/#download-assets","text":"This function downloads an Asset previously ordered (using the order function). Parameters: agreementId Identifier of the service agreement between the consumer and the publisher did Identifier of the asset to download index The service index to the access service in the DDO to download path Destination folder where the asset files will be downloaded Example: download ( \"8594385934\" , \"did:nv:1234\" , 0 , 0xaabb , \"/path/to/destination\" )","title":"Download assets"},{"location":"api/reference/Assets/#execute","text":"This function executes a compute service of an Asset previously ordered (using the order function). Parameters: agreementId Identifier of the service agreement between the consumer and the publisher did Identifier of the asset to execute index The service index to the compute service in the DDO to execute workflowDid Identifier of the compute workflow to execute Example: execute ( \"8594385934\" , \"did:nv:1234\" , 0 , 0xaabb , \"did:nv:ccdd\" )","title":"Execute"},{"location":"api/reference/Assets/#transfer-asset-ownership","text":"It transfer the on-chain ownership of one asset from the original owner to a different account. Parameters: did Identifier of the asset to execute newAccountOwner The Public address of account belonging to the new owner Example: transferOwnership ( \"did:nv:1234\" , 0xddee )","title":"Transfer asset ownership"},{"location":"api/reference/Assets/#fetch-assets-associated-information","text":"This functions allow retrieve information related with assets. Assets information can be in two different places: On-chain. As part of the assets registry ( DIDRegistry ). There is stored the did and the url resolving to the did document or ddo . Off-chain. As part of marketplaces, the metadata api services keep all the metadata information (in ddo format)","title":"Fetch assets associated information"},{"location":"api/reference/Assets/#resolve-a-did-into-a-ddo","text":"A Nevermined network is composed by only one source of truth, the decentralized logic and storage provided by the blockchain and the Smart Contracts. A part of that, the network can be composed by many different marketplaces or metada repositories. This function resolves a did existing in the unique source of truth (blockchain) into the ddo (metadata) that can be stored in any of the multiple metadata servers existing in a Nevermined network deployment. This function will return the metadata of an asset in DDO format. More information about the contents of this document can be found in the metadata specification page. Parameters: did Identifier of the asset to resolve in a DDO that is off-chain Example: resolve ( \"did:nv:1234\" )","title":"Resolve a DID into a DDO"},{"location":"api/reference/Assets/#search-for-assets","text":"This function search in a metadata api instance all the DDO that match the search criteria. This function will return a list of assets metadata matching the criteria. Parameters: text the search query sort Key or list of keys to sort the result offset Number of records per page page Page showed Example: search ( \"weather in Berlin\" , \"price\" , 0 , 1 )","title":"Search for assets"},{"location":"api/reference/Assets/#get-assets-owned-by-an-account","text":"This function retrieves the list of assets owned by an account. Parameters: account The Public address of account owning assets Example: ownerAssets ( 0xaabb )","title":"Get assets owned by an account"},{"location":"api/reference/Assets/#get-assets-purchased-by-an-account","text":"This function retrieves the list of assets purchased by an account. Parameters: account The Public address of account that purchased the assets Example: consumerAssets ( 0xaabb )","title":"Get assets purchased by an account"},{"location":"api/reference/Assets/#get-the-computation-logs-of-a-workflow-execution","text":"When a user triggers a compute execution via the execute function, this execution is scheduled and de-attached of the api method triggering it. This function returns the logs generated during the execution of the multiple stages of a workflow in the data publisher infrastructure. This function requires the executionId and agreementId for getting the logs. Parameters: agreementId Identifier of the service agreement between the consumer and the publisher executionId Identifier of the execution related with the agreement executed account The Public address of account used to execute the computation Example: computeLogs ( \"8974328\" , \"ababacc\" , 0xaabb )","title":"Get the computation logs of a workflow execution"},{"location":"api/reference/Assets/#compute-status","text":"When a user triggers a compute execution via the execute function, this execution is scheduled and de-attached of the api method triggering it. This function returns status of the jobs executed in the data publisher infrastructure. This function requires the executionId and agreementId for getting the logs. Parameters: agreementId Identifier of the service agreement between the consumer and the publisher executionId Identifier of the execution related with the agreement executed account The Public address of account used to execute the computation Example: computeStatus ( \"8974328\" , \"ababacc\" , 0xaabb )","title":"compute status"},{"location":"api/reference/Assets/#non-fungible-tokens-nfts-associated-to-assets","text":"A Decentralized Identifier (DID) that digitally represents some physical stuff, aligns quite well with the concept of a Non-Fungible Token (NFT). The implication is that, if you are an asset owner in Nevermined, you can mint NFTs associated with your DID and distribute them amongst your customers or users.","title":"Non-Fungible Tokens (NFTs) associated to assets"},{"location":"api/reference/Assets/#mint-a-nft-associated-to-an-asset","text":"This function allows to a DID owner to mint NFTs associated to the DID. Parameters: did Identifier of the asset where the NFTs will be minted amount the amount of NFTs to mint associated to the DID Example: mint ( \"did:nv:1234\" , 5 )","title":"Mint a NFT associated to an asset"},{"location":"api/reference/Assets/#burn-nfts-associated-to-an-asset","text":"This function allows to burn existing NFTs associated to a DID. Parameters: did Identifier of the asset where the NFTs will be burned amount the amount of NFTs to burn associated to the DID Example: burn ( \"did:nv:1234\" , 1 )","title":"Burn NFTs associated to an asset"},{"location":"api/reference/Assets/#transfer-nfts-associated-to-an-asset","text":"This function allows to transfer NFTs associated to a DID between accounts. Parameters: did Identifier of the asset where the NFTs will be burned account Public address of the account where the NFTs will be transferred amount the amount of NFTs to burn associated to the DID Example: transfer ( \"did:nv:1234\" , 0xabab , 2 )","title":"Transfer NFTs associated to an asset"},{"location":"api/reference/Assets/#get-nfts-balance-associated-to-an-asset","text":"This function allows to get the NFTs balance of an account for a DID. Parameters: account Public address of the account did Identifier of the asset with NFTs associated Example: balance ( 0xabab , \"did:nv:1234\" )","title":"Get NFTs balance associated to an asset"},{"location":"api/reference/Conditions/","text":"Conditions API Reference \u00b6 As part of the Service Execution Agreements (aka SEAs), Nevermined provide some functions to interact with these conditions. Every execution by an user of a service agreement can be referenced by the agreementId . That is a unique identifier of the agreement execution and it is used across this api reference document. Grant Access \u00b6 Grant access to an address for an specific Search Execution Agreement. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement to grant the access granteeAccount Public address of the account to grant the access Example: grantAccess ( \"8181818\" , \"did:nv:1234\" , 0xaabb ) Grant Service Execution \u00b6 Grant access to an address for an specific Search Execution Agreement. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement to grant the access granteeAccount Public address of the account to grant the computation execution Example: grantServiceExecution ( \"8181818\" , \"did:nv:1234\" , 0xaabb ) Lock Reward \u00b6 Lock the amount of token that are going to be paid for the asset. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to lock Example: lockPayment ( \"8181818\" , 10 ) Release Reward \u00b6 Release the payment to the data publisher (access/compute/et) related with a service execution. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to release Example: releaseReward ( \"8181818\" , 10 ) Refund Reward \u00b6 Refund the payment to the consumer. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to refund Example: refundReward ( \"8181818\" , 10 )","title":"Conditions"},{"location":"api/reference/Conditions/#conditions-api-reference","text":"As part of the Service Execution Agreements (aka SEAs), Nevermined provide some functions to interact with these conditions. Every execution by an user of a service agreement can be referenced by the agreementId . That is a unique identifier of the agreement execution and it is used across this api reference document.","title":"Conditions API Reference"},{"location":"api/reference/Conditions/#grant-access","text":"Grant access to an address for an specific Search Execution Agreement. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement to grant the access granteeAccount Public address of the account to grant the access Example: grantAccess ( \"8181818\" , \"did:nv:1234\" , 0xaabb )","title":"Grant Access"},{"location":"api/reference/Conditions/#grant-service-execution","text":"Grant access to an address for an specific Search Execution Agreement. Parameters: agreementId the unique identifier of the execution of an agreement did Identifier of the asset associated to the service agreement to grant the access granteeAccount Public address of the account to grant the computation execution Example: grantServiceExecution ( \"8181818\" , \"did:nv:1234\" , 0xaabb )","title":"Grant Service Execution"},{"location":"api/reference/Conditions/#lock-reward","text":"Lock the amount of token that are going to be paid for the asset. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to lock Example: lockPayment ( \"8181818\" , 10 )","title":"Lock Reward"},{"location":"api/reference/Conditions/#release-reward","text":"Release the payment to the data publisher (access/compute/et) related with a service execution. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to release Example: releaseReward ( \"8181818\" , 10 )","title":"Release Reward"},{"location":"api/reference/Conditions/#refund-reward","text":"Refund the payment to the consumer. Parameters: agreementId the unique identifier of the execution of an agreement amount Amount of tokens to refund Example: refundReward ( \"8181818\" , 10 )","title":"Refund Reward"},{"location":"api/reference/Provenance/","text":"Provenance API Reference \u00b6 Nevermined Smart Contracts implement the W3C Provenance specification allowing to register on-chain all the provenance information, digital signatures and fingerprints allowing to make use of an open, transparent and unique source of truth for any data ecosystem where multiple parties need to collaborate in a common goal. The complete Nevermined Provenance architecture can be found in the Provenance Spec . This module allows to register Provenance events associated to assets. Also allows to retrieve all the assets provenance track previously registered. Registering Provenance \u00b6 All the provenance events are registered on-chain via the Provenance contract. All the individual provenance events have to be associated to a Provenance ID . This ID is a unique identifier that can be used later on to retrieve information about a specific event. Registering provenance generation \u00b6 Generation is the completion of production of a new entity by an activity. This entity did not exist before generation and becomes available for usage after this generation. Nevermined encapsulate every entity to be managed using Decentralized Identifiers (DID) that are registered via the DIDRegistry Smart Contract. This contract registers automatically the provenance generation event when an asset is created. So this function is not exposed as part of the API, but is referenced here for clarity. You can find more details of this in the Provenance Specs Registering provenance derivation \u00b6 Derivation is a transformation of an entity into another, an update of an entity resulting in a new one, or the construction of a new entity based on a pre-existing entity. This function allows to register a provenance derivation event when a new asset is created as a result of some other asset. The function parameters are: provenanceId the Provenance ID newEntityDid Identifier of the new asset derived as a result of the activity usedEntityDid Identifier of the asset used for deriving a new asset as a result of the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the derivation action attributes Optional attributes associated with the action Example: wasDerivedFrom ( \"999\" , \"did:nv:1234\" , \"did:nv:5678\" , 0xa1a1 , \"activity creating asset\" , \"+ information\" ) You can find more details of this function in the Provenance Specs Registering provenance utilization \u00b6 Usage is the beginning of utilizing an entity by an activity. Before usage, the activity had not begun to utilize this entity and could not have been affected by the entity. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the usage action attributes Optional attributes associated with the action Example: used ( \"999\" , \"did:nv:1234\" , 0xa1a1 , \"using activity\" , \"additional information\" ) You can find more details of this function in the Provenance Specs Registering provenance association \u00b6 Association is an assignment of responsibility to an agent for an activity, indicating that the agent had a role in the activity. This function allows to register a provenance association event to an asset. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the association action attributes Optional attributes associated with the action Example: wasAssociatedWith ( \"999\" , \"did:nv:1234\" , \"ac1\" , \"additional information\" ) You can find more details of this function in the Provenance Specs Registering provenance delegation \u00b6 Delegation is the assignment of authority and responsibility to an agent (by itself or by another agent) to carry out a specific activity as a delegate or representative, while the agent it acts on behalf of retains some responsibility for the outcome of the delegated work. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity delegateAgentId Public address of the user/agent delegated by the responsibleAgentId responsibleAgentId Public address of the user/agent responsible of the did activityId Identifier of the activity doing the association action signature Signature of the provenanceId provided by the delegatedAgentId . This will work as proof of agreement between the delegate and the responsible about a specific provenance action. attributes Optional attributes associated with the action Example: actedOnBehalf ( \"999\" , \"did:nv:1234\" , 0xa1a1 , 0xb2b2 , \"ac1\" , \"s1gnatureeeee\" , \"additional information\" ) You can find more details of this function in the Provenance Specs Retrieving Provenance information \u00b6 Search Provenance events related to an asset \u00b6 When a new provenance event is recorded on-chain, an event is emitted including some information. This function searches across all the ProvenanceAttributeRegistered events related with a specific DID. Parameters: did Identifier of the asset we are looking to search provenance events Example: getDIDProvenanceEvents ( \"did:nv:1234\" ) Search Provenance events related to an asset \u00b6 When a new provenance event is recorded on-chain, an event is emitted including some information. This function searches for specific provenance events methods ( used , wasGeneratedBy , etc.) given a DID. Parameters: method - Reference to the W3C Provenance method event we are going to search. This parameter is an unsigned int from 0 to 15 . See more here in the Smart Contract implementation . did Identifier of the asset we are looking to search provenance events Example: getProvenanceMethodEvents ( 0 , \"did:nv:1234\" ) Get Provenance Entry \u00b6 Get from the on-chain Provenance registry the information about one provenance event, given a provenance id. Parameters: provenanceId Provenance Identifier Example: getProvenanceEntry ( \"049320943\" ) Get Provenance Owner \u00b6 Get from the on-chain Provenance registry the information about who create the provenance entry given a provenance id. Parameters: provenanceId Provenance Identifier Example: getProvenanceOwner ( \"049320943\" ) Managing Provenance Delegates \u00b6 The provenance delegates are accounts that have the ability to register provenance events associated to an asset/entity (Decentralized Identifier - DID) on behalf of the owner. This is helpful in some situations where a user creates a new asset, and later can delegate to a third party to make some actions on an asset and in extension to register provenance events associated to that. The following functions describe how to manage the delegates regarding to DIDs. Add a provenance delegate to a DID \u00b6 It associates a new user as a delegate to an existing DID. Parameters: did Identifier of the asset where the delegate will be added delegatedAccount Public address of the user associated as delegate to the did Example: addDIDProvenanceDelegate ( \"did:nv:1234\" , 0x1234 ) Remove a provenance delegate from a DID \u00b6 It removes an existing delegate of a DID. Parameters: did Identifier of the asset where the delegate will be removed delegatedAccount Public address of the user to remove as delegate to the did Example: removeDIDProvenanceDelegate ( \"did:nv:1234\" , 0x1234 ) Is an user a provenance delegate? \u00b6 Returns true or false if the user account provided is an existing delegate for an existing DID. Parameters: did Identifier of the asset delegatedAccount Public address of the user Example: isProvenanceDelegate ( \"did:nv:1234\" , 0x1234 )","title":"Provenance"},{"location":"api/reference/Provenance/#provenance-api-reference","text":"Nevermined Smart Contracts implement the W3C Provenance specification allowing to register on-chain all the provenance information, digital signatures and fingerprints allowing to make use of an open, transparent and unique source of truth for any data ecosystem where multiple parties need to collaborate in a common goal. The complete Nevermined Provenance architecture can be found in the Provenance Spec . This module allows to register Provenance events associated to assets. Also allows to retrieve all the assets provenance track previously registered.","title":"Provenance API Reference"},{"location":"api/reference/Provenance/#registering-provenance","text":"All the provenance events are registered on-chain via the Provenance contract. All the individual provenance events have to be associated to a Provenance ID . This ID is a unique identifier that can be used later on to retrieve information about a specific event.","title":"Registering Provenance"},{"location":"api/reference/Provenance/#registering-provenance-generation","text":"Generation is the completion of production of a new entity by an activity. This entity did not exist before generation and becomes available for usage after this generation. Nevermined encapsulate every entity to be managed using Decentralized Identifiers (DID) that are registered via the DIDRegistry Smart Contract. This contract registers automatically the provenance generation event when an asset is created. So this function is not exposed as part of the API, but is referenced here for clarity. You can find more details of this in the Provenance Specs","title":"Registering provenance generation"},{"location":"api/reference/Provenance/#registering-provenance-derivation","text":"Derivation is a transformation of an entity into another, an update of an entity resulting in a new one, or the construction of a new entity based on a pre-existing entity. This function allows to register a provenance derivation event when a new asset is created as a result of some other asset. The function parameters are: provenanceId the Provenance ID newEntityDid Identifier of the new asset derived as a result of the activity usedEntityDid Identifier of the asset used for deriving a new asset as a result of the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the derivation action attributes Optional attributes associated with the action Example: wasDerivedFrom ( \"999\" , \"did:nv:1234\" , \"did:nv:5678\" , 0xa1a1 , \"activity creating asset\" , \"+ information\" ) You can find more details of this function in the Provenance Specs","title":"Registering provenance derivation"},{"location":"api/reference/Provenance/#registering-provenance-utilization","text":"Usage is the beginning of utilizing an entity by an activity. Before usage, the activity had not begun to utilize this entity and could not have been affected by the entity. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the usage action attributes Optional attributes associated with the action Example: used ( \"999\" , \"did:nv:1234\" , 0xa1a1 , \"using activity\" , \"additional information\" ) You can find more details of this function in the Provenance Specs","title":"Registering provenance utilization"},{"location":"api/reference/Provenance/#registering-provenance-association","text":"Association is an assignment of responsibility to an agent for an activity, indicating that the agent had a role in the activity. This function allows to register a provenance association event to an asset. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity agentId Public address of the user/agent associated with the action activityId Identifier of the activity doing the association action attributes Optional attributes associated with the action Example: wasAssociatedWith ( \"999\" , \"did:nv:1234\" , \"ac1\" , \"additional information\" ) You can find more details of this function in the Provenance Specs","title":"Registering provenance association"},{"location":"api/reference/Provenance/#registering-provenance-delegation","text":"Delegation is the assignment of authority and responsibility to an agent (by itself or by another agent) to carry out a specific activity as a delegate or representative, while the agent it acts on behalf of retains some responsibility for the outcome of the delegated work. The function parameters are: provenanceId the Provenance ID did Identifier of the asset associated to the activity delegateAgentId Public address of the user/agent delegated by the responsibleAgentId responsibleAgentId Public address of the user/agent responsible of the did activityId Identifier of the activity doing the association action signature Signature of the provenanceId provided by the delegatedAgentId . This will work as proof of agreement between the delegate and the responsible about a specific provenance action. attributes Optional attributes associated with the action Example: actedOnBehalf ( \"999\" , \"did:nv:1234\" , 0xa1a1 , 0xb2b2 , \"ac1\" , \"s1gnatureeeee\" , \"additional information\" ) You can find more details of this function in the Provenance Specs","title":"Registering provenance delegation"},{"location":"api/reference/Provenance/#retrieving-provenance-information","text":"","title":"Retrieving Provenance information"},{"location":"api/reference/Provenance/#search-provenance-events-related-to-an-asset","text":"When a new provenance event is recorded on-chain, an event is emitted including some information. This function searches across all the ProvenanceAttributeRegistered events related with a specific DID. Parameters: did Identifier of the asset we are looking to search provenance events Example: getDIDProvenanceEvents ( \"did:nv:1234\" )","title":"Search Provenance events related to an asset"},{"location":"api/reference/Provenance/#search-provenance-events-related-to-an-asset_1","text":"When a new provenance event is recorded on-chain, an event is emitted including some information. This function searches for specific provenance events methods ( used , wasGeneratedBy , etc.) given a DID. Parameters: method - Reference to the W3C Provenance method event we are going to search. This parameter is an unsigned int from 0 to 15 . See more here in the Smart Contract implementation . did Identifier of the asset we are looking to search provenance events Example: getProvenanceMethodEvents ( 0 , \"did:nv:1234\" )","title":"Search Provenance events related to an asset"},{"location":"api/reference/Provenance/#get-provenance-entry","text":"Get from the on-chain Provenance registry the information about one provenance event, given a provenance id. Parameters: provenanceId Provenance Identifier Example: getProvenanceEntry ( \"049320943\" )","title":"Get Provenance Entry"},{"location":"api/reference/Provenance/#get-provenance-owner","text":"Get from the on-chain Provenance registry the information about who create the provenance entry given a provenance id. Parameters: provenanceId Provenance Identifier Example: getProvenanceOwner ( \"049320943\" )","title":"Get Provenance Owner"},{"location":"api/reference/Provenance/#managing-provenance-delegates","text":"The provenance delegates are accounts that have the ability to register provenance events associated to an asset/entity (Decentralized Identifier - DID) on behalf of the owner. This is helpful in some situations where a user creates a new asset, and later can delegate to a third party to make some actions on an asset and in extension to register provenance events associated to that. The following functions describe how to manage the delegates regarding to DIDs.","title":"Managing Provenance Delegates"},{"location":"api/reference/Provenance/#add-a-provenance-delegate-to-a-did","text":"It associates a new user as a delegate to an existing DID. Parameters: did Identifier of the asset where the delegate will be added delegatedAccount Public address of the user associated as delegate to the did Example: addDIDProvenanceDelegate ( \"did:nv:1234\" , 0x1234 )","title":"Add a provenance delegate to a DID"},{"location":"api/reference/Provenance/#remove-a-provenance-delegate-from-a-did","text":"It removes an existing delegate of a DID. Parameters: did Identifier of the asset where the delegate will be removed delegatedAccount Public address of the user to remove as delegate to the did Example: removeDIDProvenanceDelegate ( \"did:nv:1234\" , 0x1234 )","title":"Remove a provenance delegate from a DID"},{"location":"api/reference/Provenance/#is-an-user-a-provenance-delegate","text":"Returns true or false if the user account provided is an existing delegate for an existing DID. Parameters: did Identifier of the asset delegatedAccount Public address of the user Example: isProvenanceDelegate ( \"did:nv:1234\" , 0x1234 )","title":"Is an user a provenance delegate?"},{"location":"api/reference/Providers/","text":"Providers API Reference \u00b6 In Nevermined a data publisher can delegate to other users identified with their key material, to interact in their behalf. This is useful for users who don't want to run Nevermined infrastructure and delegate that to other entities. This module allows to manage the providers that can interact with data publisher assets. Add a new provider to an asset \u00b6 Allows to associate a new provider to an existing asset. Parameters: did the id of the document where we are gonna associate the provider providerAddress the public address of the provider account the public address of the account executing this action Example: add ( \"did:nv:1234\" , 0xaabb , 0xccdd ) Remove a provider of an asset \u00b6 Allows to de-associate a provider of an asset. Parameters: did the id of the document where we are gonna de-associate the provider providerAddress the public address of the provider account the public address of the account executing this action Example: remove ( \"did:nv:1234\" , 0xaabb , 0xccdd ) List the providers associated to an asset \u00b6 Returns a list with the public addresses of the providers associated to an asset . Parameters: did the id of the document Example: list ( \"did:nv:1234\" )","title":"Providers"},{"location":"api/reference/Providers/#providers-api-reference","text":"In Nevermined a data publisher can delegate to other users identified with their key material, to interact in their behalf. This is useful for users who don't want to run Nevermined infrastructure and delegate that to other entities. This module allows to manage the providers that can interact with data publisher assets.","title":"Providers API Reference"},{"location":"api/reference/Providers/#add-a-new-provider-to-an-asset","text":"Allows to associate a new provider to an existing asset. Parameters: did the id of the document where we are gonna associate the provider providerAddress the public address of the provider account the public address of the account executing this action Example: add ( \"did:nv:1234\" , 0xaabb , 0xccdd )","title":"Add a new provider to an asset"},{"location":"api/reference/Providers/#remove-a-provider-of-an-asset","text":"Allows to de-associate a provider of an asset. Parameters: did the id of the document where we are gonna de-associate the provider providerAddress the public address of the provider account the public address of the account executing this action Example: remove ( \"did:nv:1234\" , 0xaabb , 0xccdd )","title":"Remove a provider of an asset"},{"location":"api/reference/Providers/#list-the-providers-associated-to-an-asset","text":"Returns a list with the public addresses of the providers associated to an asset . Parameters: did the id of the document Example: list ( \"did:nv:1234\" )","title":"List the providers associated to an asset"},{"location":"api/reference/Secret-Store/","text":"Secret Store API Reference \u00b6 Nevermined integrates the Parity Secret Store to support use cases with high security requirements for the secret management. These secrets are being used for the encryption and distributed decryption of the access information to user assets. This module allows the multiparty encryption and decryption of secrets via Secret Store integration. The main functions are: Encrypt \u00b6 Encrypts a document using Secret Store. Parameters: documentId the id of the document to encrypt, typically a DID content the content to encrypt. It can be any kind of string content threshold the minimum number of Secret Store nodes that should build a quorum for decrypting a secret Example: String encryptedContent = encrypt ( \"did:nv:1234\" , \"my secret\" , 3 ) Decrypt \u00b6 Decrypts a document using Secret Store. Parameters: documentId the id of the document to encrypt, typically a DID encryptedContent the content to decrypt. Example: String decryptedContent = decrypt ( \"did:nv:1234\" , \"0358920a932854984293\" )","title":"Secret Store"},{"location":"api/reference/Secret-Store/#secret-store-api-reference","text":"Nevermined integrates the Parity Secret Store to support use cases with high security requirements for the secret management. These secrets are being used for the encryption and distributed decryption of the access information to user assets. This module allows the multiparty encryption and decryption of secrets via Secret Store integration. The main functions are:","title":"Secret Store API Reference"},{"location":"api/reference/Secret-Store/#encrypt","text":"Encrypts a document using Secret Store. Parameters: documentId the id of the document to encrypt, typically a DID content the content to encrypt. It can be any kind of string content threshold the minimum number of Secret Store nodes that should build a quorum for decrypting a secret Example: String encryptedContent = encrypt ( \"did:nv:1234\" , \"my secret\" , 3 )","title":"Encrypt"},{"location":"api/reference/Secret-Store/#decrypt","text":"Decrypts a document using Secret Store. Parameters: documentId the id of the document to encrypt, typically a DID encryptedContent the content to decrypt. Example: String decryptedContent = decrypt ( \"did:nv:1234\" , \"0358920a932854984293\" )","title":"Decrypt"},{"location":"api/reference/Tokens/","text":"Tokens API Reference \u00b6 Nevermined is a solution that uses a blockchain network to execute part of it's business logic using Smart Contracts. Nevermined uses a Ethereum (EVM) based blockchain network. So for executing transactions in existing networks is necessary to pay of that execution. In each network, you\u2019ll need ETH to pay for gas, and Nevermined token for purchasing Nevermined assets ( access and compute ). Nevermined can be deployed in any EVM based network (permissioned or not). In each of these networks ETH and Nevermined tokens can have a real value. The Tokens API Reference describe the functionalities for Nevermined token requests and token transfers. Request Nevermined Tokens \u00b6 Allows to request Nevermined tokens to the Dispenser. This functionality only will work in test networks where the Nevermined token doesn't have a real value. In other production networks it will be necessary to contact the governance entity running Nevermined. Parameters: account the public address of the account receiving the Nevermined tokens amount the amount of Nevermined tokens to receive Example: request ( 0xaabb , 5 ) Transfer Nevermined Tokens \u00b6 Allows to transfer Nevermined tokens between accounts. Parameters: receiver_account the public address of the account receiving the Nevermined tokens amount the amount of Nevermined tokens to transfer sender_account the public address of the account transferring the Nevermined tokens Example: transfer ( 0xaabb , 3 , 0xccdd )","title":"Tokens"},{"location":"api/reference/Tokens/#tokens-api-reference","text":"Nevermined is a solution that uses a blockchain network to execute part of it's business logic using Smart Contracts. Nevermined uses a Ethereum (EVM) based blockchain network. So for executing transactions in existing networks is necessary to pay of that execution. In each network, you\u2019ll need ETH to pay for gas, and Nevermined token for purchasing Nevermined assets ( access and compute ). Nevermined can be deployed in any EVM based network (permissioned or not). In each of these networks ETH and Nevermined tokens can have a real value. The Tokens API Reference describe the functionalities for Nevermined token requests and token transfers.","title":"Tokens API Reference"},{"location":"api/reference/Tokens/#request-nevermined-tokens","text":"Allows to request Nevermined tokens to the Dispenser. This functionality only will work in test networks where the Nevermined token doesn't have a real value. In other production networks it will be necessary to contact the governance entity running Nevermined. Parameters: account the public address of the account receiving the Nevermined tokens amount the amount of Nevermined tokens to receive Example: request ( 0xaabb , 5 )","title":"Request Nevermined Tokens"},{"location":"api/reference/Tokens/#transfer-nevermined-tokens","text":"Allows to transfer Nevermined tokens between accounts. Parameters: receiver_account the public address of the account receiving the Nevermined tokens amount the amount of Nevermined tokens to transfer sender_account the public address of the account transferring the Nevermined tokens Example: transfer ( 0xaabb , 3 , 0xccdd )","title":"Transfer Nevermined Tokens"},{"location":"api/reference/api-reference-latest/","text":"Nevermined API Reference \u00b6 shortname: nevermined-api-spec version: 1.0 status: Draft date: December 2020 The goal of this doc is to help a developer build a version of the Nevermined API in any programming language. Currently, the Nevermined API is defined for Object-Oriented languages such as JavaScript, Java, and Python (which are the three initial implementation languages). Modules \u00b6 The SDKs are organized using the following modules: Assets - Managing of data assets on Nevermined networks Accounts - Managing accounts Agreements - Interacting with Service Exection Agreements Conditions - Interacting with agreement conditions Provenance - Tracking & retrieving data provenance Tokens - Request and transfer Nevermined tokens Providers - Manage of asset providers Secret Store - Encryption and Decryption secrets","title":"API Overview"},{"location":"api/reference/api-reference-latest/#nevermined-api-reference","text":"shortname: nevermined-api-spec version: 1.0 status: Draft date: December 2020 The goal of this doc is to help a developer build a version of the Nevermined API in any programming language. Currently, the Nevermined API is defined for Object-Oriented languages such as JavaScript, Java, and Python (which are the three initial implementation languages).","title":"Nevermined API Reference"},{"location":"api/reference/api-reference-latest/#modules","text":"The SDKs are organized using the following modules: Assets - Managing of data assets on Nevermined networks Accounts - Managing accounts Agreements - Interacting with Service Exection Agreements Conditions - Interacting with agreement conditions Provenance - Tracking & retrieving data provenance Tokens - Request and transfer Nevermined tokens Providers - Manage of asset providers Secret Store - Encryption and Decryption secrets","title":"Modules"},{"location":"architecture/","text":"Nevermined Architecture \u00b6 Nevermined Architecture Introduction Data Ecosystem Principles Use Cases Capabilities Data Sharing Data In Situ Computation Compute backends Kubernetes backend Federated Learning backend Data Marketplace and Cataloging Architecture Technical components Nevermined Specifications (Specs) Introduction \u00b6 Nevermined is a data ecosystem solution that provides the capabilities of building bespoke networks where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. With the explosion of the data and AI market, entities have the necessity of organizing, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing & Data In Situ Computation solutions allowing to unlock data for AI. Nevermined enables a \u201cData In Situ Computation\u201d solution, meaning the data never moves, is the algorithm the one moving where the data is. It allows data owners or providers to define the conditions in which they allow others to make use of their data without giving direct access to it. Nevermined is designed to be integrated in Big Data environments. It enables monetizing the data without migration. It\u2019s also designed for GDPR compliance, it never stores any personal information on-chain (encrypted or in plain text). Nevermined is the product powered by Keyko providing Data Sharing & Data In Situ Computation solutions allowing to unlock data for AI. Data Ecosystem Principles \u00b6 During the design and construction of Nevermined, we identified 6 key factors for the adoption and usage of a data ecosystem and its continued growth: Culture - Culture & Organization help to establish how each ecosystem actor interact with others. We promote it giving a user centric approach User Experience (UX) - The ecosystems should provide an excellent User eXperience, facilitating the participation of all the partners and users Trust - Data ecosystems must promote trustful environments where untrusted parties can collaborate Integrity - Data integrity and provenance as first class citizens where the ecosystem users can validate that data doesn't change and from where is coming Compliance - Data first approach compliance with all the data regulatory requirements Incentives - We promote the usage and retention of data ecosystems via gamification and providing additional value Use Cases \u00b6 Nevermined is a platform agnostic solution enabling data use cases where different parties don't trust each other. It allows to provide data ecosystems where DATA OWNERS need to share and monetize their data with third-party people, but they want to keep the privacy and the control of their data. Typical use cases for sector are: Banking - Data Sharing with the regulator or internal across different jurisdictions Telco - Anonymized Data Sharing with the regulator and partners. AI within moving the data Health & Pharma - AI over medical results of different hospitals without revealing PI Supply Chain - Provenance, integrity and tracking of goods Automotive - Data Sharing for AI to promote the autonomous cars Others - Real estate, digital assets tokenization, .. Capabilities \u00b6 Nevermined is based in three core building blocks: Data Sharing \u00b6 It enables the data sharing capabilities between unstructured parties. The main users involved in this scenario are: Organizations with data that need to share and monetize ( Data Owners ). Organizations or individuals looking for data sets to train their models ( Data Consumers ). Typically Data Owners & Consumers don't know or trust each other. Nevermined provides a generic solution where both can share data in a decentralized and secure way. The main benefits for them are: Data Owners can get some benefit of their existing data Data Consumers can get access to datasets they couldn't get access in other conditions Nevermined Data Sharing flow In this use case the CONSUMERS can get access to the datasets, so it's ideal for problems with low data privacy constraints. The main capabilities are: Allowing data monetization. Data owners can make available their data and get some rewards/benefits when others get access to it. Allows an easy data publishing or data access from the users. Provides a Decentralized Access Control where untrusted members can feel confident that other members of the system will play honestly Supports free or paid access scenarios All the interactions related with the assets or services (when are created in the system, who has access, when the access was granted, etc.) is tracked The decentralized access control can be used in public or private blockchain networks You can find more details about the technical implementation of the Data Sharing use case in the ACCESS SPEC . Data In Situ Computation (DISC) \u00b6 It facilitates the use cases where data owners allow third parties to execute some algorithms where the data is. For the use cases with more privacy restrictions in which the Data Owner never wants to lose control of their data, and this source data can't be accessed directly, Nevermined provides a Data In Situ Computation solution. This scenario is based on the premise that data doesn't want to be moved. Moving data of their existing premises is a liability. The data can be leaked in transit and because the private nature of the data, moving it implies some regulatory issues. In that case, Nevermined provides a solution where the Data Owner allows the execution of an algorithm (tensorflow, spark, etc.) in the infrastructure where the data is. It means the Data Consumer provides the algorithm to execute, and this is moved to the Data Owner infrastructure where the data is being kept. The Data Consumer receives the result of the execution of the algorithm on top of the data. Data In Situ Computation You can find more details about the technical implementation of the Data In Situ Computation use case in the COMPUTE SPEC . The main capabilities of the Data In Situ Computation building block are: Solution designed to support different computation or backend paradigms Implemented 2 different backends, one of them orchestrating Kubernetes containers in the Data Provider environment. Other via the integration of a Federated Learning framework Framework or programming language independent The data never moves, algorithm goes where data is Consumer never get access to the real data The algorithm is moved where the data is. An ephemeral environment is created to support the computation It supports the orchestration of computing pipelines All the access control and execution is controlled via the integration with the service agreements Can be run in cloud providers or on-premise Permits the monitoring of the workflows execution Compute backends \u00b6 Nevermined supports to plug different compute backends that could be more convenient depending on the use cases. The rest of the ecosystem keeps the same (services, api\u2019s, applications on top, etc.), but depending on how the use case is, Nevermined will orchestrate the compute jobs in different ways. At this point in time Nevermined integrates 2 different compute backends: Kubernetes backend \u00b6 This backend is perfect for compute jobs that can be executed in the data provider data center and don\u2019t have high privacy constraints. In this scenario the Client can implement the algorithm using different languages or frameworks, and the Nevermined Compute solution will be in charge of orchestrating the infrastructure for moving the algorithm where the data is. Kubernetes orchestration As you can see in the above diagram, the Compute API will be in charge of triggering the compute workflow interacting with the Kubernetes infrastructure via Argo . This includes: Download the algorithm provided by the Data Scientist/Engineer Starts the right Docker container in the infrastructure Mount as volume with the data Execute the algorithm passing as parameter the path where the data is mounted Stop the Compute pod where the algorithm is running Publishing the result as a new asset Destroy all the ephemeral environment Federated Learning backend \u00b6 This backend fits for the execution of federated learning jobs using the data of providers having federated environments. In this scenario the Client can implement the data training model using a generic federated learning framework, and the Nevermined Compute solution will be in charge of orchestrating the execution across all the participants. In this scenario the Compute backend starts two independent tasks, the coordinator and the aggregator. The coordinator will do all the management of the participants as part of a federated job. The aggregator will do the secure aggregation of the trained models. Both the coordinator and aggregator are ephemeral nodes created by demand, so after the job is executed they will be stopped till a new execution request is triggered. Federated Learning backend Data Marketplace and Cataloging \u00b6 It facilitates the search, discovery and management of the existing assets in the data ecosystem. The main capabilities are: Improved User Experience Integration with the Data Governance and Data Catalog tools Easy search and discovery Native integration with the data sharing and data in situ computation building blocks Internal data catalog and APIs Tokenization and incentives Architecture \u00b6 Technical components \u00b6 The complete description of the architecture components & licenses can be found here . A brief summary of some of them: SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets. Nevermined Specifications (Specs) \u00b6 The core of the platform is documented in detail in Specification documents (aka SPECs). Here you can find a list of the most relevant SPECs: Short Name Title Version Status Editor DID Decentralized Identifiers 0.1 Raw @aaitor META Metadata 0.1 Raw @aaitor ACCESS Decentralized Access Control 0.1 Raw @aaitor COMPUTE Data In Situ Computation 0.1 Raw @aaitor FL Federated Learning Orchestration 0.1 Raw @rodolphe PROV Decentralized Data Provenance 0.1 Raw @aaitor IDM Identity management with on-chain access control 0.1 Raw @aaitor The DID, META, ACCESS & COMPUTE specs are an evolution of Ocean Protocol Enhancement Proposals - OEPs .","title":"Overview"},{"location":"architecture/#nevermined-architecture","text":"Nevermined Architecture Introduction Data Ecosystem Principles Use Cases Capabilities Data Sharing Data In Situ Computation Compute backends Kubernetes backend Federated Learning backend Data Marketplace and Cataloging Architecture Technical components Nevermined Specifications (Specs)","title":"Nevermined Architecture"},{"location":"architecture/#introduction","text":"Nevermined is a data ecosystem solution that provides the capabilities of building bespoke networks where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. With the explosion of the data and AI market, entities have the necessity of organizing, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing & Data In Situ Computation solutions allowing to unlock data for AI. Nevermined enables a \u201cData In Situ Computation\u201d solution, meaning the data never moves, is the algorithm the one moving where the data is. It allows data owners or providers to define the conditions in which they allow others to make use of their data without giving direct access to it. Nevermined is designed to be integrated in Big Data environments. It enables monetizing the data without migration. It\u2019s also designed for GDPR compliance, it never stores any personal information on-chain (encrypted or in plain text). Nevermined is the product powered by Keyko providing Data Sharing & Data In Situ Computation solutions allowing to unlock data for AI.","title":"Introduction"},{"location":"architecture/#data-ecosystem-principles","text":"During the design and construction of Nevermined, we identified 6 key factors for the adoption and usage of a data ecosystem and its continued growth: Culture - Culture & Organization help to establish how each ecosystem actor interact with others. We promote it giving a user centric approach User Experience (UX) - The ecosystems should provide an excellent User eXperience, facilitating the participation of all the partners and users Trust - Data ecosystems must promote trustful environments where untrusted parties can collaborate Integrity - Data integrity and provenance as first class citizens where the ecosystem users can validate that data doesn't change and from where is coming Compliance - Data first approach compliance with all the data regulatory requirements Incentives - We promote the usage and retention of data ecosystems via gamification and providing additional value","title":"Data Ecosystem Principles"},{"location":"architecture/#use-cases","text":"Nevermined is a platform agnostic solution enabling data use cases where different parties don't trust each other. It allows to provide data ecosystems where DATA OWNERS need to share and monetize their data with third-party people, but they want to keep the privacy and the control of their data. Typical use cases for sector are: Banking - Data Sharing with the regulator or internal across different jurisdictions Telco - Anonymized Data Sharing with the regulator and partners. AI within moving the data Health & Pharma - AI over medical results of different hospitals without revealing PI Supply Chain - Provenance, integrity and tracking of goods Automotive - Data Sharing for AI to promote the autonomous cars Others - Real estate, digital assets tokenization, ..","title":"Use Cases"},{"location":"architecture/#capabilities","text":"Nevermined is based in three core building blocks:","title":"Capabilities"},{"location":"architecture/#data-sharing","text":"It enables the data sharing capabilities between unstructured parties. The main users involved in this scenario are: Organizations with data that need to share and monetize ( Data Owners ). Organizations or individuals looking for data sets to train their models ( Data Consumers ). Typically Data Owners & Consumers don't know or trust each other. Nevermined provides a generic solution where both can share data in a decentralized and secure way. The main benefits for them are: Data Owners can get some benefit of their existing data Data Consumers can get access to datasets they couldn't get access in other conditions Nevermined Data Sharing flow In this use case the CONSUMERS can get access to the datasets, so it's ideal for problems with low data privacy constraints. The main capabilities are: Allowing data monetization. Data owners can make available their data and get some rewards/benefits when others get access to it. Allows an easy data publishing or data access from the users. Provides a Decentralized Access Control where untrusted members can feel confident that other members of the system will play honestly Supports free or paid access scenarios All the interactions related with the assets or services (when are created in the system, who has access, when the access was granted, etc.) is tracked The decentralized access control can be used in public or private blockchain networks You can find more details about the technical implementation of the Data Sharing use case in the ACCESS SPEC .","title":"Data Sharing"},{"location":"architecture/#data-in-situ-computation-disc","text":"It facilitates the use cases where data owners allow third parties to execute some algorithms where the data is. For the use cases with more privacy restrictions in which the Data Owner never wants to lose control of their data, and this source data can't be accessed directly, Nevermined provides a Data In Situ Computation solution. This scenario is based on the premise that data doesn't want to be moved. Moving data of their existing premises is a liability. The data can be leaked in transit and because the private nature of the data, moving it implies some regulatory issues. In that case, Nevermined provides a solution where the Data Owner allows the execution of an algorithm (tensorflow, spark, etc.) in the infrastructure where the data is. It means the Data Consumer provides the algorithm to execute, and this is moved to the Data Owner infrastructure where the data is being kept. The Data Consumer receives the result of the execution of the algorithm on top of the data. Data In Situ Computation You can find more details about the technical implementation of the Data In Situ Computation use case in the COMPUTE SPEC . The main capabilities of the Data In Situ Computation building block are: Solution designed to support different computation or backend paradigms Implemented 2 different backends, one of them orchestrating Kubernetes containers in the Data Provider environment. Other via the integration of a Federated Learning framework Framework or programming language independent The data never moves, algorithm goes where data is Consumer never get access to the real data The algorithm is moved where the data is. An ephemeral environment is created to support the computation It supports the orchestration of computing pipelines All the access control and execution is controlled via the integration with the service agreements Can be run in cloud providers or on-premise Permits the monitoring of the workflows execution","title":"Data In Situ Computation (DISC)"},{"location":"architecture/#compute-backends","text":"Nevermined supports to plug different compute backends that could be more convenient depending on the use cases. The rest of the ecosystem keeps the same (services, api\u2019s, applications on top, etc.), but depending on how the use case is, Nevermined will orchestrate the compute jobs in different ways. At this point in time Nevermined integrates 2 different compute backends:","title":"Compute backends"},{"location":"architecture/#kubernetes-backend","text":"This backend is perfect for compute jobs that can be executed in the data provider data center and don\u2019t have high privacy constraints. In this scenario the Client can implement the algorithm using different languages or frameworks, and the Nevermined Compute solution will be in charge of orchestrating the infrastructure for moving the algorithm where the data is. Kubernetes orchestration As you can see in the above diagram, the Compute API will be in charge of triggering the compute workflow interacting with the Kubernetes infrastructure via Argo . This includes: Download the algorithm provided by the Data Scientist/Engineer Starts the right Docker container in the infrastructure Mount as volume with the data Execute the algorithm passing as parameter the path where the data is mounted Stop the Compute pod where the algorithm is running Publishing the result as a new asset Destroy all the ephemeral environment","title":"Kubernetes backend"},{"location":"architecture/#federated-learning-backend","text":"This backend fits for the execution of federated learning jobs using the data of providers having federated environments. In this scenario the Client can implement the data training model using a generic federated learning framework, and the Nevermined Compute solution will be in charge of orchestrating the execution across all the participants. In this scenario the Compute backend starts two independent tasks, the coordinator and the aggregator. The coordinator will do all the management of the participants as part of a federated job. The aggregator will do the secure aggregation of the trained models. Both the coordinator and aggregator are ephemeral nodes created by demand, so after the job is executed they will be stopped till a new execution request is triggered. Federated Learning backend","title":"Federated Learning backend"},{"location":"architecture/#data-marketplace-and-cataloging","text":"It facilitates the search, discovery and management of the existing assets in the data ecosystem. The main capabilities are: Improved User Experience Integration with the Data Governance and Data Catalog tools Easy search and discovery Native integration with the data sharing and data in situ computation building blocks Internal data catalog and APIs Tokenization and incentives","title":"Data Marketplace and Cataloging"},{"location":"architecture/#architecture","text":"","title":"Architecture"},{"location":"architecture/#technical-components","text":"The complete description of the architecture components & licenses can be found here . A brief summary of some of them: SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets.","title":"Technical components"},{"location":"architecture/#nevermined-specifications-specs","text":"The core of the platform is documented in detail in Specification documents (aka SPECs). Here you can find a list of the most relevant SPECs: Short Name Title Version Status Editor DID Decentralized Identifiers 0.1 Raw @aaitor META Metadata 0.1 Raw @aaitor ACCESS Decentralized Access Control 0.1 Raw @aaitor COMPUTE Data In Situ Computation 0.1 Raw @aaitor FL Federated Learning Orchestration 0.1 Raw @rodolphe PROV Decentralized Data Provenance 0.1 Raw @aaitor IDM Identity management with on-chain access control 0.1 Raw @aaitor The DID, META, ACCESS & COMPUTE specs are an evolution of Ocean Protocol Enhancement Proposals - OEPs .","title":"Nevermined Specifications (Specs)"},{"location":"architecture/components/","text":"Nevermined Components \u00b6 Nevermined is a data ecosystems where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. Nevermined packages, automate and augment multiple independent open and private software components providing a fully functional data ecosystem adapted to the requirements of the enterprises. The complete technical solution includes the following components: Architecture of Components \u00b6 Nevermined components Smart Contracts \u00b6 Nevermined Smart Contracts provide the core of the Data Ecosystem. Using an Ethereum network and implemented in Solidity, the Smart Contracts provide the following functionality: ERC20 Token - Utility token used within the platform allowing to build all the payment mechanisms used across the system. DID Registry - Nevermined uses W3C Decentralized Identifiers (DID) to identify and register assets in the platform. The DID Registry allows the registering and resolving capabilities of assets across multiple Metadata providers. Service Execution Agreements (SEAs) - The core engine of the platform. They allow to define on-chain condition pipelines enabling to the users to define complex use cases. The SEAs orchestrate the execution of the Data Access and Data Computation use cases of Nevermined. Conditions - Small modules that can be plugged into the SEAs allowing to add validations logic Contract Templates - Pre-defined contract templates implementing some basic use cases Dispenser - Contract that allows to dispense token under request Libraries - Utility libraries used across the contracts All the previous contracts are Open Source software and provide the core of the Nevermined network. In addition to those, Nevermined provides some extensions of the contracts with extended functionalities: Group and individual whitelisting conditions - Enterprise users typically manage their corporate identity using Active Directory solutions or similar. In those platforms exist the mapping between the user identity and the groups where those users are part of. The advanced whitelisting conditions allow to map complex identity systems with the Smart Contracts logic allowing to provide access control mechanisms on-chain. Interface for external Tokens - It allows to plug in the system an external ERC20 Token avoiding to use the Nevermined ERC20 token. Additional SEAs Templates - The additional Service Execution Templates provide a richer set of use cases to be used in the platform. Improved SEA - Allowing to have faster agreements and simpler negotiations Smart Contracts Governance \u00b6 The control of the Smart Contracts (deployment, upgrade) is typically a responsibility of the Governance committee of the Data Ecosystem. The team responsible for the definition, deployment and maintenance of the whole system. A typical user of the ecosystem doesn\u2019t need to know anything about the underlying Smart Contracts or Blockchain. All the business logic is encapsulated in the client libraries so typically there is no direct integration between the users and the Smart Contracts. Metadata API \u00b6 The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters. Gateway \u00b6 The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway allows also the encryption and decryption of components using the following mechanisms: RSA ECDSA Parity Secret Store Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters. Compute API \u00b6 The Nevermined Compute API is an Open Source micro-service in the Nevermined ecosystem. It\u2019s a component in charge of orchestrating the execution of compute jobs in the premises of the Data/Compute Providers. In Nevermined the Data/Compute Providers can publish services saying they offer compute capabilities to the network on top of their data under some conditions for a given price. The Compute API is in charge of, after all the verifications made by the Gateway, to manage all the infrastructure to move the algorithm where the data is and track the execution of these ephemeral environments. The Compute API is a generic service exposing a REST API that can plugs different compute backends. At this point in time the Compute API integrates 2 different backends: Kubernetes backend - It allows the orchestration of Kubernetes clusters for setting up compute workflows in cloud or on-premise environments. Federated Learning backend - It manages the execution of FL jobs in different federated environments. It starts the coordinator and an aggregator tasks doing the management of the participants as part of a federated job and the secure aggregation of the trained models. Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters. Software Development Kits (SDK's) \u00b6 SDK's are the software libraries encapsulating the Nevermined business logic. They are used to interact with all the components & APIs of the system. Nevermined provides 3 different Open Source implementation of SDK's allowing the integration and implementation of complex use cases on top of the Nevermined Data Ecosystems. Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. The libraries are packaged and delivered in the typical formats for each language allowing easy integration: NPM Nevermined SDK JS NPM Nevermined SDK PY NPM Nevermined SDK JAVA Secret Store \u00b6 Nevermined integrates the Parity Secret Store to support use cases with high security requirements for the secret management. These secrets are being used for the encryption and distributed decryption of the access information to user assets. Parity Secret Store is a feature included as part of the Parity Ethereum client that allows users to store a fragmented ECDSA key on the blockchain, such that retrievals are controlled by a permissioned Smart Contract. The Secret Store implements a threshold retrieval system, so individual Secret Store nodes are unable to reconstruct the keys to decrypt documents by themselves. A Secret Store node only saves a portion of the ECDSA key. The decryption key can only be generated if a consensus is reached by an amount of Secret Store nodes bigger than the threshold that the publisher of the secret chooses. The Secret Store is integrated into Nevermined as an optional component for supporting the encryption and decryption. Command Line Interface (CLI) tool \u00b6 The Nevermined CLI tool enables to connect to the Nevermined Data Ecosystem and interact with it using the command line interface. It orchestrates all the underlaying components allowing to: Publish assets Get access to assets Search and discovery Running remote compute jobs Checking the state of Service Agreements Operational \u00b6 Are the Nevermined tools (not Open Source) allowing to automate, integrate and operate the rest of the components of the stack. The main tools available are: Contract Tools \u00b6 Nevermined Contract Tools . The Nevermined Zeppelin OS contract management framework. Deploying and upgrading Smart Contracts in multiple environments is not an easy thing. The Nevermined Contract Tools allow to deploy and upgrade smart contracts across multiple networks (production or testnet, public or private) mitigating the risk loose the control of the Smart Contracts or leave them in a non-functional way. Development and Integration \u00b6 The Nevermined Tools allows to execute all the components included in the stack in a local environment. Nevermined Tools make use of all the containers of the components and orchestrate the execution of them having a fully functional solution using the same software that you can find in a production environment. This approach allows to: Develop and integrate functionalities with a lower risk of issues when you move to a staging or production environment Automate the integration tests in the CI environments having fully functional networks used for testing Connect to remote blockchain networks from your local environment Multisig Wallet \u00b6 Nevermined Multisig Wallet helps during the token governance process. The purpose of multisig wallets is to increase security by requiring multiple parties to agree on transactions before execution. Transactions can be executed only when confirmed by a predefined number of owners. Monitoring \u00b6 The Nevermined Monitoring component is an integration of the Keyko Web3 Monitoring component adapted to the Nevermined use cases. It allows to monitor: The execution of the Service Agreements Assets registered Token Payments Compute use cases Blocks, Events and Transactions of the network The monitoring tool exposes the dashboards for an easy understanding of what's going on in the network.","title":"Components"},{"location":"architecture/components/#nevermined-components","text":"Nevermined is a data ecosystems where different entities can share and monetize their data and make an efficient and secure usage of it even with untrusted parties. Nevermined packages, automate and augment multiple independent open and private software components providing a fully functional data ecosystem adapted to the requirements of the enterprises. The complete technical solution includes the following components:","title":"Nevermined Components"},{"location":"architecture/components/#architecture-of-components","text":"Nevermined components","title":"Architecture of Components"},{"location":"architecture/components/#smart-contracts","text":"Nevermined Smart Contracts provide the core of the Data Ecosystem. Using an Ethereum network and implemented in Solidity, the Smart Contracts provide the following functionality: ERC20 Token - Utility token used within the platform allowing to build all the payment mechanisms used across the system. DID Registry - Nevermined uses W3C Decentralized Identifiers (DID) to identify and register assets in the platform. The DID Registry allows the registering and resolving capabilities of assets across multiple Metadata providers. Service Execution Agreements (SEAs) - The core engine of the platform. They allow to define on-chain condition pipelines enabling to the users to define complex use cases. The SEAs orchestrate the execution of the Data Access and Data Computation use cases of Nevermined. Conditions - Small modules that can be plugged into the SEAs allowing to add validations logic Contract Templates - Pre-defined contract templates implementing some basic use cases Dispenser - Contract that allows to dispense token under request Libraries - Utility libraries used across the contracts All the previous contracts are Open Source software and provide the core of the Nevermined network. In addition to those, Nevermined provides some extensions of the contracts with extended functionalities: Group and individual whitelisting conditions - Enterprise users typically manage their corporate identity using Active Directory solutions or similar. In those platforms exist the mapping between the user identity and the groups where those users are part of. The advanced whitelisting conditions allow to map complex identity systems with the Smart Contracts logic allowing to provide access control mechanisms on-chain. Interface for external Tokens - It allows to plug in the system an external ERC20 Token avoiding to use the Nevermined ERC20 token. Additional SEAs Templates - The additional Service Execution Templates provide a richer set of use cases to be used in the platform. Improved SEA - Allowing to have faster agreements and simpler negotiations","title":"Smart Contracts"},{"location":"architecture/components/#smart-contracts-governance","text":"The control of the Smart Contracts (deployment, upgrade) is typically a responsibility of the Governance committee of the Data Ecosystem. The team responsible for the definition, deployment and maintenance of the whole system. A typical user of the ecosystem doesn\u2019t need to know anything about the underlying Smart Contracts or Blockchain. All the business logic is encapsulated in the client libraries so typically there is no direct integration between the users and the Smart Contracts.","title":"Smart Contracts Governance"},{"location":"architecture/components/#metadata-api","text":"The Nevermined Metadata API is an Open Source micro-service that allows to store Assets metadata in an off-chain repository. It provides a plugins system allowing to persist the Metadata in ElasticSearch or MongoDB. The Metadata API exposes the functionality for searching metadata using multiple filters and parameters. The Metadata API is typically the backend used for Data Marketplaces or Data Catalogs for storing all the Metadata of a specific domain related to a Marketplace or Catalog . Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters.","title":"Metadata API"},{"location":"architecture/components/#gateway","text":"The Nevermined Gateway is an Open Source micro-service in the Nevermined ecosystem. The Gateway is the technical component executed by Data/Compute Providers allowing them to provide extended data services (e.g. storage and compute). The Nevermined Gateway, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise). The Gateway allows also the encryption and decryption of components using the following mechanisms: RSA ECDSA Parity Secret Store Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters.","title":"Gateway"},{"location":"architecture/components/#compute-api","text":"The Nevermined Compute API is an Open Source micro-service in the Nevermined ecosystem. It\u2019s a component in charge of orchestrating the execution of compute jobs in the premises of the Data/Compute Providers. In Nevermined the Data/Compute Providers can publish services saying they offer compute capabilities to the network on top of their data under some conditions for a given price. The Compute API is in charge of, after all the verifications made by the Gateway, to manage all the infrastructure to move the algorithm where the data is and track the execution of these ephemeral environments. The Compute API is a generic service exposing a REST API that can plugs different compute backends. At this point in time the Compute API integrates 2 different backends: Kubernetes backend - It allows the orchestration of Kubernetes clusters for setting up compute workflows in cloud or on-premise environments. Federated Learning backend - It manages the execution of FL jobs in different federated environments. It starts the coordinator and an aggregator tasks doing the management of the participants as part of a federated job and the secure aggregation of the trained models. Nevermined provides the package and automation of the micro-service allowing an easy integration and deployment in cloud providers and Kubernetes clusters.","title":"Compute API"},{"location":"architecture/components/#software-development-kits-sdks","text":"SDK's are the software libraries encapsulating the Nevermined business logic. They are used to interact with all the components & APIs of the system. Nevermined provides 3 different Open Source implementation of SDK's allowing the integration and implementation of complex use cases on top of the Nevermined Data Ecosystems. Nevermined SDK JS - JavaScript version of the Nevermined SDK to be integrated with front-end applications. Nevermined SDK PY - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. Nevermined SDK JAVA - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. The libraries are packaged and delivered in the typical formats for each language allowing easy integration: NPM Nevermined SDK JS NPM Nevermined SDK PY NPM Nevermined SDK JAVA","title":"Software Development Kits (SDK's)"},{"location":"architecture/components/#secret-store","text":"Nevermined integrates the Parity Secret Store to support use cases with high security requirements for the secret management. These secrets are being used for the encryption and distributed decryption of the access information to user assets. Parity Secret Store is a feature included as part of the Parity Ethereum client that allows users to store a fragmented ECDSA key on the blockchain, such that retrievals are controlled by a permissioned Smart Contract. The Secret Store implements a threshold retrieval system, so individual Secret Store nodes are unable to reconstruct the keys to decrypt documents by themselves. A Secret Store node only saves a portion of the ECDSA key. The decryption key can only be generated if a consensus is reached by an amount of Secret Store nodes bigger than the threshold that the publisher of the secret chooses. The Secret Store is integrated into Nevermined as an optional component for supporting the encryption and decryption.","title":"Secret Store"},{"location":"architecture/components/#command-line-interface-cli-tool","text":"The Nevermined CLI tool enables to connect to the Nevermined Data Ecosystem and interact with it using the command line interface. It orchestrates all the underlaying components allowing to: Publish assets Get access to assets Search and discovery Running remote compute jobs Checking the state of Service Agreements","title":"Command Line Interface (CLI) tool"},{"location":"architecture/components/#operational","text":"Are the Nevermined tools (not Open Source) allowing to automate, integrate and operate the rest of the components of the stack. The main tools available are:","title":"Operational"},{"location":"architecture/components/#contract-tools","text":"Nevermined Contract Tools . The Nevermined Zeppelin OS contract management framework. Deploying and upgrading Smart Contracts in multiple environments is not an easy thing. The Nevermined Contract Tools allow to deploy and upgrade smart contracts across multiple networks (production or testnet, public or private) mitigating the risk loose the control of the Smart Contracts or leave them in a non-functional way.","title":"Contract Tools"},{"location":"architecture/components/#development-and-integration","text":"The Nevermined Tools allows to execute all the components included in the stack in a local environment. Nevermined Tools make use of all the containers of the components and orchestrate the execution of them having a fully functional solution using the same software that you can find in a production environment. This approach allows to: Develop and integrate functionalities with a lower risk of issues when you move to a staging or production environment Automate the integration tests in the CI environments having fully functional networks used for testing Connect to remote blockchain networks from your local environment","title":"Development and Integration"},{"location":"architecture/components/#multisig-wallet","text":"Nevermined Multisig Wallet helps during the token governance process. The purpose of multisig wallets is to increase security by requiring multiple parties to agree on transactions before execution. Transactions can be executed only when confirmed by a predefined number of owners.","title":"Multisig Wallet"},{"location":"architecture/components/#monitoring","text":"The Nevermined Monitoring component is an integration of the Keyko Web3 Monitoring component adapted to the Nevermined use cases. It allows to monitor: The execution of the Service Agreements Assets registered Token Payments Compute use cases Blocks, Events and Transactions of the network The monitoring tool exposes the dashboards for an easy understanding of what's going on in the network.","title":"Monitoring"},{"location":"architecture/repos/","text":"Repositories \u00b6 The complete description of the architecture components & licenses can be found here . A brief summary of some of them: SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets.","title":"Repositories"},{"location":"architecture/repos/#repositories","text":"The complete description of the architecture components & licenses can be found here . A brief summary of some of them: SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets.","title":"Repositories"},{"location":"architecture/contracts/","text":"Nevermined Contracts Documentation \u00b6 The Nevermined Contracts are organized in different modules. Each of them is intended to keep different Solidity Smart Contracts code providing different building blocks or capabilities to implement the Nevermined Business Logic. Modules \u00b6 Registry \u00b6 It allows the registration of assets into a Nevermined network. The entry point for that is the DIDRegistry contract. It allows to The different contracts involved in the Registry module are: DID Registry DID Factory NFT Upgradeable DIDRegistry Library Provenance Registry Service Agreement Templates \u00b6 This are the templates used for the end users to define use cases or user flows. They implement a pre-defined user flow implementing a use case (like selling access to data). Every different service agreement template allows to create instances of their type by the users with custimzed conditions. The existing templates existing are: Access Template Compute Execution Template DID Sales Template NFT Sales Template NFT Access Template Dynamic Access Template A part of this, the agreements contracts module provide some internal components to manage the registering of service agreements on-chain. This contracts typically don't need be instantiated directly by end-users: Agreement Store Manager Agreement Store Library Service Agreement Conditions \u00b6 Are the different conditions allowing to the users of a flow to define the ground rules as part of an agreement. Conditions typically have different parameters allowing to the users to define the specific conditions that someone executing an agreement needs to fulfill. The combination of templates and agreements allow the definition of complex scenarios where the users can interact and transact regarding Nevermined digital assets. The existing conditions ready to be used are: Access Condition Lock Payment Condition Rewards Reward Escrow Payment Compute Execution Condition Hash Lock Condition NFT Access Condition NFT Holder Condition NFT Lock Condition Transfer DID Ownership Condition Transfer NFT Condition Sign Condition Whitelisting Condition Threshold Condition Token \u00b6 This are the contracts providing the following capabilities: Nevermined Token - A reference implementation of a ERC20 token. This NVM token is provided as default token in a Nevermined deployment. The usage of this token is not necessary. A different ERC20 can be used depending on the deployment of the network or the configuration of the service agreements. This allows to support payments in the NVM token, a different ERC20 token or in ETH . Dispenser - It allows the distribution of ERC20 tokens (typically NVM token) in a testnet. Because of that, the Dispenser contract is not deployed in production or mainnet networks . Libraries \u00b6 EpochLibrary HashListLibrary Common Hash List Contract Interfaces \u00b6 IList ISecret Store ISecret Store Permission Template Libraries \u00b6 Allow the registration and management of Service Agreement Templates. Typically are not necessary by users, that can make use of the already pre-defined service agreement templates. Template Store Manager Template Store Library Agreement Template Condition Libraries \u00b6 Internal libraries allowing the management and support of conditions. Condition Store Manager Condition Store Library Condition Base Contract","title":"Smart Contracts"},{"location":"architecture/contracts/#nevermined-contracts-documentation","text":"The Nevermined Contracts are organized in different modules. Each of them is intended to keep different Solidity Smart Contracts code providing different building blocks or capabilities to implement the Nevermined Business Logic.","title":"Nevermined Contracts Documentation"},{"location":"architecture/contracts/#modules","text":"","title":"Modules"},{"location":"architecture/contracts/#registry","text":"It allows the registration of assets into a Nevermined network. The entry point for that is the DIDRegistry contract. It allows to The different contracts involved in the Registry module are: DID Registry DID Factory NFT Upgradeable DIDRegistry Library Provenance Registry","title":"Registry"},{"location":"architecture/contracts/#service-agreement-templates","text":"This are the templates used for the end users to define use cases or user flows. They implement a pre-defined user flow implementing a use case (like selling access to data). Every different service agreement template allows to create instances of their type by the users with custimzed conditions. The existing templates existing are: Access Template Compute Execution Template DID Sales Template NFT Sales Template NFT Access Template Dynamic Access Template A part of this, the agreements contracts module provide some internal components to manage the registering of service agreements on-chain. This contracts typically don't need be instantiated directly by end-users: Agreement Store Manager Agreement Store Library","title":"Service Agreement Templates"},{"location":"architecture/contracts/#service-agreement-conditions","text":"Are the different conditions allowing to the users of a flow to define the ground rules as part of an agreement. Conditions typically have different parameters allowing to the users to define the specific conditions that someone executing an agreement needs to fulfill. The combination of templates and agreements allow the definition of complex scenarios where the users can interact and transact regarding Nevermined digital assets. The existing conditions ready to be used are: Access Condition Lock Payment Condition Rewards Reward Escrow Payment Compute Execution Condition Hash Lock Condition NFT Access Condition NFT Holder Condition NFT Lock Condition Transfer DID Ownership Condition Transfer NFT Condition Sign Condition Whitelisting Condition Threshold Condition","title":"Service Agreement Conditions"},{"location":"architecture/contracts/#token","text":"This are the contracts providing the following capabilities: Nevermined Token - A reference implementation of a ERC20 token. This NVM token is provided as default token in a Nevermined deployment. The usage of this token is not necessary. A different ERC20 can be used depending on the deployment of the network or the configuration of the service agreements. This allows to support payments in the NVM token, a different ERC20 token or in ETH . Dispenser - It allows the distribution of ERC20 tokens (typically NVM token) in a testnet. Because of that, the Dispenser contract is not deployed in production or mainnet networks .","title":"Token"},{"location":"architecture/contracts/#libraries","text":"EpochLibrary HashListLibrary Common Hash List","title":"Libraries"},{"location":"architecture/contracts/#contract-interfaces","text":"IList ISecret Store ISecret Store Permission","title":"Contract Interfaces"},{"location":"architecture/contracts/#template-libraries","text":"Allow the registration and management of Service Agreement Templates. Typically are not necessary by users, that can make use of the already pre-defined service agreement templates. Template Store Manager Template Store Library Agreement Template","title":"Template Libraries"},{"location":"architecture/contracts/#condition-libraries","text":"Internal libraries allowing the management and support of conditions. Condition Store Manager Condition Store Library Condition Base Contract","title":"Condition Libraries"},{"location":"architecture/contracts/Packages/","text":"Packaging \u00b6 The following package describes how to package the Keeper Contracts in different formats. It is helpful to distribute the compiled smart contracts ABI's in different \"flavours\". It allows to import those ABI's from different languages enabling an easier interaction with the Keeper. Javascript (NPM) \u00b6 NPM packages are published as part of the Nevermined NPM organization . Github Actions is configured to release a new version of the nevermined-io/contracts NPM library after tagging. Versions of the library must be modified in the package.json file. { \"name\" : \"@nevermined-io/contracts\" , \"version\" : \"1.0.0\" , .. } Typically you can't overwrite NPM already published versions of the libraries. This package uses Semantic Versioning , so if you are testing with new versions, it's recommended to play with the patch numbers. If you need to build a local version of the package you need to run the following commands: npm install npm run build If you need to release a new version of the library before tagging, you need to execute the following command: npm publish --access public To do that you need to be an authorized user in the NPM Nevermined organization. Python \u00b6 Python packages are generated automatically in Pypi format: https://pypi.org/project/nevermined-contracts/ Java \u00b6 Java packages are generated automatically for JVM applications and published into Maven central: https://search.maven.org/artifact/io.keyko.nevermined/contracts","title":"Packaging"},{"location":"architecture/contracts/Packages/#packaging","text":"The following package describes how to package the Keeper Contracts in different formats. It is helpful to distribute the compiled smart contracts ABI's in different \"flavours\". It allows to import those ABI's from different languages enabling an easier interaction with the Keeper.","title":"Packaging"},{"location":"architecture/contracts/Packages/#javascript-npm","text":"NPM packages are published as part of the Nevermined NPM organization . Github Actions is configured to release a new version of the nevermined-io/contracts NPM library after tagging. Versions of the library must be modified in the package.json file. { \"name\" : \"@nevermined-io/contracts\" , \"version\" : \"1.0.0\" , .. } Typically you can't overwrite NPM already published versions of the libraries. This package uses Semantic Versioning , so if you are testing with new versions, it's recommended to play with the patch numbers. If you need to build a local version of the package you need to run the following commands: npm install npm run build If you need to release a new version of the library before tagging, you need to execute the following command: npm publish --access public To do that you need to be an authorized user in the NPM Nevermined organization.","title":"Javascript (NPM)"},{"location":"architecture/contracts/Packages/#python","text":"Python packages are generated automatically in Pypi format: https://pypi.org/project/nevermined-contracts/","title":"Python"},{"location":"architecture/contracts/Packages/#java","text":"Java packages are generated automatically for JVM applications and published into Maven central: https://search.maven.org/artifact/io.keyko.nevermined/contracts","title":"Java"},{"location":"architecture/contracts/ReleaseProcess/","text":"Release Process \u00b6 Build a new version \u00b6 The steps to build a new version are the following: Create a new local feature branch, e.g. git checkout -b release/v0.2.5 Use the bumpversion.sh script to bump the project version. You can execute the script using {major|minor|patch} as first argument to bump the version accordingly: To bump the patch version: ./bumpversion.sh patch To bump the minor version: ./bumpversion.sh minor To bump the major version: ./bumpversion.sh major assuming we are on version v0.2.4 and the desired version is v0.2.5 ./bumpversion.sh patch has to be run. run npm i to update the version in package-lock.json Interact with networks \u00b6 Roles \u00b6 We define four roles: deployer : represented as accounts[0] upgrader : represented as accounts[1] upgraderWallet : represented as the upgrader from wallets.json ownerWallet : represented as the owner from wallets.json Flags \u00b6 --testnet Deploys the Dispenser, the NeverminedToken and the contracts from contracts.json --with-token Deploys the NeverminedToken and the contracts from contracts.json Deployer \u00b6 Can be any account. It is used for deploying the initial proxy contracts and the logic contracts. Upgrader \u00b6 Has to be an owner of the upgrader multi sig wallet. It is used for issuing upgrade requests against the upgrader multi sig wallet. UpgraderWallet \u00b6 One instance of the multi sig wallet, defined as upgrader . This wallet will be assigned as zos admin and is required to do upgrades. OwnerWallet \u00b6 One instance of the multi sig wallet, defined as owner . This wallet will be assigned as the owner of all the contracts. It can be used to call specific functions in the contracts ie. change the configuration. Deploy & Upgrade \u00b6 run npm run clean to clean the work dir. run npm run compile to compile the contracts. Staging \u00b6 Copy the wallet file for staging cp wallets_staging.json wallets.json run export MNEMONIC=<your staging mnemonic> . You will find them in the password manager. Deploy the whole application \u00b6 To deploy all contracts run npm run deploy:staging Deploy a single contracts \u00b6 To deploy a single contract you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:staging -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser . Upgrade the whole application \u00b6 To upgrade all contracts run npm run upgrade:staging Upgrade a single contract \u00b6 To upgrade a single contract run npm run upgrade:staging -- NeverminedToken . For upgrading the NeverminedToken contract. Persist artifacts \u00b6 Commit all changes in artifacts/*.staging.json Kovan \u00b6 Copy the wallet file for kovan > cp wallets_kovan.json wallets.json run export MNEMONIC=<your kovan mnemonic> . You will find them in the password manager. run export INFURA_TOKEN=<your infura token> . You will get it from infura . Deploy the whole application \u00b6 To deploy all the contracts run npm run deploy:kovan Deploy a single contracts \u00b6 To deploy a single contracts you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:kovan -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser . Upgrade the whole application \u00b6 To upgrade all contracts run npm run upgrade:kovan Upgrade a single contract \u00b6 To upgrade a single contract run npm run upgrade:kovan -- NeverminedToken . For upgrading the NeverminedToken contract. Persist artifacts \u00b6 Commit all changes in artifacts/*.kovan.json Approve upgrades \u00b6 All upgrades of the contracts have to be approved by the upgrader wallet configured in the wallets.json file. go to https://wallet.gnosis.pm Load upgrader wallet Select an Ethereum Account that is an owner of the multi sig wallet, but not the one who issued the upgrade request. This can be done in the following ways: Connect to a local Blockchain node that holds the private key. Connect to MetaMask and select the owner account from the multi sig wallet. Connect a hardware wallet like ledger or trezor. Select the transaction you want to confirm (the upgrade script will tell you which transactions have to be approved in which wallets) Click Confirm Document \u00b6 Contracts documentation \u00b6 Update the contracts documentation run yarn doc:contracts Commit the changes in docs/contracts folder Address Documentation \u00b6 Update the addresses in the README.md run node ./scripts/contracts/get-addresses.js <network name> It will output the current proxy addresses in the README friendly format. | AccessCondition | v0.9.0 | 0x45DE141F8Efc355F1451a102FB6225F1EDd2921d | | AgreementStoreManager | v0.9.0 | 0x62f84700b1A0ea6Bfb505aDC3c0286B7944D247C | | ConditionStoreManager | v0.9.0 | 0x39b0AA775496C5ebf26f3B81C9ed1843f09eE466 | | DIDRegistry | v0.9.0 | 0x4A0f7F763B1A7937aED21D63b2A78adc89c5Db23 | | DIDRegistryLibrary | v0.9.0 | 0x3B3504908Db36f5D5f07CD420ee2BBBbDfB674cF | | Dispenser | v0.9.0 | 0x865396b7ddc58C693db7FCAD1168E3BD95Fe3368 | .... Copy this to the README.md Trigger CI \u00b6 Commit the missing changes to the feature branch. Tag the last commit with the new version number ie. v0.2.5 Push the feature branch to GitHub. Make a pull request from the just-pushed branch to develop branch. Wait for all the tests to pass! Merge the pull request into the develop branch. Release and packages \u00b6 The release itself is done by github actions based on the tagged commit. It will deploy the following components: npm pypi maven docker The npm, pypi and maven packages contain the contract artifacts for the contracts already deployed in different networks (such as Production , Staging , Testing , or Spree ). The docker image generated contains the contracts and script ready to be used to deploy the contracts to a network. It is used for deploying the contracts in the local network Spree in nevermined-io/tools Once the new version is tagged and released, you can edit the Releases section of GitHub with the information and changes about the new version (in the future, these will come from the changelog): Audit \u00b6 To check or document that all transactions have been approved in the multi sig wallet you can run npm run audit:staging to get a list of all the current transactions and their current status. Wallet: 0x24EB26D4042a2AB576E7E39b87c3f33f276AeF92 Transaction ID: 64 Destination: 0xfA16d26e9F4fffC6e40963B281a0bB08C31ed40C Contract: EscrowAccessSecretStoreTemplate Data is `upgradeTo` call: true Confirmed from: 0x7A13E1aD23546c9b804aDFd13e9AcB184EfCAF58 Executed: false","title":"Release Process"},{"location":"architecture/contracts/ReleaseProcess/#release-process","text":"","title":"Release Process"},{"location":"architecture/contracts/ReleaseProcess/#build-a-new-version","text":"The steps to build a new version are the following: Create a new local feature branch, e.g. git checkout -b release/v0.2.5 Use the bumpversion.sh script to bump the project version. You can execute the script using {major|minor|patch} as first argument to bump the version accordingly: To bump the patch version: ./bumpversion.sh patch To bump the minor version: ./bumpversion.sh minor To bump the major version: ./bumpversion.sh major assuming we are on version v0.2.4 and the desired version is v0.2.5 ./bumpversion.sh patch has to be run. run npm i to update the version in package-lock.json","title":"Build a new version"},{"location":"architecture/contracts/ReleaseProcess/#interact-with-networks","text":"","title":"Interact with networks"},{"location":"architecture/contracts/ReleaseProcess/#roles","text":"We define four roles: deployer : represented as accounts[0] upgrader : represented as accounts[1] upgraderWallet : represented as the upgrader from wallets.json ownerWallet : represented as the owner from wallets.json","title":"Roles"},{"location":"architecture/contracts/ReleaseProcess/#flags","text":"--testnet Deploys the Dispenser, the NeverminedToken and the contracts from contracts.json --with-token Deploys the NeverminedToken and the contracts from contracts.json","title":"Flags"},{"location":"architecture/contracts/ReleaseProcess/#deployer","text":"Can be any account. It is used for deploying the initial proxy contracts and the logic contracts.","title":"Deployer"},{"location":"architecture/contracts/ReleaseProcess/#upgrader","text":"Has to be an owner of the upgrader multi sig wallet. It is used for issuing upgrade requests against the upgrader multi sig wallet.","title":"Upgrader"},{"location":"architecture/contracts/ReleaseProcess/#upgraderwallet","text":"One instance of the multi sig wallet, defined as upgrader . This wallet will be assigned as zos admin and is required to do upgrades.","title":"UpgraderWallet"},{"location":"architecture/contracts/ReleaseProcess/#ownerwallet","text":"One instance of the multi sig wallet, defined as owner . This wallet will be assigned as the owner of all the contracts. It can be used to call specific functions in the contracts ie. change the configuration.","title":"OwnerWallet"},{"location":"architecture/contracts/ReleaseProcess/#deploy-upgrade","text":"run npm run clean to clean the work dir. run npm run compile to compile the contracts.","title":"Deploy &amp; Upgrade"},{"location":"architecture/contracts/ReleaseProcess/#staging","text":"Copy the wallet file for staging cp wallets_staging.json wallets.json run export MNEMONIC=<your staging mnemonic> . You will find them in the password manager.","title":"Staging"},{"location":"architecture/contracts/ReleaseProcess/#deploy-the-whole-application","text":"To deploy all contracts run npm run deploy:staging","title":"Deploy the whole application"},{"location":"architecture/contracts/ReleaseProcess/#deploy-a-single-contracts","text":"To deploy a single contract you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:staging -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser .","title":"Deploy a single contracts"},{"location":"architecture/contracts/ReleaseProcess/#upgrade-the-whole-application","text":"To upgrade all contracts run npm run upgrade:staging","title":"Upgrade the whole application"},{"location":"architecture/contracts/ReleaseProcess/#upgrade-a-single-contract","text":"To upgrade a single contract run npm run upgrade:staging -- NeverminedToken . For upgrading the NeverminedToken contract.","title":"Upgrade a single contract"},{"location":"architecture/contracts/ReleaseProcess/#persist-artifacts","text":"Commit all changes in artifacts/*.staging.json","title":"Persist artifacts"},{"location":"architecture/contracts/ReleaseProcess/#kovan","text":"Copy the wallet file for kovan > cp wallets_kovan.json wallets.json run export MNEMONIC=<your kovan mnemonic> . You will find them in the password manager. run export INFURA_TOKEN=<your infura token> . You will get it from infura .","title":"Kovan"},{"location":"architecture/contracts/ReleaseProcess/#deploy-the-whole-application_1","text":"To deploy all the contracts run npm run deploy:kovan","title":"Deploy the whole application"},{"location":"architecture/contracts/ReleaseProcess/#deploy-a-single-contracts_1","text":"To deploy a single contracts you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:kovan -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser .","title":"Deploy a single contracts"},{"location":"architecture/contracts/ReleaseProcess/#upgrade-the-whole-application_1","text":"To upgrade all contracts run npm run upgrade:kovan","title":"Upgrade the whole application"},{"location":"architecture/contracts/ReleaseProcess/#upgrade-a-single-contract_1","text":"To upgrade a single contract run npm run upgrade:kovan -- NeverminedToken . For upgrading the NeverminedToken contract.","title":"Upgrade a single contract"},{"location":"architecture/contracts/ReleaseProcess/#persist-artifacts_1","text":"Commit all changes in artifacts/*.kovan.json","title":"Persist artifacts"},{"location":"architecture/contracts/ReleaseProcess/#approve-upgrades","text":"All upgrades of the contracts have to be approved by the upgrader wallet configured in the wallets.json file. go to https://wallet.gnosis.pm Load upgrader wallet Select an Ethereum Account that is an owner of the multi sig wallet, but not the one who issued the upgrade request. This can be done in the following ways: Connect to a local Blockchain node that holds the private key. Connect to MetaMask and select the owner account from the multi sig wallet. Connect a hardware wallet like ledger or trezor. Select the transaction you want to confirm (the upgrade script will tell you which transactions have to be approved in which wallets) Click Confirm","title":"Approve upgrades"},{"location":"architecture/contracts/ReleaseProcess/#document","text":"","title":"Document"},{"location":"architecture/contracts/ReleaseProcess/#contracts-documentation","text":"Update the contracts documentation run yarn doc:contracts Commit the changes in docs/contracts folder","title":"Contracts documentation"},{"location":"architecture/contracts/ReleaseProcess/#address-documentation","text":"Update the addresses in the README.md run node ./scripts/contracts/get-addresses.js <network name> It will output the current proxy addresses in the README friendly format. | AccessCondition | v0.9.0 | 0x45DE141F8Efc355F1451a102FB6225F1EDd2921d | | AgreementStoreManager | v0.9.0 | 0x62f84700b1A0ea6Bfb505aDC3c0286B7944D247C | | ConditionStoreManager | v0.9.0 | 0x39b0AA775496C5ebf26f3B81C9ed1843f09eE466 | | DIDRegistry | v0.9.0 | 0x4A0f7F763B1A7937aED21D63b2A78adc89c5Db23 | | DIDRegistryLibrary | v0.9.0 | 0x3B3504908Db36f5D5f07CD420ee2BBBbDfB674cF | | Dispenser | v0.9.0 | 0x865396b7ddc58C693db7FCAD1168E3BD95Fe3368 | .... Copy this to the README.md","title":"Address Documentation"},{"location":"architecture/contracts/ReleaseProcess/#trigger-ci","text":"Commit the missing changes to the feature branch. Tag the last commit with the new version number ie. v0.2.5 Push the feature branch to GitHub. Make a pull request from the just-pushed branch to develop branch. Wait for all the tests to pass! Merge the pull request into the develop branch.","title":"Trigger CI"},{"location":"architecture/contracts/ReleaseProcess/#release-and-packages","text":"The release itself is done by github actions based on the tagged commit. It will deploy the following components: npm pypi maven docker The npm, pypi and maven packages contain the contract artifacts for the contracts already deployed in different networks (such as Production , Staging , Testing , or Spree ). The docker image generated contains the contracts and script ready to be used to deploy the contracts to a network. It is used for deploying the contracts in the local network Spree in nevermined-io/tools Once the new version is tagged and released, you can edit the Releases section of GitHub with the information and changes about the new version (in the future, these will come from the changelog):","title":"Release and packages"},{"location":"architecture/contracts/ReleaseProcess/#audit","text":"To check or document that all transactions have been approved in the multi sig wallet you can run npm run audit:staging to get a list of all the current transactions and their current status. Wallet: 0x24EB26D4042a2AB576E7E39b87c3f33f276AeF92 Transaction ID: 64 Destination: 0xfA16d26e9F4fffC6e40963B281a0bB08C31ed40C Contract: EscrowAccessSecretStoreTemplate Data is `upgradeTo` call: true Confirmed from: 0x7A13E1aD23546c9b804aDFd13e9AcB184EfCAF58 Executed: false","title":"Audit"},{"location":"architecture/contracts/Upgrades/","text":"Upgrade Process \u00b6 This documents explains in detail how nevermined-contracts should be deployed using zeppelinOS and how the contracts can be upgraded. The latest section describes the test procedure. Quickstart \u00b6 The first step to work with zos is to install dependencies then initialize the project. Then compile contracts and add contracts to the project. Finally push the contracts into the network and create the upgradable instances. Once the contracts are deployed they can be tested and upgraded. Also we change the proxy administrator to a MultiSignature wallet to approve upgrades. We are going to use the Nevermined Contract Tools in order to perform any future deployments/upgrades. Details \u00b6 Here we provide more details into each step of the initial deploy and the approach of upgradeability and governance. Roles \u00b6 Before going into more details about the deployment. We should differentiate between different roles in the system which govern the upgradeability in nevermined-contracts. Roles are defined as follows: deployer: represented as accounts[0] upgrader: represented as accounts[1] upgraderWallet: represented as the upgrader from wallets.json ownerWallet: represented as the owner from wallets.json - Deployer : Can be any account. It is used for deploying the initial proxy contracts and the logic contracts . Upgrader : Has to be an owner of the upgrader multi sig wallet. It is used for issuing upgrade requests against the upgrader multi sig wallet. UpgraderWallet : One instance of the multi sig wallet, defined as upgrader . This wallet will be assigned as zos admin and is required to do upgrades. OwnerWallet : One instance of the multi sig wallet, defined as owner . This wallet will be assigned as the owner of all the contracts. It can be used to call specific functions in the contracts ie. change the configuration. Deploy & Upgrade \u00b6 zos does not support migrations, hence all the initial configuration should be performed with Nevermined Contract Tools . Contract constructors are ignored so the initial setup of the contract should be made in a initialize function that will be executed only once after the initial deployment. 1. Configuration \u00b6 Nevermined Contract Tools checks the contracts.json in order to detect the current contracts that are going to be deployed: [ \"ConditionStoreManager\" , \"TemplateStoreManager\" , \"AgreementStoreManager\" , \"SignCondition\" , \"HashLockCondition\" , \"LockRewardCondition\" , \"NFTHolderCondition\" , \"AccessCondition\" , \"EscrowReward\" , \"EscrowAccessSecretStoreTemplate\" , \"NFTAccessTemplate\" , \"DIDRegistry\" ] Moreover for each network, Nevermined Contract Tools needs to detect the roles and their addresses from a pre-defined wallets config file. The following configuration should be an example for wallets-<NETWORK_NAME>.json : [ { \"name\" : \"upgrader\" , \"address\" : \"0x24eb26d4042a2ab576e7e39b87c3f33f276aef92\" }, { \"name\" : \"owner\" , \"address\" : \"0xd02d68c62401472ce35ba3c7e505deae62db2b8b\" } ] 2. Preparation \u00b6 The following commands clean, install dependencies and compile the contracts: $ npm run clean #to clean the work dir $ npm i #install dependencies $ npm run compile #to compile the contracts 3. Deploy & Upgrade \u00b6 The following steps shows how to perform contracts deployment and upgrade on Rinkeby and Kovan networks. Nile \u00b6 Copy the wallet file for rinkeby cp wallets_rinkeby.json wallets.json run export MNEMONIC=<your staging mnemonic> . You will find them in the password manager. Deploy the whole application \u00b6 To deploy all contracts run npm run deploy:rinkeby Deploy a single contracts \u00b6 To deploy a single contract you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:rinkeby -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser . Upgrade the whole application \u00b6 To upgrade all contracts run npm run upgrade:rinkeby Upgrade a single contract \u00b6 To upgrade a single contract run npm run upgrade:rinkeby -- NeverminedToken . For upgrading the NeverminedToken contract. Persist artifacts \u00b6 Commit all changes in artifacts/*.rinkeby.json Kovan \u00b6 Copy the wallet file for kovan > cp wallets_kovan.json wallets.json run export MNEMONIC=<your kovan mnemonic> . You will find them in the password manager. run export INFURA_TOKEN=<your infura token> . You will get it from infura . Deploy the whole application \u00b6 To deploy all the contracts run npm run deploy:kovan Deploy a single contracts \u00b6 To deploy a single contracts you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:kovan -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser . Upgrade the whole application \u00b6 To upgrade all contracts run npm run upgrade:kovan Upgrade a single contract \u00b6 To upgrade a single contract run npm run upgrade:kovan -- NeverminedToken . For upgrading the NeverminedToken contract. Persist artifacts \u00b6 Commit all changes in artifacts/*.kovan.json 4. Approve Upgrade(s) \u00b6 All upgrades of the contracts have to be approved by the upgrader wallet configured in the wallets.json file. go to https://wallet.gnosis.pm Load upgrader wallet Select an Ethereum Account that is an owner of the multi sig wallet, but not the one who issued the upgrade request. This can be done in the following ways: Connect to a local Blockchain node that holds the private key. Connect to MetaMask and select the owner account from the multi sig wallet. Connect a hardware wallet like ledger or trezor. Select the transaction you want to confirm (the upgrade script will tell you which transactions have to be approved in which wallets) Click Confirm 5. Audit Contracts \u00b6 To check or document that all transactions have been approved in the multi sig wallet you can run npm run audit:rinkeby to get a list of all the current transactions and their current status. Wallet: 0x24EB26D4042a2AB576E7E39b87c3f33f276AeF92 Transaction ID: 64 Destination: 0xfA16d26e9F4fffC6e40963B281a0bB08C31ed40C Contract: EscrowAccessSecretStoreTemplate Data is `upgradeTo` call: true Confirmed from: 0x7A13E1aD23546c9b804aDFd13e9AcB184EfCAF58 Executed: false 6. Documentation \u00b6 Update the addresses in the README.md run node ./scripts/contracts/get-addresses.js <network name> It will output the current proxy addresses in the README friendly format. | AccessCondition | v0.9.0 | 0x45DE141F8Efc355F1451a102FB6225F1EDd2921d | | AgreementStoreManager | v0.9.0 | 0x62f84700b1A0ea6Bfb505aDC3c0286B7944D247C | | ConditionStoreManager | v0.9.0 | 0x39b0AA775496C5ebf26f3B81C9ed1843f09eE466 | | DIDRegistry | v0.9.0 | 0x4A0f7F763B1A7937aED21D63b2A78adc89c5Db23 | | DIDRegistryLibrary | v0.9.0 | 0x3B3504908Db36f5D5f07CD420ee2BBBbDfB674cF | | Dispenser | v0.9.0 | 0x865396b7ddc58C693db7FCAD1168E3BD95Fe3368 | .... Copy this to the README.md","title":"Upgrade Process"},{"location":"architecture/contracts/Upgrades/#upgrade-process","text":"This documents explains in detail how nevermined-contracts should be deployed using zeppelinOS and how the contracts can be upgraded. The latest section describes the test procedure.","title":"Upgrade Process"},{"location":"architecture/contracts/Upgrades/#quickstart","text":"The first step to work with zos is to install dependencies then initialize the project. Then compile contracts and add contracts to the project. Finally push the contracts into the network and create the upgradable instances. Once the contracts are deployed they can be tested and upgraded. Also we change the proxy administrator to a MultiSignature wallet to approve upgrades. We are going to use the Nevermined Contract Tools in order to perform any future deployments/upgrades.","title":"Quickstart"},{"location":"architecture/contracts/Upgrades/#details","text":"Here we provide more details into each step of the initial deploy and the approach of upgradeability and governance.","title":"Details"},{"location":"architecture/contracts/Upgrades/#roles","text":"Before going into more details about the deployment. We should differentiate between different roles in the system which govern the upgradeability in nevermined-contracts. Roles are defined as follows: deployer: represented as accounts[0] upgrader: represented as accounts[1] upgraderWallet: represented as the upgrader from wallets.json ownerWallet: represented as the owner from wallets.json - Deployer : Can be any account. It is used for deploying the initial proxy contracts and the logic contracts . Upgrader : Has to be an owner of the upgrader multi sig wallet. It is used for issuing upgrade requests against the upgrader multi sig wallet. UpgraderWallet : One instance of the multi sig wallet, defined as upgrader . This wallet will be assigned as zos admin and is required to do upgrades. OwnerWallet : One instance of the multi sig wallet, defined as owner . This wallet will be assigned as the owner of all the contracts. It can be used to call specific functions in the contracts ie. change the configuration.","title":"Roles"},{"location":"architecture/contracts/Upgrades/#deploy-upgrade","text":"zos does not support migrations, hence all the initial configuration should be performed with Nevermined Contract Tools . Contract constructors are ignored so the initial setup of the contract should be made in a initialize function that will be executed only once after the initial deployment.","title":"Deploy &amp; Upgrade"},{"location":"architecture/contracts/Upgrades/#1-configuration","text":"Nevermined Contract Tools checks the contracts.json in order to detect the current contracts that are going to be deployed: [ \"ConditionStoreManager\" , \"TemplateStoreManager\" , \"AgreementStoreManager\" , \"SignCondition\" , \"HashLockCondition\" , \"LockRewardCondition\" , \"NFTHolderCondition\" , \"AccessCondition\" , \"EscrowReward\" , \"EscrowAccessSecretStoreTemplate\" , \"NFTAccessTemplate\" , \"DIDRegistry\" ] Moreover for each network, Nevermined Contract Tools needs to detect the roles and their addresses from a pre-defined wallets config file. The following configuration should be an example for wallets-<NETWORK_NAME>.json : [ { \"name\" : \"upgrader\" , \"address\" : \"0x24eb26d4042a2ab576e7e39b87c3f33f276aef92\" }, { \"name\" : \"owner\" , \"address\" : \"0xd02d68c62401472ce35ba3c7e505deae62db2b8b\" } ]","title":"1. Configuration"},{"location":"architecture/contracts/Upgrades/#2-preparation","text":"The following commands clean, install dependencies and compile the contracts: $ npm run clean #to clean the work dir $ npm i #install dependencies $ npm run compile #to compile the contracts","title":"2. Preparation"},{"location":"architecture/contracts/Upgrades/#3-deploy-upgrade","text":"The following steps shows how to perform contracts deployment and upgrade on Rinkeby and Kovan networks.","title":"3. Deploy &amp; Upgrade"},{"location":"architecture/contracts/Upgrades/#nile","text":"Copy the wallet file for rinkeby cp wallets_rinkeby.json wallets.json run export MNEMONIC=<your staging mnemonic> . You will find them in the password manager.","title":"Nile"},{"location":"architecture/contracts/Upgrades/#deploy-the-whole-application","text":"To deploy all contracts run npm run deploy:rinkeby","title":"Deploy the whole application"},{"location":"architecture/contracts/Upgrades/#deploy-a-single-contracts","text":"To deploy a single contract you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:rinkeby -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser .","title":"Deploy a single contracts"},{"location":"architecture/contracts/Upgrades/#upgrade-the-whole-application","text":"To upgrade all contracts run npm run upgrade:rinkeby","title":"Upgrade the whole application"},{"location":"architecture/contracts/Upgrades/#upgrade-a-single-contract","text":"To upgrade a single contract run npm run upgrade:rinkeby -- NeverminedToken . For upgrading the NeverminedToken contract.","title":"Upgrade a single contract"},{"location":"architecture/contracts/Upgrades/#persist-artifacts","text":"Commit all changes in artifacts/*.rinkeby.json","title":"Persist artifacts"},{"location":"architecture/contracts/Upgrades/#kovan","text":"Copy the wallet file for kovan > cp wallets_kovan.json wallets.json run export MNEMONIC=<your kovan mnemonic> . You will find them in the password manager. run export INFURA_TOKEN=<your infura token> . You will get it from infura .","title":"Kovan"},{"location":"architecture/contracts/Upgrades/#deploy-the-whole-application_1","text":"To deploy all the contracts run npm run deploy:kovan","title":"Deploy the whole application"},{"location":"architecture/contracts/Upgrades/#deploy-a-single-contracts_1","text":"To deploy a single contracts you need to specify the contracts to deploy as a parameter to the deploy script: ie. npm run deploy:kovan -- NeverminedToken Dispenser will deploy NeverminedToken and Dispenser .","title":"Deploy a single contracts"},{"location":"architecture/contracts/Upgrades/#upgrade-the-whole-application_1","text":"To upgrade all contracts run npm run upgrade:kovan","title":"Upgrade the whole application"},{"location":"architecture/contracts/Upgrades/#upgrade-a-single-contract_1","text":"To upgrade a single contract run npm run upgrade:kovan -- NeverminedToken . For upgrading the NeverminedToken contract.","title":"Upgrade a single contract"},{"location":"architecture/contracts/Upgrades/#persist-artifacts_1","text":"Commit all changes in artifacts/*.kovan.json","title":"Persist artifacts"},{"location":"architecture/contracts/Upgrades/#4-approve-upgrades","text":"All upgrades of the contracts have to be approved by the upgrader wallet configured in the wallets.json file. go to https://wallet.gnosis.pm Load upgrader wallet Select an Ethereum Account that is an owner of the multi sig wallet, but not the one who issued the upgrade request. This can be done in the following ways: Connect to a local Blockchain node that holds the private key. Connect to MetaMask and select the owner account from the multi sig wallet. Connect a hardware wallet like ledger or trezor. Select the transaction you want to confirm (the upgrade script will tell you which transactions have to be approved in which wallets) Click Confirm","title":"4. Approve Upgrade(s)"},{"location":"architecture/contracts/Upgrades/#5-audit-contracts","text":"To check or document that all transactions have been approved in the multi sig wallet you can run npm run audit:rinkeby to get a list of all the current transactions and their current status. Wallet: 0x24EB26D4042a2AB576E7E39b87c3f33f276AeF92 Transaction ID: 64 Destination: 0xfA16d26e9F4fffC6e40963B281a0bB08C31ed40C Contract: EscrowAccessSecretStoreTemplate Data is `upgradeTo` call: true Confirmed from: 0x7A13E1aD23546c9b804aDFd13e9AcB184EfCAF58 Executed: false","title":"5. Audit Contracts"},{"location":"architecture/contracts/Upgrades/#6-documentation","text":"Update the addresses in the README.md run node ./scripts/contracts/get-addresses.js <network name> It will output the current proxy addresses in the README friendly format. | AccessCondition | v0.9.0 | 0x45DE141F8Efc355F1451a102FB6225F1EDd2921d | | AgreementStoreManager | v0.9.0 | 0x62f84700b1A0ea6Bfb505aDC3c0286B7944D247C | | ConditionStoreManager | v0.9.0 | 0x39b0AA775496C5ebf26f3B81C9ed1843f09eE466 | | DIDRegistry | v0.9.0 | 0x4A0f7F763B1A7937aED21D63b2A78adc89c5Db23 | | DIDRegistryLibrary | v0.9.0 | 0x3B3504908Db36f5D5f07CD420ee2BBBbDfB674cF | | Dispenser | v0.9.0 | 0x865396b7ddc58C693db7FCAD1168E3BD95Fe3368 | .... Copy this to the README.md","title":"6. Documentation"},{"location":"architecture/contracts/contracts/Common/","text":"Functions \u00b6 getCurrentBlockNumber \u00b6 function getCurrentBlockNumber ( ) external returns ( uint256 ) getCurrentBlockNumber get block number Return Values: \u00b6 Name Type Description the current block number ### isContract function isContract ( ) public returns ( bool ) isContract detect whether the address is is a contract address or externally owned account Return Values: \u00b6 Name Type Description true address if it is a contract address ### provenanceSignatureIsCorrect function provenanceSignatureIsCorrect ( address _agentId , bytes32 _hash , bytes _signature ) public returns ( bool ) Parameters: \u00b6 Name Type Description _agentId address The address of the agent _hash bytes32 bytes32 message, the hash is the signed message. What is recovered is the signer address. _signature bytes Signatures provided by the agent Return Values: \u00b6 Name Type Description true address if the signature correspond to the agent address ### calculateTotalAmount function calculateTotalAmount ( ) public returns ( uint256 ) Sum the total amount given an uint array Return Values: \u00b6 Name Type Description the uint256[] total amount","title":"Common"},{"location":"architecture/contracts/contracts/Common/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/Common/#getcurrentblocknumber","text":"function getCurrentBlockNumber ( ) external returns ( uint256 ) getCurrentBlockNumber get block number","title":"getCurrentBlockNumber"},{"location":"architecture/contracts/contracts/Common/#return-values","text":"Name Type Description the current block number ### isContract function isContract ( ) public returns ( bool ) isContract detect whether the address is is a contract address or externally owned account","title":"Return Values:"},{"location":"architecture/contracts/contracts/Common/#return-values_1","text":"Name Type Description true address if it is a contract address ### provenanceSignatureIsCorrect function provenanceSignatureIsCorrect ( address _agentId , bytes32 _hash , bytes _signature ) public returns ( bool )","title":"Return Values:"},{"location":"architecture/contracts/contracts/Common/#parameters","text":"Name Type Description _agentId address The address of the agent _hash bytes32 bytes32 message, the hash is the signed message. What is recovered is the signer address. _signature bytes Signatures provided by the agent","title":"Parameters:"},{"location":"architecture/contracts/contracts/Common/#return-values_2","text":"Name Type Description true address if the signature correspond to the agent address ### calculateTotalAmount function calculateTotalAmount ( ) public returns ( uint256 ) Sum the total amount given an uint array","title":"Return Values:"},{"location":"architecture/contracts/contracts/Common/#return-values_3","text":"Name Type Description the uint256[] total amount","title":"Return Values:"},{"location":"architecture/contracts/contracts/Dispenser/","text":"Functions \u00b6 initialize \u00b6 function initialize ( address _tokenAddress , address _owner ) external Dispenser Initializer Parameters: \u00b6 Name Type Description _tokenAddress address The deployed contract address of an ERC20 _owner address The owner of the Dispenser Runs only on initial contract creation. requestTokens \u00b6 function requestTokens ( uint256 amount ) external returns ( bool tokensTransferred ) user can request some tokens for testing Parameters: \u00b6 Name Type Description amount uint256 the amount of tokens to be requested Return Values: \u00b6 Name Type Description tokensTransferred uint256 Boolean indication of tokens are requested ### setMinPeriod function setMinPeriod ( uint256 period ) external the Owner can set the min period for token requests Parameters: \u00b6 Name Type Description period uint256 the min amount of time before next request setMaxAmount \u00b6 function setMaxAmount ( uint256 amount ) external the Owner can set the max amount for token requests Parameters: \u00b6 Name Type Description amount uint256 the max amount of tokens that can be requested setMaxMintAmount \u00b6 function setMaxMintAmount ( uint256 amount ) external the Owner can set the max amount for token requests Parameters: \u00b6 Name Type Description amount uint256 the max amount of tokens that can be requested Events \u00b6 RequestFrequencyExceeded \u00b6 event RequestFrequencyExceeded ( ) RequestLimitExceeded \u00b6 event RequestLimitExceeded ( )","title":"Dispenser"},{"location":"architecture/contracts/contracts/Dispenser/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/Dispenser/#initialize","text":"function initialize ( address _tokenAddress , address _owner ) external Dispenser Initializer","title":"initialize"},{"location":"architecture/contracts/contracts/Dispenser/#parameters","text":"Name Type Description _tokenAddress address The deployed contract address of an ERC20 _owner address The owner of the Dispenser Runs only on initial contract creation.","title":"Parameters:"},{"location":"architecture/contracts/contracts/Dispenser/#requesttokens","text":"function requestTokens ( uint256 amount ) external returns ( bool tokensTransferred ) user can request some tokens for testing","title":"requestTokens"},{"location":"architecture/contracts/contracts/Dispenser/#parameters_1","text":"Name Type Description amount uint256 the amount of tokens to be requested","title":"Parameters:"},{"location":"architecture/contracts/contracts/Dispenser/#return-values","text":"Name Type Description tokensTransferred uint256 Boolean indication of tokens are requested ### setMinPeriod function setMinPeriod ( uint256 period ) external the Owner can set the min period for token requests","title":"Return Values:"},{"location":"architecture/contracts/contracts/Dispenser/#parameters_2","text":"Name Type Description period uint256 the min amount of time before next request","title":"Parameters:"},{"location":"architecture/contracts/contracts/Dispenser/#setmaxamount","text":"function setMaxAmount ( uint256 amount ) external the Owner can set the max amount for token requests","title":"setMaxAmount"},{"location":"architecture/contracts/contracts/Dispenser/#parameters_3","text":"Name Type Description amount uint256 the max amount of tokens that can be requested","title":"Parameters:"},{"location":"architecture/contracts/contracts/Dispenser/#setmaxmintamount","text":"function setMaxMintAmount ( uint256 amount ) external the Owner can set the max amount for token requests","title":"setMaxMintAmount"},{"location":"architecture/contracts/contracts/Dispenser/#parameters_4","text":"Name Type Description amount uint256 the max amount of tokens that can be requested","title":"Parameters:"},{"location":"architecture/contracts/contracts/Dispenser/#events","text":"","title":"Events"},{"location":"architecture/contracts/contracts/Dispenser/#requestfrequencyexceeded","text":"event RequestFrequencyExceeded ( )","title":"RequestFrequencyExceeded"},{"location":"architecture/contracts/contracts/Dispenser/#requestlimitexceeded","text":"event RequestLimitExceeded ( )","title":"RequestLimitExceeded"},{"location":"architecture/contracts/contracts/HashLists/","text":"Hash lists contract is a sample list contract in which uses HashListLibrary.sol in order to store, retrieve, remove, and update bytes32 values in hash lists. This is a reference implementation for IList interface. It is used for whitelisting condition. Any entity can have its own implementation of the interface in which could be used for the same condition. Functions \u00b6 initialize \u00b6 function initialize ( address _owner ) public HashLists Initializer Parameters: \u00b6 Name Type Description _owner address The owner of the hash list Runs only upon contract creation. hash \u00b6 function hash ( address account ) public returns ( bytes32 ) hash ethereum accounts Parameters: \u00b6 Name Type Description account address Ethereum address Return Values: \u00b6 Name Type Description bytes32 address hash of the account ### add function add ( bytes32 [] values ) external returns ( bool ) put an array of elements without indexing this meant to save gas in case of large arrays Parameters: \u00b6 Name Type Description values bytes32[] is an array of elements value Return Values: \u00b6 Name Type Description true bytes32[] if values are added successfully ### add function add ( bytes32 value ) external returns ( bool ) add indexes an element then adds it to a list Parameters: \u00b6 Name Type Description value bytes32 is a bytes32 value Return Values: \u00b6 Name Type Description true bytes32 if value is added successfully ### update function update ( bytes32 oldValue , bytes32 newValue ) external returns ( bool ) update the value with a new value and maintain indices Parameters: \u00b6 Name Type Description oldValue bytes32 is an element value in a list newValue bytes32 new value Return Values: \u00b6 Name Type Description true bytes32 if value is updated successfully ### index function index ( uint256 from , uint256 to ) external returns ( bool ) index is used to map each element value to its index on the list Parameters: \u00b6 Name Type Description from uint256 index is where to 'from' indexing in the list to uint256 index is where to stop indexing Return Values: \u00b6 Name Type Description true uint256 if the sub list is indexed ### has function has ( bytes32 id , bytes32 value ) external returns ( bool ) has checks whether a value is exist Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) value bytes32 is element value in list Return Values: \u00b6 Name Type Description true bytes32 if the value exists ### has function has ( bytes32 value ) external returns ( bool ) has checks whether a value is exist Parameters: \u00b6 Name Type Description value bytes32 is element value in list Return Values: \u00b6 Name Type Description true bytes32 if the value exists ### remove function remove ( bytes32 value ) external returns ( bool ) remove value from a list, updates indices, and list size Parameters: \u00b6 Name Type Description value bytes32 is an element value in a list Return Values: \u00b6 Name Type Description true bytes32 if value is removed successfully ### get function get ( bytes32 id , uint256 _index ) external returns ( bytes32 ) has value by index Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) _index uint256 is where is value is stored in the list Return Values: \u00b6 Name Type Description the bytes32 value if exists ### size function size ( bytes32 id ) external returns ( uint256 ) size gets the list size Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) Return Values: \u00b6 Name Type Description total bytes32 length of the list ### all function all ( bytes32 id ) external returns ( bytes32 []) all returns all list elements Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) Return Values: \u00b6 Name Type Description all bytes32 list elements ### indexOf function indexOf ( bytes32 id , bytes32 value ) external returns ( uint256 ) indexOf gets the index of a value in a list Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) value bytes32 is element value in list Return Values: \u00b6 Name Type Description value bytes32 index in list ### ownedBy function ownedBy ( bytes32 id ) external returns ( address ) ownedBy gets the list owner Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) Return Values: \u00b6 Name Type Description list bytes32 owner ### isIndexed function isIndexed ( bytes32 id ) external returns ( bool ) isIndexed checks if the list is indexed Parameters: \u00b6 Name Type Description id bytes32 the list identifier (the hash of list owner's address) Return Values: \u00b6 Name Type Description true bytes32 if the list is indexed","title":"HashLists"},{"location":"architecture/contracts/contracts/HashLists/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/HashLists/#initialize","text":"function initialize ( address _owner ) public HashLists Initializer","title":"initialize"},{"location":"architecture/contracts/contracts/HashLists/#parameters","text":"Name Type Description _owner address The owner of the hash list Runs only upon contract creation.","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#hash","text":"function hash ( address account ) public returns ( bytes32 ) hash ethereum accounts","title":"hash"},{"location":"architecture/contracts/contracts/HashLists/#parameters_1","text":"Name Type Description account address Ethereum address","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values","text":"Name Type Description bytes32 address hash of the account ### add function add ( bytes32 [] values ) external returns ( bool ) put an array of elements without indexing this meant to save gas in case of large arrays","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_2","text":"Name Type Description values bytes32[] is an array of elements value","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_1","text":"Name Type Description true bytes32[] if values are added successfully ### add function add ( bytes32 value ) external returns ( bool ) add indexes an element then adds it to a list","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_3","text":"Name Type Description value bytes32 is a bytes32 value","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_2","text":"Name Type Description true bytes32 if value is added successfully ### update function update ( bytes32 oldValue , bytes32 newValue ) external returns ( bool ) update the value with a new value and maintain indices","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_4","text":"Name Type Description oldValue bytes32 is an element value in a list newValue bytes32 new value","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_3","text":"Name Type Description true bytes32 if value is updated successfully ### index function index ( uint256 from , uint256 to ) external returns ( bool ) index is used to map each element value to its index on the list","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_5","text":"Name Type Description from uint256 index is where to 'from' indexing in the list to uint256 index is where to stop indexing","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_4","text":"Name Type Description true uint256 if the sub list is indexed ### has function has ( bytes32 id , bytes32 value ) external returns ( bool ) has checks whether a value is exist","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_6","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address) value bytes32 is element value in list","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_5","text":"Name Type Description true bytes32 if the value exists ### has function has ( bytes32 value ) external returns ( bool ) has checks whether a value is exist","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_7","text":"Name Type Description value bytes32 is element value in list","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_6","text":"Name Type Description true bytes32 if the value exists ### remove function remove ( bytes32 value ) external returns ( bool ) remove value from a list, updates indices, and list size","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_8","text":"Name Type Description value bytes32 is an element value in a list","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_7","text":"Name Type Description true bytes32 if value is removed successfully ### get function get ( bytes32 id , uint256 _index ) external returns ( bytes32 ) has value by index","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_9","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address) _index uint256 is where is value is stored in the list","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_8","text":"Name Type Description the bytes32 value if exists ### size function size ( bytes32 id ) external returns ( uint256 ) size gets the list size","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_10","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address)","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_9","text":"Name Type Description total bytes32 length of the list ### all function all ( bytes32 id ) external returns ( bytes32 []) all returns all list elements","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_11","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address)","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_10","text":"Name Type Description all bytes32 list elements ### indexOf function indexOf ( bytes32 id , bytes32 value ) external returns ( uint256 ) indexOf gets the index of a value in a list","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_12","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address) value bytes32 is element value in list","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_11","text":"Name Type Description value bytes32 index in list ### ownedBy function ownedBy ( bytes32 id ) external returns ( address ) ownedBy gets the list owner","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_13","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address)","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_12","text":"Name Type Description list bytes32 owner ### isIndexed function isIndexed ( bytes32 id ) external returns ( bool ) isIndexed checks if the list is indexed","title":"Return Values:"},{"location":"architecture/contracts/contracts/HashLists/#parameters_14","text":"Name Type Description id bytes32 the list identifier (the hash of list owner's address)","title":"Parameters:"},{"location":"architecture/contracts/contracts/HashLists/#return-values_13","text":"Name Type Description true bytes32 if the list is indexed","title":"Return Values:"},{"location":"architecture/contracts/contracts/NeverminedToken/","text":"Implementation of a Test Token. Test Token is an ERC20 token only for testing purposes Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address payable _initialMinter ) public NeverminedToken Initializer Runs only on initial contract creation. Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract _initialMinter address payable is the first token minter added _beforeTokenTransfer \u00b6 function _beforeTokenTransfer ( ) internal See {ERC20-_beforeTokenTransfer}. Requirements: minted tokens must not cause the total supply to go over the cap. mint \u00b6 function mint ( ) external returns ( bool ) Creates amount tokens and assigns them to account , increasing the total supply. Emits a {Transfer} event with from set to the zero address. Requirements: to cannot be the zero address.","title":"NeverminedToken"},{"location":"architecture/contracts/contracts/NeverminedToken/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/NeverminedToken/#initialize","text":"function initialize ( address _owner , address payable _initialMinter ) public NeverminedToken Initializer Runs only on initial contract creation.","title":"initialize"},{"location":"architecture/contracts/contracts/NeverminedToken/#parameters","text":"Name Type Description _owner address refers to the owner of the contract _initialMinter address payable is the first token minter added","title":"Parameters:"},{"location":"architecture/contracts/contracts/NeverminedToken/#_beforetokentransfer","text":"function _beforeTokenTransfer ( ) internal See {ERC20-_beforeTokenTransfer}. Requirements: minted tokens must not cause the total supply to go over the cap.","title":"_beforeTokenTransfer"},{"location":"architecture/contracts/contracts/NeverminedToken/#mint","text":"function mint ( ) external returns ( bool ) Creates amount tokens and assigns them to account , increasing the total supply. Emits a {Transfer} event with from set to the zero address. Requirements: to cannot be the zero address.","title":"mint"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreLibrary/","text":"Implementation of the Agreement Store Library. For more information: https://github.com/oceanprotocol/OEPs/issues/125 TODO: update the OEP link The agreement store library holds the business logic in which manages the life cycle of SEA agreement, each agreement is linked to the DID of an asset, template, and condition IDs. Functions \u00b6 create \u00b6 function create ( struct AgreementStoreLibrary . AgreementList _self , bytes32 _id , bytes32 _did , address _templateId , bytes32 [] _conditionIds ) internal returns ( uint256 size ) create new agreement checks whether the agreement Id exists, creates new agreement instance, including the template, conditions and DID. Parameters: \u00b6 Name Type Description _self struct AgreementStoreLibrary.AgreementList is AgreementList storage pointer _id bytes32 agreement identifier _did bytes32 asset decentralized identifier _templateId address template identifier _conditionIds bytes32[] array of condition identifiers Return Values: \u00b6 Name Type Description size struct AgreementStoreLibrary.AgreementList which is the index of the created agreement","title":"AgreementStoreLibrary"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreLibrary/#create","text":"function create ( struct AgreementStoreLibrary . AgreementList _self , bytes32 _id , bytes32 _did , address _templateId , bytes32 [] _conditionIds ) internal returns ( uint256 size ) create new agreement checks whether the agreement Id exists, creates new agreement instance, including the template, conditions and DID.","title":"create"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreLibrary/#parameters","text":"Name Type Description _self struct AgreementStoreLibrary.AgreementList is AgreementList storage pointer _id bytes32 agreement identifier _did bytes32 asset decentralized identifier _templateId address template identifier _conditionIds bytes32[] array of condition identifiers","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreLibrary/#return-values","text":"Name Type Description size struct AgreementStoreLibrary.AgreementList which is the index of the created agreement","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/","text":"Implementation of the Agreement Store. The agreement store generates conditions for an agreement template. Agreement templates must to be approved in the Template Store Each agreement is linked to the DID of an asset. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _templateStoreManagerAddress , address _didRegistryAddress ) public initialize AgreementStoreManager Initializer Initializes Ownable. Only on contract creation. Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract _conditionStoreManagerAddress address is the address of the connected condition store _templateStoreManagerAddress address is the address of the connected template store _didRegistryAddress address is the address of the connected DID Registry createAgreement \u00b6 function createAgreement ( bytes32 _id , bytes32 _did , address [] _conditionTypes , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts ) public returns ( uint256 size ) Create a new agreement. The agreement will create conditions of conditionType with conditionId. Only \"approved\" templates can access this function. Parameters: \u00b6 Name Type Description _id bytes32 is the ID of the new agreement. Must be unique. _did bytes32 is the bytes32 DID of the asset. The DID must be registered beforehand. _conditionTypes address[] is a list of addresses that point to Condition contracts. _conditionIds bytes32[] is a list of bytes32 content-addressed Condition IDs _timeLocks uint256[] is a list of uint time lock values associated to each Condition _timeOuts uint256[] is a list of uint time out values associated to each Condition Return Values: \u00b6 Name Type Description size bytes32 the size of the agreement list after the create action. ### getAgreement function getAgreement ( bytes32 _id ) external returns ( bytes32 did , address didOwner , address templateId , bytes32 [] conditionIds , address lastUpdatedBy , uint256 blockNumberUpdated ) Get agreement with _id. The agreement will create conditions of conditionType with conditionId. Only \"approved\" templates can access this function. Parameters: \u00b6 Name Type Description _id bytes32 is the ID of the agreement. getAgreementDIDOwner \u00b6 function getAgreementDIDOwner ( bytes32 _id ) external returns ( address didOwner ) get the DID owner for this agreement with _id. Parameters: \u00b6 Name Type Description _id bytes32 is the ID of the agreement. Return Values: \u00b6 Name Type Description didOwner bytes32 the DID owner associated with agreement.did from the DID registry. ### isAgreementDIDOwner function isAgreementDIDOwner ( bytes32 _id , address _owner ) external returns ( bool ) check the DID owner for this agreement with _id. Parameters: \u00b6 Name Type Description _id bytes32 is the ID of the agreement. _owner address is the DID owner Return Values: \u00b6 Name Type Description the bytes32 DID owner associated with agreement.did from the DID registry. ### isAgreementDIDProvider function isAgreementDIDProvider ( bytes32 _id , address _provider ) external returns ( bool ) isAgreementDIDProvider for a given agreement Id and address check whether a DID provider is associated with this agreement Parameters: \u00b6 Name Type Description _id bytes32 is the ID of the agreement _provider address is the DID provider Return Values: \u00b6 Name Type Description true bytes32 if a DID provider is associated with the agreement ID ### getAgreementListSize function getAgreementListSize ( ) public returns ( uint256 size ) Return Values: \u00b6 Name Type Description size the length of the agreement list. ### getAgreementIdsForDID function getAgreementIdsForDID ( bytes32 _did ) public returns ( bytes32 []) Parameters: \u00b6 Name Type Description _did bytes32 is the bytes32 DID of the asset. Return Values: \u00b6 Name Type Description the bytes32 agreement IDs for a given DID ### getAgreementIdsForTemplateId function getAgreementIdsForTemplateId ( address _templateId ) public returns ( bytes32 []) Parameters: \u00b6 Name Type Description _templateId address is the address of the agreement template. Return Values: \u00b6 Name Type Description the address agreement IDs for a given DID ### getDIDRegistryAddress function getDIDRegistryAddress ( ) public returns ( address ) getDIDRegistryAddress utility function used by other contracts or any EOA. Return Values: \u00b6 Name Type Description the DIDRegistry address","title":"AgreementStoreManager"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _templateStoreManagerAddress , address _didRegistryAddress ) public initialize AgreementStoreManager Initializer Initializes Ownable. Only on contract creation.","title":"initialize"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters","text":"Name Type Description _owner address refers to the owner of the contract _conditionStoreManagerAddress address is the address of the connected condition store _templateStoreManagerAddress address is the address of the connected template store _didRegistryAddress address is the address of the connected DID Registry","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#createagreement","text":"function createAgreement ( bytes32 _id , bytes32 _did , address [] _conditionTypes , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts ) public returns ( uint256 size ) Create a new agreement. The agreement will create conditions of conditionType with conditionId. Only \"approved\" templates can access this function.","title":"createAgreement"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_1","text":"Name Type Description _id bytes32 is the ID of the new agreement. Must be unique. _did bytes32 is the bytes32 DID of the asset. The DID must be registered beforehand. _conditionTypes address[] is a list of addresses that point to Condition contracts. _conditionIds bytes32[] is a list of bytes32 content-addressed Condition IDs _timeLocks uint256[] is a list of uint time lock values associated to each Condition _timeOuts uint256[] is a list of uint time out values associated to each Condition","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values","text":"Name Type Description size bytes32 the size of the agreement list after the create action. ### getAgreement function getAgreement ( bytes32 _id ) external returns ( bytes32 did , address didOwner , address templateId , bytes32 [] conditionIds , address lastUpdatedBy , uint256 blockNumberUpdated ) Get agreement with _id. The agreement will create conditions of conditionType with conditionId. Only \"approved\" templates can access this function.","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_2","text":"Name Type Description _id bytes32 is the ID of the agreement.","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#getagreementdidowner","text":"function getAgreementDIDOwner ( bytes32 _id ) external returns ( address didOwner ) get the DID owner for this agreement with _id.","title":"getAgreementDIDOwner"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_3","text":"Name Type Description _id bytes32 is the ID of the agreement.","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_1","text":"Name Type Description didOwner bytes32 the DID owner associated with agreement.did from the DID registry. ### isAgreementDIDOwner function isAgreementDIDOwner ( bytes32 _id , address _owner ) external returns ( bool ) check the DID owner for this agreement with _id.","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_4","text":"Name Type Description _id bytes32 is the ID of the agreement. _owner address is the DID owner","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_2","text":"Name Type Description the bytes32 DID owner associated with agreement.did from the DID registry. ### isAgreementDIDProvider function isAgreementDIDProvider ( bytes32 _id , address _provider ) external returns ( bool ) isAgreementDIDProvider for a given agreement Id and address check whether a DID provider is associated with this agreement","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_5","text":"Name Type Description _id bytes32 is the ID of the agreement _provider address is the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_3","text":"Name Type Description true bytes32 if a DID provider is associated with the agreement ID ### getAgreementListSize function getAgreementListSize ( ) public returns ( uint256 size )","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_4","text":"Name Type Description size the length of the agreement list. ### getAgreementIdsForDID function getAgreementIdsForDID ( bytes32 _did ) public returns ( bytes32 [])","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_6","text":"Name Type Description _did bytes32 is the bytes32 DID of the asset.","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_5","text":"Name Type Description the bytes32 agreement IDs for a given DID ### getAgreementIdsForTemplateId function getAgreementIdsForTemplateId ( address _templateId ) public returns ( bytes32 [])","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#parameters_7","text":"Name Type Description _templateId address is the address of the agreement template.","title":"Parameters:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_6","text":"Name Type Description the address agreement IDs for a given DID ### getDIDRegistryAddress function getDIDRegistryAddress ( ) public returns ( address ) getDIDRegistryAddress utility function used by other contracts or any EOA.","title":"Return Values:"},{"location":"architecture/contracts/contracts/agreements/AgreementStoreManager/#return-values_7","text":"Name Type Description the DIDRegistry address","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/","text":"Implementation of the Access Condition Access Secret Store Condition is special condition where a client or Parity secret store can encrypt/decrypt documents based on the on-chain granted permissions. For a given DID document, and agreement ID, the owner/provider of the DID will fulfill the condition. Consequently secret store will check whether the permission is granted for the consumer in order to encrypt/decrypt the document. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address hashValues \u00b6 function hashValues ( bytes32 _documentId , address _grantee ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _documentId , address _grantee ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill access secret store condition only DID owner or DID provider can call this method. Fulfill method sets the permissions for the granted consumer's address to true then fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ### grantPermission function grantPermission ( address _grantee , bytes32 _documentId ) public grantPermission is called only by DID owner or provider Parameters: \u00b6 Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys renouncePermission \u00b6 function renouncePermission ( address _grantee , bytes32 _documentId ) public renouncePermission is called only by DID owner or provider Parameters: \u00b6 Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys checkPermissions \u00b6 function checkPermissions ( address _documentId , bytes32 _grantee ) external returns ( bool permissionGranted ) checkPermissions is called by Parity secret store Parameters: \u00b6 Name Type Description _documentId address refers to the DID in which secret store will issue the decryption keys _grantee bytes32 is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description permissionGranted address true if the access was granted ## Events ### Fulfilled event Fulfilled ( )","title":"AccessCondition"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#hashvalues","text":"function hashValues ( bytes32 _documentId , address _grantee ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters_1","text":"Name Type Description _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _documentId , address _grantee ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill access secret store condition only DID owner or DID provider can call this method. Fulfill method sets the permissions for the granted consumer's address to true then fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ### grantPermission function grantPermission ( address _grantee , bytes32 _documentId ) public grantPermission is called only by DID owner or provider","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters_3","text":"Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#renouncepermission","text":"function renouncePermission ( address _grantee , bytes32 _documentId ) public renouncePermission is called only by DID owner or provider","title":"renouncePermission"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters_4","text":"Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#checkpermissions","text":"function checkPermissions ( address _documentId , bytes32 _grantee ) external returns ( bool permissionGranted ) checkPermissions is called by Parity secret store","title":"checkPermissions"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#parameters_5","text":"Name Type Description _documentId address refers to the DID in which secret store will issue the decryption keys _grantee bytes32 is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/AccessCondition/#return-values_2","text":"Name Type Description permissionGranted address true if the access was granted ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/","text":"Implementation of the Compute Execution Condition This condition is meant to be a signal in which triggers the execution of a compute service. The compute service is fully described in the associated DID document. The provider of the compute service will send this signal to its workers by fulfilling the condition where they are listening to the fulfilled event. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address hashValues \u00b6 function hashValues ( bytes32 _did , address _computeConsumer ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the consumer's address Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _computeConsumer ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill compute execution condition only the compute provider can fulfill this condition. By fulfilling this condition the compute provider will trigger the execution of the offered job/compute. The compute service is described in a DID document. Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the consumer's address Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ### wasComputeTriggered function wasComputeTriggered ( bytes32 _did , address _computeConsumer ) public returns ( bool ) wasComputeTriggered checks whether the compute is triggered or not. Parameters: \u00b6 Name Type Description _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the compute consumer's address Return Values: \u00b6 Name Type Description true bytes32 if the compute is triggered ## Events ### Fulfilled event Fulfilled ( )","title":"ComputeExecutionCondition"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _computeConsumer ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#parameters_1","text":"Name Type Description _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the consumer's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _computeConsumer ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill compute execution condition only the compute provider can fulfill this condition. By fulfilling this condition the compute provider will trigger the execution of the offered job/compute. The compute service is described in a DID document.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the consumer's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ### wasComputeTriggered function wasComputeTriggered ( bytes32 _did , address _computeConsumer ) public returns ( bool ) wasComputeTriggered checks whether the compute is triggered or not.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#parameters_3","text":"Name Type Description _did bytes32 Decentralized Identifier (unique compute/asset resolver) describes the compute service _computeConsumer address is the compute consumer's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ComputeExecutionCondition/#return-values_2","text":"Name Type Description true bytes32 if the compute is triggered ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/Condition/","text":"Implementation of the Condition Each condition has a validation function that returns either FULFILLED, ABORTED or UNFULFILLED. When a condition is successfully solved, we call it FULFILLED. If a condition cannot be FULFILLED anymore due to a timeout or other types of counter-proofs, the condition is ABORTED. UNFULFILLED values imply that a condition has not been provably FULFILLED or ABORTED. All initialized conditions start out as UNFULFILLED. Functions \u00b6 generateId \u00b6 function generateId ( bytes32 _agreementId , bytes32 _valueHash ) public returns ( bytes32 ) generateId condition Id from the following parameters Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement ID _valueHash bytes32 hash of all the condition input values fulfill \u00b6 function fulfill ( bytes32 _id , enum ConditionStoreLibrary . ConditionState _newState ) internal returns ( enum ConditionStoreLibrary . ConditionState ) fulfill set the condition state to Fulfill | Abort Parameters: \u00b6 Name Type Description _id bytes32 condition identifier _newState enum ConditionStoreLibrary.ConditionState new condition state (Fulfill/Abort) Return Values: \u00b6 Name Type Description the bytes32 updated condition state ### abortByTimeOut function abortByTimeOut ( bytes32 _id ) external returns ( enum ConditionStoreLibrary . ConditionState ) abortByTimeOut set condition state to Aborted if the condition is timed out Parameters: \u00b6 Name Type Description _id bytes32 condition identifier Return Values: \u00b6 Name Type Description the bytes32 updated condition state","title":"Condition"},{"location":"architecture/contracts/contracts/conditions/Condition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/Condition/#generateid","text":"function generateId ( bytes32 _agreementId , bytes32 _valueHash ) public returns ( bytes32 ) generateId condition Id from the following parameters","title":"generateId"},{"location":"architecture/contracts/contracts/conditions/Condition/#parameters","text":"Name Type Description _agreementId bytes32 SEA agreement ID _valueHash bytes32 hash of all the condition input values","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/Condition/#fulfill","text":"function fulfill ( bytes32 _id , enum ConditionStoreLibrary . ConditionState _newState ) internal returns ( enum ConditionStoreLibrary . ConditionState ) fulfill set the condition state to Fulfill | Abort","title":"fulfill"},{"location":"architecture/contracts/contracts/conditions/Condition/#parameters_1","text":"Name Type Description _id bytes32 condition identifier _newState enum ConditionStoreLibrary.ConditionState new condition state (Fulfill/Abort)","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/Condition/#return-values","text":"Name Type Description the bytes32 updated condition state ### abortByTimeOut function abortByTimeOut ( bytes32 _id ) external returns ( enum ConditionStoreLibrary . ConditionState ) abortByTimeOut set condition state to Aborted if the condition is timed out","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/Condition/#parameters_2","text":"Name Type Description _id bytes32 condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/Condition/#return-values_1","text":"Name Type Description the bytes32 updated condition state","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/","text":"Implementation of the Condition Store Library. Condition is a key component in the service execution agreement. This library holds the logic for creating and updating condition Any Condition has only four state transitions starts with Uninitialized, Unfulfilled, Fulfilled, and Aborted. Condition state transition goes only forward from Unintialized -> Unfulfilled -> {Fulfilled || Aborted} Functions \u00b6 create \u00b6 function create ( struct ConditionStoreLibrary . ConditionList _self , bytes32 _id , address _typeRef ) internal returns ( uint256 size ) create new condition check whether the condition exists, assigns condition type, condition state, last updated by, and update at (which is the current block number) Parameters: \u00b6 Name Type Description _self struct ConditionStoreLibrary.ConditionList is the ConditionList storage pointer _id bytes32 valid condition identifier _typeRef address condition contract address Return Values: \u00b6 Name Type Description size struct ConditionStoreLibrary.ConditionList is the condition index ### updateState function updateState ( struct ConditionStoreLibrary . ConditionList _self , bytes32 _id , enum ConditionStoreLibrary . ConditionState _newState ) internal updateState update the condition state check whether the condition state transition is right, assign the new state, update last updated by and updated at. Parameters: \u00b6 Name Type Description _self struct ConditionStoreLibrary.ConditionList is the ConditionList storage pointer _id bytes32 condition identifier _newState enum ConditionStoreLibrary.ConditionState the new state of the condition","title":"ConditionStoreLibrary"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/#create","text":"function create ( struct ConditionStoreLibrary . ConditionList _self , bytes32 _id , address _typeRef ) internal returns ( uint256 size ) create new condition check whether the condition exists, assigns condition type, condition state, last updated by, and update at (which is the current block number)","title":"create"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/#parameters","text":"Name Type Description _self struct ConditionStoreLibrary.ConditionList is the ConditionList storage pointer _id bytes32 valid condition identifier _typeRef address condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/#return-values","text":"Name Type Description size struct ConditionStoreLibrary.ConditionList is the condition index ### updateState function updateState ( struct ConditionStoreLibrary . ConditionList _self , bytes32 _id , enum ConditionStoreLibrary . ConditionState _newState ) internal updateState update the condition state check whether the condition state transition is right, assign the new state, update last updated by and updated at.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreLibrary/#parameters_1","text":"Name Type Description _self struct ConditionStoreLibrary.ConditionList is the ConditionList storage pointer _id bytes32 condition identifier _newState enum ConditionStoreLibrary.ConditionState the new state of the condition","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/","text":"Implementation of the Condition Store Manager. Condition store manager is responsible for enforcing the the business logic behind creating/updating the condition state based on the assigned role to each party. Only specific type of contracts are allowed to call this contract, therefor there are two types of roles, create role that in which is able to create conditions. The second role is the update role, which is can update the condition state. Also, it support delegating the roles to other contract(s)/account(s). Functions \u00b6 initialize \u00b6 function initialize ( address _owner ) public initialize ConditionStoreManager Initializer Initialize Ownable. Only on contract creation, Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract getCreateRole \u00b6 function getCreateRole ( ) external returns ( address ) getCreateRole get the address of contract which has the create role Return Values: \u00b6 Name Type Description create condition role address ### delegateCreateRole function delegateCreateRole ( address delegatee ) external delegateCreateRole only owner can delegate the create condition role to a different address Parameters: \u00b6 Name Type Description delegatee address delegatee address delegateUpdateRole \u00b6 function delegateUpdateRole ( bytes32 delegatee ) external delegateUpdateRole only owner can delegate the update role to a different address for specific condition Id which has the create role Parameters: \u00b6 Name Type Description delegatee bytes32 delegatee address createCondition \u00b6 function createCondition ( bytes32 _id , address _typeRef ) external returns ( uint256 size ) createCondition only called by create role address the condition should use a valid condition contract address, valid time lock and timeout. Moreover, it enforce the condition state transition from Uninitialized to Unfulfilled. Parameters: \u00b6 Name Type Description _id bytes32 unique condition identifier _typeRef address condition contract address Return Values: \u00b6 Name Type Description size bytes32 the index of the created condition ### createCondition function createCondition ( bytes32 _id , address _typeRef , uint256 _timeLock , uint256 _timeOut ) public returns ( uint256 size ) createCondition only called by create role address the condition should use a valid condition contract address, valid time lock and timeout. Moreover, it enforce the condition state transition from Uninitialized to Unfulfilled. Parameters: \u00b6 Name Type Description _id bytes32 unique condition identifier _typeRef address condition contract address _timeLock uint256 start of the time window _timeOut uint256 end of the time window Return Values: \u00b6 Name Type Description size bytes32 the index of the created condition ### updateConditionState function updateConditionState ( bytes32 _id ) external returns ( enum ConditionStoreLibrary . ConditionState ) updateConditionState only called by update role address. It enforce the condition state transition to either Fulfill or Aborted state Parameters: \u00b6 Name Type Description _id bytes32 unique condition identifier Return Values: \u00b6 Name Type Description the bytes32 current condition state ### getConditionListSize function getConditionListSize ( ) external returns ( uint256 size ) getConditionListSize Return Values: \u00b6 Name Type Description size the length of the condition list ### getCondition function getCondition ( ) external returns ( address typeRef , enum ConditionStoreLibrary . ConditionState state , uint256 timeLock , uint256 timeOut , uint256 blockNumber , address createdBy , address lastUpdatedBy , uint256 blockNumberUpdated ) getCondition Return Values: \u00b6 Name Type Description typeRef bytes32 the type reference state condition state timeLock the time lock timeOut time out blockNumber block number createdBy address lastUpdatedBy address blockNumberUpdated block number updated ### getConditionState function getConditionState ( ) external returns ( enum ConditionStoreLibrary . ConditionState ) getConditionState Return Values: \u00b6 Name Type Description condition bytes32 state ### getConditionTypeRef function getConditionTypeRef ( ) external returns ( address ) getConditionTypeRef Return Values: \u00b6 Name Type Description condition bytes32 typeRef ### getConditionCreatedBy function getConditionCreatedBy ( ) external returns ( address ) getConditionCreatedBy Return Values: \u00b6 Name Type Description condition bytes32 createdBy address ### isConditionTimeLocked function isConditionTimeLocked ( ) public returns ( bool ) isConditionTimeLocked Return Values: \u00b6 Name Type Description whether bytes32 the condition is timedLock ended ### isConditionTimedOut function isConditionTimedOut ( ) public returns ( bool ) isConditionTimedOut Return Values: \u00b6 Name Type Description whether bytes32 the condition is timed out ## Events ### ConditionCreated event ConditionCreated ( ) ConditionUpdated \u00b6 event ConditionUpdated ( )","title":"ConditionStoreManager"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#initialize","text":"function initialize ( address _owner ) public initialize ConditionStoreManager Initializer Initialize Ownable. Only on contract creation,","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters","text":"Name Type Description _owner address refers to the owner of the contract","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#getcreaterole","text":"function getCreateRole ( ) external returns ( address ) getCreateRole get the address of contract which has the create role","title":"getCreateRole"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values","text":"Name Type Description create condition role address ### delegateCreateRole function delegateCreateRole ( address delegatee ) external delegateCreateRole only owner can delegate the create condition role to a different address","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters_1","text":"Name Type Description delegatee address delegatee address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#delegateupdaterole","text":"function delegateUpdateRole ( bytes32 delegatee ) external delegateUpdateRole only owner can delegate the update role to a different address for specific condition Id which has the create role","title":"delegateUpdateRole"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters_2","text":"Name Type Description delegatee bytes32 delegatee address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#createcondition","text":"function createCondition ( bytes32 _id , address _typeRef ) external returns ( uint256 size ) createCondition only called by create role address the condition should use a valid condition contract address, valid time lock and timeout. Moreover, it enforce the condition state transition from Uninitialized to Unfulfilled.","title":"createCondition"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters_3","text":"Name Type Description _id bytes32 unique condition identifier _typeRef address condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_1","text":"Name Type Description size bytes32 the index of the created condition ### createCondition function createCondition ( bytes32 _id , address _typeRef , uint256 _timeLock , uint256 _timeOut ) public returns ( uint256 size ) createCondition only called by create role address the condition should use a valid condition contract address, valid time lock and timeout. Moreover, it enforce the condition state transition from Uninitialized to Unfulfilled.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters_4","text":"Name Type Description _id bytes32 unique condition identifier _typeRef address condition contract address _timeLock uint256 start of the time window _timeOut uint256 end of the time window","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_2","text":"Name Type Description size bytes32 the index of the created condition ### updateConditionState function updateConditionState ( bytes32 _id ) external returns ( enum ConditionStoreLibrary . ConditionState ) updateConditionState only called by update role address. It enforce the condition state transition to either Fulfill or Aborted state","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#parameters_5","text":"Name Type Description _id bytes32 unique condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_3","text":"Name Type Description the bytes32 current condition state ### getConditionListSize function getConditionListSize ( ) external returns ( uint256 size ) getConditionListSize","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_4","text":"Name Type Description size the length of the condition list ### getCondition function getCondition ( ) external returns ( address typeRef , enum ConditionStoreLibrary . ConditionState state , uint256 timeLock , uint256 timeOut , uint256 blockNumber , address createdBy , address lastUpdatedBy , uint256 blockNumberUpdated ) getCondition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_5","text":"Name Type Description typeRef bytes32 the type reference state condition state timeLock the time lock timeOut time out blockNumber block number createdBy address lastUpdatedBy address blockNumberUpdated block number updated ### getConditionState function getConditionState ( ) external returns ( enum ConditionStoreLibrary . ConditionState ) getConditionState","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_6","text":"Name Type Description condition bytes32 state ### getConditionTypeRef function getConditionTypeRef ( ) external returns ( address ) getConditionTypeRef","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_7","text":"Name Type Description condition bytes32 typeRef ### getConditionCreatedBy function getConditionCreatedBy ( ) external returns ( address ) getConditionCreatedBy","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_8","text":"Name Type Description condition bytes32 createdBy address ### isConditionTimeLocked function isConditionTimeLocked ( ) public returns ( bool ) isConditionTimeLocked","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_9","text":"Name Type Description whether bytes32 the condition is timedLock ended ### isConditionTimedOut function isConditionTimedOut ( ) public returns ( bool ) isConditionTimedOut","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#return-values_10","text":"Name Type Description whether bytes32 the condition is timed out ## Events ### ConditionCreated event ConditionCreated ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ConditionStoreManager/#conditionupdated","text":"event ConditionUpdated ( )","title":"ConditionUpdated"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/","text":"Implementation of the Hash Lock Condition Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address hashValues \u00b6 function hashValues ( uint256 _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _preimage uint256 refers uint value of the hash pre-image. Return Values: \u00b6 Name Type Description bytes32 uint256 hash of all these values ### hashValues function hashValues ( string _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _preimage string refers string value of the hash pre-image. Return Values: \u00b6 Name Type Description bytes32 string hash of all these values ### hashValues function hashValues ( bytes32 _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _preimage bytes32 refers bytes32 value of the hash pre-image. Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image uint value Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier Return Values: \u00b6 Name Type Description condition bytes32 state ### fulfill function fulfill ( bytes32 _agreementId ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image string value Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier Return Values: \u00b6 Name Type Description condition bytes32 state ### fulfill function fulfill ( bytes32 _agreementId ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image bytes32 value Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier Return Values: \u00b6 Name Type Description condition bytes32 state","title":"HashLockCondition"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#hashvalues","text":"function hashValues ( uint256 _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_1","text":"Name Type Description _preimage uint256 refers uint value of the hash pre-image.","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values","text":"Name Type Description bytes32 uint256 hash of all these values ### hashValues function hashValues ( string _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_2","text":"Name Type Description _preimage string refers string value of the hash pre-image.","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values_1","text":"Name Type Description bytes32 string hash of all these values ### hashValues function hashValues ( bytes32 _preimage ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_3","text":"Name Type Description _preimage bytes32 refers bytes32 value of the hash pre-image.","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values_2","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image uint value","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_4","text":"Name Type Description _agreementId bytes32 SEA agreement identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values_3","text":"Name Type Description condition bytes32 state ### fulfill function fulfill ( bytes32 _agreementId ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image string value","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_5","text":"Name Type Description _agreementId bytes32 SEA agreement identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values_4","text":"Name Type Description condition bytes32 state ### fulfill function fulfill ( bytes32 _agreementId ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the condition by calling check the the hash and the pre-image bytes32 value","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#parameters_6","text":"Name Type Description _agreementId bytes32 SEA agreement identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/HashLockCondition/#return-values_5","text":"Name Type Description condition bytes32 state","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/","text":"Implementation of the Lock Payment Condition This condition allows to lock payment for multiple receivers taking into account the royalties to be paid to the original creators in a secondary market. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _tokenAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _tokenAddress address Default Token contract address _didRegistryAddress address DID Registry address hashValues \u00b6 function hashValues ( bytes32 _did , address _rewardAddress , address _tokenAddress , uint256 [] _amounts , address [] _receivers ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 the asset decentralized identifier _rewardAddress address the contract address where the reward is locked _tokenAddress address the ERC20 contract address to use during the lock payment. If the address is 0x0 means we won't use a ERC20 but ETH for payment _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address payable _rewardAddress , address _tokenAddress , uint256 [] _amounts , address [] _receivers ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires valid token transfer in order to lock the amount of tokens based on the SEA Parameters: \u00b6 Name Type Description _agreementId bytes32 the agreement identifier _did bytes32 the asset decentralized identifier _rewardAddress address payable the contract address where the reward is locked _tokenAddress address the ERC20 contract address to use during the lock payment. _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses Return Values: \u00b6 Name Type Description condition bytes32 state ### _transferERC20 function _transferERC20 ( address _rewardAddress , address _tokenAddress , uint256 _amount ) internal returns ( bool ) _transferERC20 transfer ERC20 tokens Parameters: \u00b6 Name Type Description _rewardAddress address the address to receive the tokens _tokenAddress address the ERC20 contract address to use during the payment _amount uint256 token amount to be locked/released Return Values: \u00b6 Name Type Description true address if everything worked ### _transferETH function _transferETH ( address payable _rewardAddress , uint256 _amount ) internal _transferETH transfer ETH Parameters: \u00b6 Name Type Description _rewardAddress address payable the address to receive the ETH _amount uint256 ETH amount to be locked/released Events \u00b6 Fulfilled \u00b6 event Fulfilled ( )","title":"LockPaymentCondition"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _tokenAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _tokenAddress address Default Token contract address _didRegistryAddress address DID Registry address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _rewardAddress , address _tokenAddress , uint256 [] _amounts , address [] _receivers ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#parameters_1","text":"Name Type Description _did bytes32 the asset decentralized identifier _rewardAddress address the contract address where the reward is locked _tokenAddress address the ERC20 contract address to use during the lock payment. If the address is 0x0 means we won't use a ERC20 but ETH for payment _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address payable _rewardAddress , address _tokenAddress , uint256 [] _amounts , address [] _receivers ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires valid token transfer in order to lock the amount of tokens based on the SEA","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 the agreement identifier _did bytes32 the asset decentralized identifier _rewardAddress address payable the contract address where the reward is locked _tokenAddress address the ERC20 contract address to use during the lock payment. _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#return-values_1","text":"Name Type Description condition bytes32 state ### _transferERC20 function _transferERC20 ( address _rewardAddress , address _tokenAddress , uint256 _amount ) internal returns ( bool ) _transferERC20 transfer ERC20 tokens","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#parameters_3","text":"Name Type Description _rewardAddress address the address to receive the tokens _tokenAddress address the ERC20 contract address to use during the payment _amount uint256 token amount to be locked/released","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#return-values_2","text":"Name Type Description true address if everything worked ### _transferETH function _transferETH ( address payable _rewardAddress , uint256 _amount ) internal _transferETH transfer ETH","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#parameters_4","text":"Name Type Description _rewardAddress address payable the address to receive the ETH _amount uint256 ETH amount to be locked/released","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#events","text":"","title":"Events"},{"location":"architecture/contracts/contracts/conditions/LockPaymentCondition/#fulfilled","text":"event Fulfilled ( )","title":"Fulfilled"},{"location":"architecture/contracts/contracts/conditions/SignCondition/","text":"Implementation of the Sign Condition Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address hashValues \u00b6 function hashValues ( bytes32 _message , address _publicKey ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _message bytes32 the message to be signed _publicKey address the public key of the signing address Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _message , address _publicKey , bytes _signature ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill validate the signed message and fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier _message bytes32 the message to be signed _publicKey address the public key of the signing address _signature bytes signature of the signed message using the public key Return Values: \u00b6 Name Type Description condition bytes32 state","title":"SignCondition"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#hashvalues","text":"function hashValues ( bytes32 _message , address _publicKey ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#parameters_1","text":"Name Type Description _message bytes32 the message to be signed _publicKey address the public key of the signing address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _message , address _publicKey , bytes _signature ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill validate the signed message and fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 SEA agreement identifier _message bytes32 the message to be signed _publicKey address the public key of the signing address _signature bytes signature of the signed message using the public key","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/SignCondition/#return-values_1","text":"Name Type Description condition bytes32 state","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/","text":"Implementation of the Threshold Condition Threshold condition acts as a filter for a set of input condition(s) in which sends a signal whether to complete the flow execution or abort it. This type of conditions works as intermediary conditions where they wire SEA conditions in order to support more complex scenarios. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address hashValues \u00b6 function hashValues ( bytes32 [] inputConditions , uint256 threshold ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description inputConditions bytes32[] array of input conditions IDs threshold uint256 the required number of fulfilled input conditions Return Values: \u00b6 Name Type Description bytes32 bytes32[] hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 [] _inputConditions , uint256 threshold ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill threshold condition the fulfill method check whether input conditions are fulfilled or not. Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _inputConditions bytes32[] array of input conditions IDs threshold uint256 the required number of fulfilled input conditions Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted)","title":"ThresholdCondition"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#hashvalues","text":"function hashValues ( bytes32 [] inputConditions , uint256 threshold ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#parameters_1","text":"Name Type Description inputConditions bytes32[] array of input conditions IDs threshold uint256 the required number of fulfilled input conditions","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#return-values","text":"Name Type Description bytes32 bytes32[] hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 [] _inputConditions , uint256 threshold ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill threshold condition the fulfill method check whether input conditions are fulfilled or not.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _inputConditions bytes32[] array of input conditions IDs threshold uint256 the required number of fulfilled input conditions","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/ThresholdCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted)","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/","text":"Implementation of condition allowing to transfer the ownership between the original owner and a receiver Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address hashValues \u00b6 function hashValues ( bytes32 _did , address _receiver ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 refers to the DID in which secret store will issue the decryption keys _receiver address is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _receiver ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer DID ownership condition only DID owner or DID provider can call this method. Fulfill method transfer full ownership permissions to to _receiver address. When true then fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _receiver address is the address of the granted user Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( )","title":"TransferDIDOwnershipCondition"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _receiver ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#parameters_1","text":"Name Type Description _did bytes32 refers to the DID in which secret store will issue the decryption keys _receiver address is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _receiver ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer DID ownership condition only DID owner or DID provider can call this method. Fulfill method transfer full ownership permissions to to _receiver address. When true then fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _receiver address is the address of the granted user","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/TransferDIDOwnershipCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/","text":"Implementation of the Whitelisting Condition Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address hashValues \u00b6 function hashValues ( address _listAddress , bytes32 _item ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _listAddress address list contract address _item bytes32 item in the list Return Values: \u00b6 Name Type Description bytes32 address hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , address _listAddress , bytes32 _item ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill check whether address is whitelisted in order to fulfill the condition. This method will be called by any one in this whitelist. Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier _listAddress address list contract address _item bytes32 item in the list Return Values: \u00b6 Name Type Description condition bytes32 state","title":"WhitelistingCondition"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#hashvalues","text":"function hashValues ( address _listAddress , bytes32 _item ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#parameters_1","text":"Name Type Description _listAddress address list contract address _item bytes32 item in the list","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#return-values","text":"Name Type Description bytes32 address hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , address _listAddress , bytes32 _item ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill check whether address is whitelisted in order to fulfill the condition. This method will be called by any one in this whitelist.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 SEA agreement identifier _listAddress address list contract address _item bytes32 item in the list","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/WhitelistingCondition/#return-values_1","text":"Name Type Description condition bytes32 state","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/","text":"Implementation of the Access Condition specific for NFTs NFT Access Condition is special condition used to give access to a specific NFT related to a DID. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address hashValues \u00b6 function hashValues ( bytes32 _documentId , address _grantee ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _documentId , address _grantee ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill access secret store condition only DID owner or DID provider can call this method. Fulfill method sets the permissions for the granted consumer's address to true then fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ### grantPermission function grantPermission ( address _grantee , bytes32 _documentId ) public grantPermission is called only by DID owner or provider Parameters: \u00b6 Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys checkPermissions \u00b6 function checkPermissions ( address _documentId , bytes32 _grantee ) external returns ( bool permissionGranted ) checkPermissions is called to validate the permissions of user related to the NFT attached to an asset Parameters: \u00b6 Name Type Description _documentId address refers to the DID _grantee bytes32 is the address of the granted user or the DID provider Return Values: \u00b6 Name Type Description permissionGranted address true if the access was granted ## Events ### Fulfilled event Fulfilled ( )","title":"NFTAccessCondition"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#hashvalues","text":"function hashValues ( bytes32 _documentId , address _grantee ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#parameters_1","text":"Name Type Description _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _documentId , address _grantee ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill access secret store condition only DID owner or DID provider can call this method. Fulfill method sets the permissions for the granted consumer's address to true then fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _documentId bytes32 refers to the DID in which secret store will issue the decryption keys _grantee address is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ### grantPermission function grantPermission ( address _grantee , bytes32 _documentId ) public grantPermission is called only by DID owner or provider","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#parameters_3","text":"Name Type Description _grantee address is the address of the granted user or the DID provider _documentId bytes32 refers to the DID in which secret store will issue the decryption keys","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#checkpermissions","text":"function checkPermissions ( address _documentId , bytes32 _grantee ) external returns ( bool permissionGranted ) checkPermissions is called to validate the permissions of user related to the NFT attached to an asset","title":"checkPermissions"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#parameters_4","text":"Name Type Description _documentId address refers to the DID _grantee bytes32 is the address of the granted user or the DID provider","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTAccessCondition/#return-values_2","text":"Name Type Description permissionGranted address true if the access was granted ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/","text":"Implementation of the Nft Holder Condition Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _didRegistryAddress address DIDRegistry address hashValues \u00b6 function hashValues ( bytes32 _did , address _holderAddress , uint256 _amount ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 the Decentralized Identifier of the asset _holderAddress address the address of the NFT holder _amount uint256 is the amount NFTs that need to be hold by the holder Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _holderAddress , uint256 _amount ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires a validation that holder has enough NFTs for a specific DID Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier _did bytes32 the Decentralized Identifier of the asset _holderAddress address the contract address where the reward is locked _amount uint256 is the amount of NFT to be hold Return Values: \u00b6 Name Type Description condition bytes32 state ## Events ### Fulfilled event Fulfilled ( )","title":"NFTHolderCondition"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _didRegistryAddress address DIDRegistry address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _holderAddress , uint256 _amount ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#parameters_1","text":"Name Type Description _did bytes32 the Decentralized Identifier of the asset _holderAddress address the address of the NFT holder _amount uint256 is the amount NFTs that need to be hold by the holder","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _holderAddress , uint256 _amount ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires a validation that holder has enough NFTs for a specific DID","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 SEA agreement identifier _did bytes32 the Decentralized Identifier of the asset _holderAddress address the contract address where the reward is locked _amount uint256 is the amount of NFT to be hold","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTHolderCondition/#return-values_1","text":"Name Type Description condition bytes32 state ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/","text":"Implementation of the NFT Lock Condition Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _didRegistryAddress address DIDRegistry contract address hashValues \u00b6 function hashValues ( bytes32 _did , address _rewardAddress , uint256 _amount ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 the DID of the asset with NFTs attached to lock _rewardAddress address the final address to receive the NFTs _amount uint256 is the amount of the locked tokens Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _rewardAddress , uint256 _amount ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires valid NFT transfer in order to lock the amount of DID NFTs based on the SEA Parameters: \u00b6 Name Type Description _agreementId bytes32 SEA agreement identifier _did bytes32 Asset Decentralized Identifier _rewardAddress address the contract address where the reward is locked _amount uint256 is the amount of tokens to be transferred Return Values: \u00b6 Name Type Description condition bytes32 state ### onERC1155Received function onERC1155Received ( ) external returns ( bytes4 ) onERC1155BatchReceived \u00b6 function onERC1155BatchReceived ( ) external returns ( bytes4 ) supportsInterface \u00b6 function supportsInterface ( ) external returns ( bool ) Events \u00b6 Fulfilled \u00b6 event Fulfilled ( )","title":"NFTLockCondition"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _didRegistryAddress address DIDRegistry contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _rewardAddress , uint256 _amount ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#parameters_1","text":"Name Type Description _did bytes32 the DID of the asset with NFTs attached to lock _rewardAddress address the final address to receive the NFTs _amount uint256 is the amount of the locked tokens","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _rewardAddress , uint256 _amount ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill requires valid NFT transfer in order to lock the amount of DID NFTs based on the SEA","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 SEA agreement identifier _did bytes32 Asset Decentralized Identifier _rewardAddress address the contract address where the reward is locked _amount uint256 is the amount of tokens to be transferred","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#return-values_1","text":"Name Type Description condition bytes32 state ### onERC1155Received function onERC1155Received ( ) external returns ( bytes4 )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#onerc1155batchreceived","text":"function onERC1155BatchReceived ( ) external returns ( bytes4 )","title":"onERC1155BatchReceived"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#supportsinterface","text":"function supportsInterface ( ) external returns ( bool )","title":"supportsInterface"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#events","text":"","title":"Events"},{"location":"architecture/contracts/contracts/conditions/NFTs/NFTLockCondition/#fulfilled","text":"event Fulfilled ( )","title":"Fulfilled"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/","text":"Implementation of condition allowing to transfer an NFT between the original owner and a receiver Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address hashValues \u00b6 function hashValues ( bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _lockCondition ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the granted user or the DID provider _nftAmount uint256 amount of NFTs to transfer _lockCondition bytes32 lock condition identifier Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _lockPaymentCondition ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer NFT condition only DID owner or DID provider can call this method. Fulfill method transfer a certain amount of NFTs to the _receiver address. When true then fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the account to receive the NFT _nftAmount uint256 amount of NFTs to transfer _lockPaymentCondition bytes32 lock payment condition identifier Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ### fulfillWithNFTLock function fulfillWithNFTLock ( bytes32 _agreementId , bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _nftLockCondition ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer NFT condition only DID owner or DID provider can call this method. Fulfill method transfer a certain amount of NFTs to the _receiver address. When true then fulfill the condition Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the account to receive the NFT _nftAmount uint256 amount of NFTs to transfer _nftLockCondition bytes32 lock payment condition identifier Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( )","title":"TransferNFTCondition"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _agreementStoreManagerAddress ) external initialize init the contract with the following parameters this function is called only once during the contract initialization.","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _agreementStoreManagerAddress address agreement store manager address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#hashvalues","text":"function hashValues ( bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _lockCondition ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#parameters_1","text":"Name Type Description _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the granted user or the DID provider _nftAmount uint256 amount of NFTs to transfer _lockCondition bytes32 lock condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _lockPaymentCondition ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer NFT condition only DID owner or DID provider can call this method. Fulfill method transfer a certain amount of NFTs to the _receiver address. When true then fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the account to receive the NFT _nftAmount uint256 amount of NFTs to transfer _lockPaymentCondition bytes32 lock payment condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ### fulfillWithNFTLock function fulfillWithNFTLock ( bytes32 _agreementId , bytes32 _did , address _nftReceiver , uint256 _nftAmount , bytes32 _nftLockCondition ) public returns ( enum ConditionStoreLibrary . ConditionState ) fulfill the transfer NFT condition only DID owner or DID provider can call this method. Fulfill method transfer a certain amount of NFTs to the _receiver address. When true then fulfill the condition","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#parameters_3","text":"Name Type Description _agreementId bytes32 agreement identifier _did bytes32 refers to the DID in which secret store will issue the decryption keys _nftReceiver address is the address of the account to receive the NFT _nftAmount uint256 amount of NFTs to transfer _nftLockCondition bytes32 lock payment condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/NFTs/TransferNFTCondition/#return-values_2","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/","text":"Implementation of the Escrow Payment Condition The Escrow payment is reward condition in which only can release reward if lock and release conditions are fulfilled. Functions \u00b6 receive \u00b6 function receive ( ) external initialize \u00b6 function initialize ( address _owner , address _conditionStoreManagerAddress , address _tokenAddress ) external initialize init the contract with the following parameters Parameters: \u00b6 Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _tokenAddress address Default token contract address hashValues \u00b6 function hashValues ( bytes32 _did , uint256 [] _amounts , address [] _receivers , address _lockPaymentAddress , address _tokenAddress , bytes32 _lockCondition , bytes32 _releaseCondition ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters Parameters: \u00b6 Name Type Description _did bytes32 asset decentralized identifier _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses _lockPaymentAddress address lock payment contract address _tokenAddress address the ERC20 contract address to use during the payment _lockCondition bytes32 lock condition identifier _releaseCondition bytes32 release condition identifier Return Values: \u00b6 Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , uint256 [] _amounts , address [] _receivers , address _lockPaymentAddress , address _tokenAddress , bytes32 _lockCondition , bytes32 _releaseCondition ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill escrow reward condition fulfill method checks whether the lock and release conditions are fulfilled in order to release/refund the reward to receiver/sender respectively. Parameters: \u00b6 Name Type Description _agreementId bytes32 agreement identifier _did bytes32 asset decentralized identifier _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's address _lockPaymentAddress address lock payment contract address _tokenAddress address the ERC20 contract address to use during the payment _lockCondition bytes32 lock condition identifier _releaseCondition bytes32 release condition identifier Return Values: \u00b6 Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( ) Received \u00b6 event Received ( )","title":"EscrowPaymentCondition"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#receive","text":"function receive ( ) external","title":"receive"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#initialize","text":"function initialize ( address _owner , address _conditionStoreManagerAddress , address _tokenAddress ) external initialize init the contract with the following parameters","title":"initialize"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#parameters","text":"Name Type Description _owner address contract's owner account address _conditionStoreManagerAddress address condition store manager address _tokenAddress address Default token contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#hashvalues","text":"function hashValues ( bytes32 _did , uint256 [] _amounts , address [] _receivers , address _lockPaymentAddress , address _tokenAddress , bytes32 _lockCondition , bytes32 _releaseCondition ) public returns ( bytes32 ) hashValues generates the hash of condition inputs with the following parameters","title":"hashValues"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#parameters_1","text":"Name Type Description _did bytes32 asset decentralized identifier _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's addresses _lockPaymentAddress address lock payment contract address _tokenAddress address the ERC20 contract address to use during the payment _lockCondition bytes32 lock condition identifier _releaseCondition bytes32 release condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#return-values","text":"Name Type Description bytes32 bytes32 hash of all these values ### fulfill function fulfill ( bytes32 _agreementId , bytes32 _did , uint256 [] _amounts , address [] _receivers , address _lockPaymentAddress , address _tokenAddress , bytes32 _lockCondition , bytes32 _releaseCondition ) external returns ( enum ConditionStoreLibrary . ConditionState ) fulfill escrow reward condition fulfill method checks whether the lock and release conditions are fulfilled in order to release/refund the reward to receiver/sender respectively.","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#parameters_2","text":"Name Type Description _agreementId bytes32 agreement identifier _did bytes32 asset decentralized identifier _amounts uint256[] token amounts to be locked/released _receivers address[] receiver's address _lockPaymentAddress address lock payment contract address _tokenAddress address the ERC20 contract address to use during the payment _lockCondition bytes32 lock condition identifier _releaseCondition bytes32 release condition identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#return-values_1","text":"Name Type Description condition bytes32 state (Fulfilled/Aborted) ## Events ### Fulfilled event Fulfilled ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/conditions/rewards/EscrowPaymentCondition/#received","text":"event Received ( )","title":"Received"},{"location":"architecture/contracts/contracts/conditions/rewards/Reward/","text":"Implementation of the Reward. Generic reward condition","title":"Reward"},{"location":"architecture/contracts/contracts/interfaces/IList/","text":"Functions \u00b6 has \u00b6 function has ( ) external returns ( bool ) has \u00b6 function has ( ) external returns ( bool )","title":"IList"},{"location":"architecture/contracts/contracts/interfaces/IList/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/interfaces/IList/#has","text":"function has ( ) external returns ( bool )","title":"has"},{"location":"architecture/contracts/contracts/interfaces/IList/#has_1","text":"function has ( ) external returns ( bool )","title":"has"},{"location":"architecture/contracts/contracts/interfaces/ISecretStore/","text":"Functions \u00b6 checkPermissions \u00b6 function checkPermissions ( ) external returns ( bool permissionGranted ) checkPermissions is called by Parity secret store","title":"ISecretStore"},{"location":"architecture/contracts/contracts/interfaces/ISecretStore/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/interfaces/ISecretStore/#checkpermissions","text":"function checkPermissions ( ) external returns ( bool permissionGranted ) checkPermissions is called by Parity secret store","title":"checkPermissions"},{"location":"architecture/contracts/contracts/interfaces/ISecretStorePermission/","text":"Functions \u00b6 grantPermission \u00b6 function grantPermission ( ) external grantPermission is called only by documentKeyId Owner or provider renouncePermission \u00b6 function renouncePermission ( ) external renouncePermission is called only by documentKeyId Owner or provider","title":"ISecretStorePermission"},{"location":"architecture/contracts/contracts/interfaces/ISecretStorePermission/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/interfaces/ISecretStorePermission/#grantpermission","text":"function grantPermission ( ) external grantPermission is called only by documentKeyId Owner or provider","title":"grantPermission"},{"location":"architecture/contracts/contracts/interfaces/ISecretStorePermission/#renouncepermission","text":"function renouncePermission ( ) external renouncePermission is called only by documentKeyId Owner or provider","title":"renouncePermission"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/","text":"Implementation of Epoch Library. For an arbitrary Epoch, this library manages the life cycle of an Epoch. Usually this library is used for handling the time window between conditions in an agreement. For more information about Epoch checkout the below link https://github.com/oceanprotocol/OEPs/issues/119 TODO: update to the OEP link Functions \u00b6 create \u00b6 function create ( struct EpochLibrary . EpochList _self , bytes32 _timeLock , uint256 _timeOut ) internal create creates new Epoch Parameters: \u00b6 Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer _timeLock bytes32 value in block count (can not fulfill before) _timeOut uint256 value in block count (can not fulfill after) isTimedOut \u00b6 function isTimedOut ( struct EpochLibrary . EpochList _self ) external returns ( bool ) isTimedOut means you cannot fulfill after Parameters: \u00b6 Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer Return Values: \u00b6 Name Type Description true struct EpochLibrary.EpochList if the current block number is gt timeOut ### isTimeLocked function isTimeLocked ( struct EpochLibrary . EpochList _self ) external returns ( bool ) isTimeLocked means you cannot fulfill before Parameters: \u00b6 Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer Return Values: \u00b6 Name Type Description true struct EpochLibrary.EpochList if the current block number is gt timeLock ### getEpochTimeOut function getEpochTimeOut ( struct EpochLibrary . Epoch _self ) public returns ( uint256 ) getEpochTimeOut Parameters: \u00b6 Name Type Description _self struct EpochLibrary.Epoch is the Epoch storage pointer getEpochTimeLock \u00b6 function getEpochTimeLock ( struct EpochLibrary . Epoch _self ) public returns ( uint256 ) getEpochTimeLock Parameters: \u00b6 Name Type Description _self struct EpochLibrary.Epoch is the Epoch storage pointer","title":"EpochLibrary"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#create","text":"function create ( struct EpochLibrary . EpochList _self , bytes32 _timeLock , uint256 _timeOut ) internal create creates new Epoch","title":"create"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#parameters","text":"Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer _timeLock bytes32 value in block count (can not fulfill before) _timeOut uint256 value in block count (can not fulfill after)","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#istimedout","text":"function isTimedOut ( struct EpochLibrary . EpochList _self ) external returns ( bool ) isTimedOut means you cannot fulfill after","title":"isTimedOut"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#parameters_1","text":"Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#return-values","text":"Name Type Description true struct EpochLibrary.EpochList if the current block number is gt timeOut ### isTimeLocked function isTimeLocked ( struct EpochLibrary . EpochList _self ) external returns ( bool ) isTimeLocked means you cannot fulfill before","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#parameters_2","text":"Name Type Description _self struct EpochLibrary.EpochList is the Epoch storage pointer","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#return-values_1","text":"Name Type Description true struct EpochLibrary.EpochList if the current block number is gt timeLock ### getEpochTimeOut function getEpochTimeOut ( struct EpochLibrary . Epoch _self ) public returns ( uint256 ) getEpochTimeOut","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#parameters_3","text":"Name Type Description _self struct EpochLibrary.Epoch is the Epoch storage pointer","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#getepochtimelock","text":"function getEpochTimeLock ( struct EpochLibrary . Epoch _self ) public returns ( uint256 ) getEpochTimeLock","title":"getEpochTimeLock"},{"location":"architecture/contracts/contracts/libraries/EpochLibrary/#parameters_4","text":"Name Type Description _self struct EpochLibrary.Epoch is the Epoch storage pointer","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/","text":"Implementation of the basic functionality of list of hash values. This library allows other contracts to build and maintain lists and also preserves the privacy of the data by accepting only hashed content (bytes32 based data type) Functions \u00b6 add \u00b6 function add ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) add index an element then add it to a list Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is a bytes32 value Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if value is added successfully ### add function add ( struct HashListLibrary . List _self , bytes32 [] values ) public returns ( bool ) put an array of elements without indexing this meant to save gas in case of large arrays Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage values bytes32[] is an array of elements value Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if values are added successfully ### update function update ( struct HashListLibrary . List _self , bytes32 oldValue , bytes32 newValue ) public returns ( bool ) update the value with a new value and maintain indices Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage oldValue bytes32 is an element value in a list newValue bytes32 new value Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if value is updated successfully ### remove function remove ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) remove value from a list, updates indices, and list size Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is an element value in a list Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if value is removed successfully ### get function get ( struct HashListLibrary . List _self , uint256 index ) public returns ( bytes32 ) has value by index Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage index uint256 is where is value is stored in the list Return Values: \u00b6 Name Type Description the struct HashListLibrary.List value if exists ### index function index ( struct HashListLibrary . List _self , uint256 from , uint256 to ) public returns ( bool ) index is used to map each element value to its index on the list Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage from uint256 index is where to 'from' indexing in the list to uint256 index is where to stop indexing Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if the sub list is indexed ### setOwner function setOwner ( ) public setOwner set list owner param _owner owner address indexOf \u00b6 function indexOf ( struct HashListLibrary . List _self , bytes32 value ) public returns ( uint256 ) indexOf gets the index of a value in a list Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is element value in list Return Values: \u00b6 Name Type Description value struct HashListLibrary.List index in list ### isIndexed function isIndexed ( struct HashListLibrary . List _self ) public returns ( bool ) isIndexed checks if the list is indexed Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if the list is indexed ### all function all ( struct HashListLibrary . List _self ) public returns ( bytes32 []) all returns all list elements Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage Return Values: \u00b6 Name Type Description all struct HashListLibrary.List list elements ### has function has ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) size returns the list size Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is element value in list Return Values: \u00b6 Name Type Description true struct HashListLibrary.List if the value exists ### size function size ( struct HashListLibrary . List _self ) public returns ( uint256 ) size gets the list size Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage Return Values: \u00b6 Name Type Description total struct HashListLibrary.List length of the list ### ownedBy function ownedBy ( struct HashListLibrary . List _self ) public returns ( address ) ownedBy gets the list owner Parameters: \u00b6 Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage Return Values: \u00b6 Name Type Description list struct HashListLibrary.List owner","title":"HashListLibrary"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#add","text":"function add ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) add index an element then add it to a list","title":"add"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is a bytes32 value","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values","text":"Name Type Description true struct HashListLibrary.List if value is added successfully ### add function add ( struct HashListLibrary . List _self , bytes32 [] values ) public returns ( bool ) put an array of elements without indexing this meant to save gas in case of large arrays","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_1","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage values bytes32[] is an array of elements value","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_1","text":"Name Type Description true struct HashListLibrary.List if values are added successfully ### update function update ( struct HashListLibrary . List _self , bytes32 oldValue , bytes32 newValue ) public returns ( bool ) update the value with a new value and maintain indices","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_2","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage oldValue bytes32 is an element value in a list newValue bytes32 new value","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_2","text":"Name Type Description true struct HashListLibrary.List if value is updated successfully ### remove function remove ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) remove value from a list, updates indices, and list size","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_3","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is an element value in a list","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_3","text":"Name Type Description true struct HashListLibrary.List if value is removed successfully ### get function get ( struct HashListLibrary . List _self , uint256 index ) public returns ( bytes32 ) has value by index","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_4","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage index uint256 is where is value is stored in the list","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_4","text":"Name Type Description the struct HashListLibrary.List value if exists ### index function index ( struct HashListLibrary . List _self , uint256 from , uint256 to ) public returns ( bool ) index is used to map each element value to its index on the list","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_5","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage from uint256 index is where to 'from' indexing in the list to uint256 index is where to stop indexing","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_5","text":"Name Type Description true struct HashListLibrary.List if the sub list is indexed ### setOwner function setOwner ( ) public setOwner set list owner param _owner owner address","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#indexof","text":"function indexOf ( struct HashListLibrary . List _self , bytes32 value ) public returns ( uint256 ) indexOf gets the index of a value in a list","title":"indexOf"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_6","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is element value in list","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_6","text":"Name Type Description value struct HashListLibrary.List index in list ### isIndexed function isIndexed ( struct HashListLibrary . List _self ) public returns ( bool ) isIndexed checks if the list is indexed","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_7","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_7","text":"Name Type Description true struct HashListLibrary.List if the list is indexed ### all function all ( struct HashListLibrary . List _self ) public returns ( bytes32 []) all returns all list elements","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_8","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_8","text":"Name Type Description all struct HashListLibrary.List list elements ### has function has ( struct HashListLibrary . List _self , bytes32 value ) public returns ( bool ) size returns the list size","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_9","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage value bytes32 is element value in list","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_9","text":"Name Type Description true struct HashListLibrary.List if the value exists ### size function size ( struct HashListLibrary . List _self ) public returns ( uint256 ) size gets the list size","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_10","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_10","text":"Name Type Description total struct HashListLibrary.List length of the list ### ownedBy function ownedBy ( struct HashListLibrary . List _self ) public returns ( address ) ownedBy gets the list owner","title":"Return Values:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#parameters_11","text":"Name Type Description _self struct HashListLibrary.List is a pointer to list in the storage","title":"Parameters:"},{"location":"architecture/contracts/contracts/libraries/HashListLibrary/#return-values_11","text":"Name Type Description list struct HashListLibrary.List owner","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/","text":"Implementation of the DID Registry. Functions \u00b6 initialize \u00b6 function initialize ( address _owner ) public DIDRegistry Initializer Initialize Ownable. Only on contract creation. Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract. registerAttribute \u00b6 function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] _url ) public returns ( uint256 size ) Register DID attributes. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info. Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _url address[] refers to the attribute value, limited to 2048 bytes. Return Values: \u00b6 Name Type Description size bytes32 refers to the size of the registry after the register action. ### registerDID function registerDID ( bytes32 _did , bytes32 _checksum , address [] _providers , string _url , bytes32 _activityId , string _attributes ) public returns ( uint256 size ) Register DID attributes. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info. Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _providers address[] list of addresses that can act as an asset provider _url string refers to the url resolving the DID into a DID Document (DDO), limited to 2048 bytes. _activityId bytes32 refers to activity _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description size bytes32 refers to the size of the registry after the register action. ### areRoyaltiesValid function areRoyaltiesValid ( bytes32 _did , uint256 [] _amounts , address [] _receivers ) public returns ( bool ) areRoyaltiesValid checks if for a given DID and rewards distribution, this allocate the original creator royalties properly Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _amounts uint256[] refers to the amounts to reward _receivers address[] refers to the receivers of rewards Return Values: \u00b6 Name Type Description true bytes32 if the rewards distribution respect the original creator royalties ### wasGeneratedBy function wasGeneratedBy ( ) internal returns ( bool ) used \u00b6 function used ( ) public returns ( bool success ) wasDerivedFrom \u00b6 function wasDerivedFrom ( ) public returns ( bool success ) wasAssociatedWith \u00b6 function wasAssociatedWith ( ) public returns ( bool success ) actedOnBehalf \u00b6 function actedOnBehalf ( bytes32 _provId , bytes32 _did , address _delegateAgentId , address _responsibleAgentId , bytes32 _activityId , bytes _signatureDelegate , string _attributes ) public returns ( bool success ) Implements the W3C PROV Delegation action Each party involved in this method (_delegateAgentId & _responsibleAgentId) must provide a valid signature. The content to sign is a representation of the footprint of the event (_did + _delegateAgentId + _responsibleAgentId + _activityId) Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _delegateAgentId address refers to address acting on behalf of the provenance record _responsibleAgentId address refers to address responsible of the provenance record _activityId bytes32 refers to activity _signatureDelegate bytes refers to the digital signature provided by the did delegate. _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description success bytes32 true if the action was properly registered ### addDIDProvider function addDIDProvider ( bytes32 _did , address _provider ) external addDIDProvider add new DID provider. it adds new DID provider to the providers list. A provider is any entity that can serve the registered asset Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address. removeDIDProvider \u00b6 function removeDIDProvider ( bytes32 _did , address _provider ) external removeDIDProvider delete an existing DID provider. Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address. addDIDProvenanceDelegate \u00b6 function addDIDProvenanceDelegate ( bytes32 _did , address _delegate ) public addDIDProvenanceDelegate add new DID provenance delegate. it adds new DID provenance delegate to the delegates list. A delegate is any entity that interact with the provenance entries of one DID Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegates's address. removeDIDProvenanceDelegate \u00b6 function removeDIDProvenanceDelegate ( bytes32 _did , address _delegate ) external removeDIDProvenanceDelegate delete an existing DID delegate. Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegate's address. transferDIDOwnership \u00b6 function transferDIDOwnership ( bytes32 _did , address _newOwner ) external transferDIDOwnership transfer DID ownership Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _newOwner address new owner address grantPermission \u00b6 function grantPermission ( bytes32 _did , address _grantee ) external grantPermission grants access permission to grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address revokePermission \u00b6 function revokePermission ( bytes32 _did , address _grantee ) external revokePermission revokes access permission from grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address getPermission \u00b6 function getPermission ( bytes32 _did , address _grantee ) external returns ( bool ) getPermission gets access permission of a grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address Return Values: \u00b6 Name Type Description true bytes32 if grantee has access permission to a DID ### isDIDProvider function isDIDProvider ( bytes32 _did , address _provider ) public returns ( bool ) isDIDProvider check whether a given DID provider exists Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address. getDIDRegister \u00b6 function getDIDRegister ( bytes32 _did ) public returns ( address owner , bytes32 lastChecksum , string url , address lastUpdatedBy , uint256 blockNumberUpdated , address [] providers , uint256 nftSupply , uint256 mintCap , uint256 royalties ) Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). Return Values: \u00b6 Name Type Description owner bytes32 the did owner lastChecksum url lastUpdatedBy blockNumberUpdated getBlockNumberUpdated \u00b6 function getBlockNumberUpdated ( bytes32 _did ) public returns ( uint256 blockNumberUpdated ) Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). Return Values: \u00b6 Name Type Description blockNumberUpdated bytes32 last modified (update) block number of a DID. ### getDIDOwner function getDIDOwner ( bytes32 _did ) public returns ( address didOwner ) Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). Return Values: \u00b6 Name Type Description didOwner bytes32 the address of the DID owner. ### getDIDRegistrySize function getDIDRegistrySize ( ) public returns ( uint256 size ) Return Values: \u00b6 Name Type Description size the length of the DID registry. ### getDIDRegisterIds function getDIDRegisterIds ( ) public returns ( bytes32 []) Return Values: \u00b6 Name Type Description the length of the DID registry. ### _grantPermission function _grantPermission ( bytes32 _did , address _grantee ) internal _grantPermission grants access permission to grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address _revokePermission \u00b6 function _revokePermission ( bytes32 _did , address _grantee ) internal _revokePermission revokes access permission from grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address _getPermission \u00b6 function _getPermission ( bytes32 _did , address _grantee ) internal returns ( bool ) _getPermission gets access permission of a grantee Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address Return Values: \u00b6 Name Type Description true bytes32 if grantee has access permission to a DID ### getProvenanceEntry function getProvenanceEntry ( bytes32 _provId ) public returns ( bytes32 did , bytes32 relatedDid , address agentId , bytes32 activityId , address agentInvolvedId , uint8 method , address createdBy , uint256 blockNumberUpdated , bytes signature ) Fetch the complete provenance entry attributes Parameters: \u00b6 Name Type Description _provId bytes32 refers to the provenance identifier Return Values: \u00b6 Name Type Description did bytes32 relatedDid activityId agentInvolvedId createdBy blockNumberUpdated signature isDIDOwner \u00b6 function isDIDOwner ( address _address , bytes32 _did ) public returns ( bool ) isDIDOwner check whether a given address is owner for a DID Parameters: \u00b6 Name Type Description _address address user address. _did bytes32 refers to decentralized identifier (a bytes32 length ID). isOwnerProviderOrDelegate \u00b6 function isOwnerProviderOrDelegate ( bytes32 _did ) public returns ( bool ) isOwnerProviderOrDelegate check whether msg.sender is owner, provider or delegate for a DID given Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). Return Values: \u00b6 Name Type Description boolean bytes32 true if yes ### isProvenanceDelegate function isProvenanceDelegate ( bytes32 _did , address _delegate ) public returns ( bool ) isProvenanceDelegate check whether a given DID delegate exists Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegate's address. Return Values: \u00b6 Name Type Description boolean bytes32 true if yes ### getProvenanceOwner function getProvenanceOwner ( bytes32 _did ) public returns ( address provenanceOwner ) Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). Return Values: \u00b6 Name Type Description provenanceOwner bytes32 the address of the Provenance owner. ## Events ### DIDAttributeRegistered event DIDAttributeRegistered ( ) DID Events DIDProviderRemoved \u00b6 event DIDProviderRemoved ( ) DIDProviderAdded \u00b6 event DIDProviderAdded ( ) DIDOwnershipTransferred \u00b6 event DIDOwnershipTransferred ( ) DIDPermissionGranted \u00b6 event DIDPermissionGranted ( ) DIDPermissionRevoked \u00b6 event DIDPermissionRevoked ( ) DIDProvenanceDelegateRemoved \u00b6 event DIDProvenanceDelegateRemoved ( ) DIDProvenanceDelegateAdded \u00b6 event DIDProvenanceDelegateAdded ( )","title":"DIDFactory"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#initialize","text":"function initialize ( address _owner ) public DIDRegistry Initializer Initialize Ownable. Only on contract creation.","title":"initialize"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters","text":"Name Type Description _owner address refers to the owner of the contract.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#registerattribute","text":"function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] _url ) public returns ( uint256 size ) Register DID attributes. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info.","title":"registerAttribute"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_1","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _url address[] refers to the attribute value, limited to 2048 bytes.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values","text":"Name Type Description size bytes32 refers to the size of the registry after the register action. ### registerDID function registerDID ( bytes32 _did , bytes32 _checksum , address [] _providers , string _url , bytes32 _activityId , string _attributes ) public returns ( uint256 size ) Register DID attributes. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info.","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_2","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _providers address[] list of addresses that can act as an asset provider _url string refers to the url resolving the DID into a DID Document (DDO), limited to 2048 bytes. _activityId bytes32 refers to activity _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_1","text":"Name Type Description size bytes32 refers to the size of the registry after the register action. ### areRoyaltiesValid function areRoyaltiesValid ( bytes32 _did , uint256 [] _amounts , address [] _receivers ) public returns ( bool ) areRoyaltiesValid checks if for a given DID and rewards distribution, this allocate the original creator royalties properly","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_3","text":"Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _amounts uint256[] refers to the amounts to reward _receivers address[] refers to the receivers of rewards","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_2","text":"Name Type Description true bytes32 if the rewards distribution respect the original creator royalties ### wasGeneratedBy function wasGeneratedBy ( ) internal returns ( bool )","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#used","text":"function used ( ) public returns ( bool success )","title":"used"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#wasderivedfrom","text":"function wasDerivedFrom ( ) public returns ( bool success )","title":"wasDerivedFrom"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#wasassociatedwith","text":"function wasAssociatedWith ( ) public returns ( bool success )","title":"wasAssociatedWith"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#actedonbehalf","text":"function actedOnBehalf ( bytes32 _provId , bytes32 _did , address _delegateAgentId , address _responsibleAgentId , bytes32 _activityId , bytes _signatureDelegate , string _attributes ) public returns ( bool success ) Implements the W3C PROV Delegation action Each party involved in this method (_delegateAgentId & _responsibleAgentId) must provide a valid signature. The content to sign is a representation of the footprint of the event (_did + _delegateAgentId + _responsibleAgentId + _activityId)","title":"actedOnBehalf"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_4","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _delegateAgentId address refers to address acting on behalf of the provenance record _responsibleAgentId address refers to address responsible of the provenance record _activityId bytes32 refers to activity _signatureDelegate bytes refers to the digital signature provided by the did delegate. _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_3","text":"Name Type Description success bytes32 true if the action was properly registered ### addDIDProvider function addDIDProvider ( bytes32 _did , address _provider ) external addDIDProvider add new DID provider. it adds new DID provider to the providers list. A provider is any entity that can serve the registered asset","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_5","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#removedidprovider","text":"function removeDIDProvider ( bytes32 _did , address _provider ) external removeDIDProvider delete an existing DID provider.","title":"removeDIDProvider"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_6","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#adddidprovenancedelegate","text":"function addDIDProvenanceDelegate ( bytes32 _did , address _delegate ) public addDIDProvenanceDelegate add new DID provenance delegate. it adds new DID provenance delegate to the delegates list. A delegate is any entity that interact with the provenance entries of one DID","title":"addDIDProvenanceDelegate"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_7","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegates's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#removedidprovenancedelegate","text":"function removeDIDProvenanceDelegate ( bytes32 _did , address _delegate ) external removeDIDProvenanceDelegate delete an existing DID delegate.","title":"removeDIDProvenanceDelegate"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_8","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegate's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#transferdidownership","text":"function transferDIDOwnership ( bytes32 _did , address _newOwner ) external transferDIDOwnership transfer DID ownership","title":"transferDIDOwnership"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_9","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _newOwner address new owner address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#grantpermission","text":"function grantPermission ( bytes32 _did , address _grantee ) external grantPermission grants access permission to grantee","title":"grantPermission"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_10","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#revokepermission","text":"function revokePermission ( bytes32 _did , address _grantee ) external revokePermission revokes access permission from grantee","title":"revokePermission"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_11","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#getpermission","text":"function getPermission ( bytes32 _did , address _grantee ) external returns ( bool ) getPermission gets access permission of a grantee","title":"getPermission"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_12","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_4","text":"Name Type Description true bytes32 if grantee has access permission to a DID ### isDIDProvider function isDIDProvider ( bytes32 _did , address _provider ) public returns ( bool ) isDIDProvider check whether a given DID provider exists","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_13","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _provider address provider's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#getdidregister","text":"function getDIDRegister ( bytes32 _did ) public returns ( address owner , bytes32 lastChecksum , string url , address lastUpdatedBy , uint256 blockNumberUpdated , address [] providers , uint256 nftSupply , uint256 mintCap , uint256 royalties )","title":"getDIDRegister"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_14","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_5","text":"Name Type Description owner bytes32 the did owner lastChecksum url lastUpdatedBy blockNumberUpdated","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#getblocknumberupdated","text":"function getBlockNumberUpdated ( bytes32 _did ) public returns ( uint256 blockNumberUpdated )","title":"getBlockNumberUpdated"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_15","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_6","text":"Name Type Description blockNumberUpdated bytes32 last modified (update) block number of a DID. ### getDIDOwner function getDIDOwner ( bytes32 _did ) public returns ( address didOwner )","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_16","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_7","text":"Name Type Description didOwner bytes32 the address of the DID owner. ### getDIDRegistrySize function getDIDRegistrySize ( ) public returns ( uint256 size )","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_8","text":"Name Type Description size the length of the DID registry. ### getDIDRegisterIds function getDIDRegisterIds ( ) public returns ( bytes32 [])","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_9","text":"Name Type Description the length of the DID registry. ### _grantPermission function _grantPermission ( bytes32 _did , address _grantee ) internal _grantPermission grants access permission to grantee","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_17","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#_revokepermission","text":"function _revokePermission ( bytes32 _did , address _grantee ) internal _revokePermission revokes access permission from grantee","title":"_revokePermission"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_18","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#_getpermission","text":"function _getPermission ( bytes32 _did , address _grantee ) internal returns ( bool ) _getPermission gets access permission of a grantee","title":"_getPermission"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_19","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID) _grantee address address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_10","text":"Name Type Description true bytes32 if grantee has access permission to a DID ### getProvenanceEntry function getProvenanceEntry ( bytes32 _provId ) public returns ( bytes32 did , bytes32 relatedDid , address agentId , bytes32 activityId , address agentInvolvedId , uint8 method , address createdBy , uint256 blockNumberUpdated , bytes signature ) Fetch the complete provenance entry attributes","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_20","text":"Name Type Description _provId bytes32 refers to the provenance identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_11","text":"Name Type Description did bytes32 relatedDid activityId agentInvolvedId createdBy blockNumberUpdated signature","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#isdidowner","text":"function isDIDOwner ( address _address , bytes32 _did ) public returns ( bool ) isDIDOwner check whether a given address is owner for a DID","title":"isDIDOwner"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_21","text":"Name Type Description _address address user address. _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#isownerproviderordelegate","text":"function isOwnerProviderOrDelegate ( bytes32 _did ) public returns ( bool ) isOwnerProviderOrDelegate check whether msg.sender is owner, provider or delegate for a DID given","title":"isOwnerProviderOrDelegate"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_22","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_12","text":"Name Type Description boolean bytes32 true if yes ### isProvenanceDelegate function isProvenanceDelegate ( bytes32 _did , address _delegate ) public returns ( bool ) isProvenanceDelegate check whether a given DID delegate exists","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_23","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _delegate address delegate's address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_13","text":"Name Type Description boolean bytes32 true if yes ### getProvenanceOwner function getProvenanceOwner ( bytes32 _did ) public returns ( address provenanceOwner )","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#parameters_24","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID).","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#return-values_14","text":"Name Type Description provenanceOwner bytes32 the address of the Provenance owner. ## Events ### DIDAttributeRegistered event DIDAttributeRegistered ( ) DID Events","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didproviderremoved","text":"event DIDProviderRemoved ( )","title":"DIDProviderRemoved"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didprovideradded","text":"event DIDProviderAdded ( )","title":"DIDProviderAdded"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didownershiptransferred","text":"event DIDOwnershipTransferred ( )","title":"DIDOwnershipTransferred"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didpermissiongranted","text":"event DIDPermissionGranted ( )","title":"DIDPermissionGranted"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didpermissionrevoked","text":"event DIDPermissionRevoked ( )","title":"DIDPermissionRevoked"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didprovenancedelegateremoved","text":"event DIDProvenanceDelegateRemoved ( )","title":"DIDProvenanceDelegateRemoved"},{"location":"architecture/contracts/contracts/registry/DIDFactory/#didprovenancedelegateadded","text":"event DIDProvenanceDelegateAdded ( )","title":"DIDProvenanceDelegateAdded"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/","text":"Implementation of a Mintable DID Registry. Functions \u00b6 initialize \u00b6 function initialize ( address _owner ) public DIDRegistry Initializer Initialize Ownable. Only on contract creation. Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract. registerMintableDID \u00b6 function registerMintableDID ( bytes32 _did , bytes32 _checksum , address [] _providers , string _url , uint256 _cap , uint8 _royalties , bytes32 _activityId , string _attributes ) public returns ( uint256 size ) Register a Mintable DID. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info. Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _providers address[] list of addresses that can act as an asset provider _url string refers to the url resolving the DID into a DID Document (DDO), limited to 2048 bytes. _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market _activityId bytes32 refers to activity _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description size bytes32 refers to the size of the registry after the register action. ### enableAndMintDidNft function enableAndMintDidNft ( bytes32 _did , uint256 _cap , uint8 _royalties , bool _preMint ) public returns ( bool success ) enableDidNft creates the initial setup of NFTs minting and royalties distribution. After this initial setup, this data can't be changed anymore for the DID given, even for the owner of the DID. The reason of this is to avoid minting additional NFTs after the initial agreement, what could affect the valuation of NFTs of a DID already created. update the DID registry providers list by adding the mintCap and royalties configuration Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market _preMint bool if is true mint directly the amount capped tokens and lock in the _lockAddress mint \u00b6 function mint ( bytes32 _did , uint256 _amount ) public Mints a NFT associated to the DID Because ERC-1155 uses uint256 and DID's are bytes32, there is a conversion between both Only the DID owner can mint NFTs associated to the DID Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _amount uint256 amount to mint burn \u00b6 function burn ( bytes32 _did , uint256 _amount ) public Burns NFTs associated to the DID Because ERC-1155 uses uint256 and DID's are bytes32, there is a conversion between both Only the DID owner can burn NFTs associated to the DID Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _amount uint256 amount to burn","title":"DIDRegistry"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#initialize","text":"function initialize ( address _owner ) public DIDRegistry Initializer Initialize Ownable. Only on contract creation.","title":"initialize"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#parameters","text":"Name Type Description _owner address refers to the owner of the contract.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#registermintabledid","text":"function registerMintableDID ( bytes32 _did , bytes32 _checksum , address [] _providers , string _url , uint256 _cap , uint8 _royalties , bytes32 _activityId , string _attributes ) public returns ( uint256 size ) Register a Mintable DID. The first attribute of a DID registered sets the DID owner. Subsequent updates record _checksum and update info.","title":"registerMintableDID"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#parameters_1","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _checksum bytes32 includes a one-way HASH calculated using the DDO content. _providers address[] list of addresses that can act as an asset provider _url string refers to the url resolving the DID into a DID Document (DDO), limited to 2048 bytes. _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market _activityId bytes32 refers to activity _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#return-values","text":"Name Type Description size bytes32 refers to the size of the registry after the register action. ### enableAndMintDidNft function enableAndMintDidNft ( bytes32 _did , uint256 _cap , uint8 _royalties , bool _preMint ) public returns ( bool success ) enableDidNft creates the initial setup of NFTs minting and royalties distribution. After this initial setup, this data can't be changed anymore for the DID given, even for the owner of the DID. The reason of this is to avoid minting additional NFTs after the initial agreement, what could affect the valuation of NFTs of a DID already created. update the DID registry providers list by adding the mintCap and royalties configuration","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#parameters_2","text":"Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market _preMint bool if is true mint directly the amount capped tokens and lock in the _lockAddress","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#mint","text":"function mint ( bytes32 _did , uint256 _amount ) public Mints a NFT associated to the DID Because ERC-1155 uses uint256 and DID's are bytes32, there is a conversion between both Only the DID owner can mint NFTs associated to the DID","title":"mint"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#parameters_3","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _amount uint256 amount to mint","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#burn","text":"function burn ( bytes32 _did , uint256 _amount ) public Burns NFTs associated to the DID Because ERC-1155 uses uint256 and DID's are bytes32, there is a conversion between both Only the DID owner can burn NFTs associated to the DID","title":"burn"},{"location":"architecture/contracts/contracts/registry/DIDRegistry/#parameters_4","text":"Name Type Description _did bytes32 refers to decentralized identifier (a bytes32 length ID). _amount uint256 amount to burn","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/","text":"All function calls are currently implemented without side effects Functions \u00b6 update \u00b6 function update ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , bytes32 _checksum , string _url ) external returns ( uint256 size ) update the DID store access modifiers and storage pointer should be implemented in DIDRegistry Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _checksum bytes32 includes a one-way HASH calculated using the DDO content _url string includes the url resolving to the DID Document (DDO) initializeNftConfig \u00b6 function initializeNftConfig ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , uint256 _cap , uint8 _royalties ) internal initializeNftConfig creates the initial setup of NFTs minting and royalties distribution. After this initial setup, this data can't be changed anymore for the DID given, even for the owner of the DID. The reason of this is to avoid minting additional NFTs after the initial agreement, what could affect the valuation of NFTs of a DID already created. update the DID registry providers list by adding the mintCap and royalties configuration Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market The royalties in secondary market for the creator should be between 0% >= x < 100% areRoyaltiesValid \u00b6 function areRoyaltiesValid ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , uint256 [] _amounts , address [] _receivers ) internal returns ( bool ) areRoyaltiesValid checks if for a given DID and rewards distribution, this allocate the original creator royalties properly Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _amounts uint256[] refers to the amounts to reward _receivers address[] refers to the receivers of rewards Return Values: \u00b6 Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the rewards distribution respect the original creator royalties ### addProvider function addProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address provider ) internal addProvider add provider to DID registry update the DID registry providers list by adding a new provider Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) provider address the provider's address removeProvider \u00b6 function removeProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _provider ) internal returns ( bool ) removeProvider remove provider from DID registry update the DID registry providers list by removing an existing provider Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _provider address the provider's address updateDIDOwner \u00b6 function updateDIDOwner ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _newOwner ) internal updateDIDOwner transfer DID ownership to a new owner Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _newOwner address the new DID owner address isProvider \u00b6 function isProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _provider ) public returns ( bool ) isProvider check whether DID provider exists Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _provider address the provider's address Return Values: \u00b6 Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the provider already exists ### addDelegate function addDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address delegate ) internal addDelegate add delegate to DID registry update the DID registry delegates list by adding a new delegate Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) delegate address the delegate's address removeDelegate \u00b6 function removeDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _delegate ) internal returns ( bool ) removeDelegate remove delegate from DID registry update the DID registry delegates list by removing an existing delegate Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _delegate address the delegate's address isDelegate \u00b6 function isDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _delegate ) public returns ( bool ) isDelegate check whether DID delegate exists Parameters: \u00b6 Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _delegate address the delegate's address Return Values: \u00b6 Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the delegate already exists","title":"DIDRegistryLibrary"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#update","text":"function update ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , bytes32 _checksum , string _url ) external returns ( uint256 size ) update the DID store access modifiers and storage pointer should be implemented in DIDRegistry","title":"update"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _checksum bytes32 includes a one-way HASH calculated using the DDO content _url string includes the url resolving to the DID Document (DDO)","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#initializenftconfig","text":"function initializeNftConfig ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , uint256 _cap , uint8 _royalties ) internal initializeNftConfig creates the initial setup of NFTs minting and royalties distribution. After this initial setup, this data can't be changed anymore for the DID given, even for the owner of the DID. The reason of this is to avoid minting additional NFTs after the initial agreement, what could affect the valuation of NFTs of a DID already created. update the DID registry providers list by adding the mintCap and royalties configuration","title":"initializeNftConfig"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_1","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _cap uint256 refers to the mint cap _royalties uint8 refers to the royalties to reward to the DID creator in the secondary market The royalties in secondary market for the creator should be between 0% >= x < 100%","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#areroyaltiesvalid","text":"function areRoyaltiesValid ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , uint256 [] _amounts , address [] _receivers ) internal returns ( bool ) areRoyaltiesValid checks if for a given DID and rewards distribution, this allocate the original creator royalties properly","title":"areRoyaltiesValid"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_2","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _amounts uint256[] refers to the amounts to reward _receivers address[] refers to the receivers of rewards","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#return-values","text":"Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the rewards distribution respect the original creator royalties ### addProvider function addProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address provider ) internal addProvider add provider to DID registry update the DID registry providers list by adding a new provider","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_3","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) provider address the provider's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#removeprovider","text":"function removeProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _provider ) internal returns ( bool ) removeProvider remove provider from DID registry update the DID registry providers list by removing an existing provider","title":"removeProvider"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_4","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _provider address the provider's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#updatedidowner","text":"function updateDIDOwner ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _newOwner ) internal updateDIDOwner transfer DID ownership to a new owner","title":"updateDIDOwner"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_5","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _newOwner address the new DID owner address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#isprovider","text":"function isProvider ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _provider ) public returns ( bool ) isProvider check whether DID provider exists","title":"isProvider"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_6","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _provider address the provider's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#return-values_1","text":"Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the provider already exists ### addDelegate function addDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address delegate ) internal addDelegate add delegate to DID registry update the DID registry delegates list by adding a new delegate","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_7","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) delegate address the delegate's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#removedelegate","text":"function removeDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _delegate ) internal returns ( bool ) removeDelegate remove delegate from DID registry update the DID registry delegates list by removing an existing delegate","title":"removeDelegate"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_8","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _delegate address the delegate's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#isdelegate","text":"function isDelegate ( struct DIDRegistryLibrary . DIDRegisterList _self , bytes32 _did , address _delegate ) public returns ( bool ) isDelegate check whether DID delegate exists","title":"isDelegate"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#parameters_9","text":"Name Type Description _self struct DIDRegistryLibrary.DIDRegisterList refers to storage pointer _did bytes32 refers to decentralized identifier (a byte32 length ID) _delegate address the delegate's address","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/DIDRegistryLibrary/#return-values_2","text":"Name Type Description true struct DIDRegistryLibrary.DIDRegisterList if the delegate already exists","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/","text":"All function calls are currently implemented without side effects Functions \u00b6 __ProvenanceRegistry_init \u00b6 function __ProvenanceRegistry_init ( ) internal __ProvenanceRegistry_init_unchained \u00b6 function __ProvenanceRegistry_init_unchained ( ) internal createProvenanceEntry \u00b6 function createProvenanceEntry ( bytes32 _provId , bytes32 _did , bytes32 _relatedDid , address _agentId , bytes32 _activityId , address _agentInvolvedId , enum ProvenanceRegistry . ProvenanceMethod _method , address _createdBy , bytes _signatureDelegate ) internal returns ( bool ) create an event in the Provenance store access modifiers and storage pointer should be implemented in ProvenanceRegistry Parameters: \u00b6 Name Type Description _provId bytes32 refers to provenance event identifier _did bytes32 refers to decentralized identifier (a byte32 length ID) _relatedDid bytes32 refers to decentralized identifier (a byte32 length ID) of a related entity _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _agentInvolvedId address refers to address of the agent involved with the provenance record _method enum ProvenanceRegistry.ProvenanceMethod refers to the W3C Provenance method _createdBy address refers to address of the agent triggering the activity _signatureDelegate bytes refers to the digital signature provided by the did delegate. _wasGeneratedBy \u00b6 function _wasGeneratedBy ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool ) Implements the W3C PROV Generation action Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description the bytes32 number of the new provenance size ### _used function _used ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , bytes _signatureUsing , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Usage action Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _signatureUsing bytes refers to the digital signature provided by the agent using the _did _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description success bytes32 true if the action was properly registered ### _wasDerivedFrom function _wasDerivedFrom ( bytes32 _provId , bytes32 _newEntityDid , bytes32 _usedEntityDid , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Derivation action Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _newEntityDid bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _usedEntityDid bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity used to derive the new did _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description success bytes32 true if the action was properly registered ### _wasAssociatedWith function _wasAssociatedWith ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Association action Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description success bytes32 true if the action was properly registered ### _actedOnBehalf function _actedOnBehalf ( bytes32 _provId , bytes32 _did , address _delegateAgentId , address _responsibleAgentId , bytes32 _activityId , bytes _signatureDelegate , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Delegation action Each party involved in this method (_delegateAgentId & _responsibleAgentId) must provide a valid signature. The content to sign is a representation of the footprint of the event (_did + _delegateAgentId + _responsibleAgentId + _activityId) Parameters: \u00b6 Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _delegateAgentId address refers to address acting on behalf of the provenance record _responsibleAgentId address refers to address responsible of the provenance record _activityId bytes32 refers to activity _signatureDelegate bytes refers to the digital signature provided by the did delegate. _attributes string refers to the provenance attributes Return Values: \u00b6 Name Type Description success bytes32 true if the action was properly registered ## Events ### ProvenanceAttributeRegistered event ProvenanceAttributeRegistered ( ) Provenance Events WasGeneratedBy \u00b6 event WasGeneratedBy ( ) Used \u00b6 event Used ( ) WasDerivedFrom \u00b6 event WasDerivedFrom ( ) WasAssociatedWith \u00b6 event WasAssociatedWith ( ) ActedOnBehalf \u00b6 event ActedOnBehalf ( )","title":"ProvenanceRegistry"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#__provenanceregistry_init","text":"function __ProvenanceRegistry_init ( ) internal","title":"__ProvenanceRegistry_init"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#__provenanceregistry_init_unchained","text":"function __ProvenanceRegistry_init_unchained ( ) internal","title":"__ProvenanceRegistry_init_unchained"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#createprovenanceentry","text":"function createProvenanceEntry ( bytes32 _provId , bytes32 _did , bytes32 _relatedDid , address _agentId , bytes32 _activityId , address _agentInvolvedId , enum ProvenanceRegistry . ProvenanceMethod _method , address _createdBy , bytes _signatureDelegate ) internal returns ( bool ) create an event in the Provenance store access modifiers and storage pointer should be implemented in ProvenanceRegistry","title":"createProvenanceEntry"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters","text":"Name Type Description _provId bytes32 refers to provenance event identifier _did bytes32 refers to decentralized identifier (a byte32 length ID) _relatedDid bytes32 refers to decentralized identifier (a byte32 length ID) of a related entity _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _agentInvolvedId address refers to address of the agent involved with the provenance record _method enum ProvenanceRegistry.ProvenanceMethod refers to the W3C Provenance method _createdBy address refers to address of the agent triggering the activity _signatureDelegate bytes refers to the digital signature provided by the did delegate.","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#_wasgeneratedby","text":"function _wasGeneratedBy ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool ) Implements the W3C PROV Generation action","title":"_wasGeneratedBy"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters_1","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#return-values","text":"Name Type Description the bytes32 number of the new provenance size ### _used function _used ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , bytes _signatureUsing , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Usage action","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters_2","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _signatureUsing bytes refers to the digital signature provided by the agent using the _did _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#return-values_1","text":"Name Type Description success bytes32 true if the action was properly registered ### _wasDerivedFrom function _wasDerivedFrom ( bytes32 _provId , bytes32 _newEntityDid , bytes32 _usedEntityDid , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Derivation action","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters_3","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _newEntityDid bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity created _usedEntityDid bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity used to derive the new did _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#return-values_2","text":"Name Type Description success bytes32 true if the action was properly registered ### _wasAssociatedWith function _wasAssociatedWith ( bytes32 _provId , bytes32 _did , address _agentId , bytes32 _activityId , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Association action","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters_4","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _agentId address refers to address of the agent creating the provenance record _activityId bytes32 refers to activity _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#return-values_3","text":"Name Type Description success bytes32 true if the action was properly registered ### _actedOnBehalf function _actedOnBehalf ( bytes32 _provId , bytes32 _did , address _delegateAgentId , address _responsibleAgentId , bytes32 _activityId , bytes _signatureDelegate , string _attributes ) internal returns ( bool success ) Implements the W3C PROV Delegation action Each party involved in this method (_delegateAgentId & _responsibleAgentId) must provide a valid signature. The content to sign is a representation of the footprint of the event (_did + _delegateAgentId + _responsibleAgentId + _activityId)","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#parameters_5","text":"Name Type Description _provId bytes32 unique identifier referring to the provenance entry _did bytes32 refers to decentralized identifier (a bytes32 length ID) of the entity _delegateAgentId address refers to address acting on behalf of the provenance record _responsibleAgentId address refers to address responsible of the provenance record _activityId bytes32 refers to activity _signatureDelegate bytes refers to the digital signature provided by the did delegate. _attributes string refers to the provenance attributes","title":"Parameters:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#return-values_4","text":"Name Type Description success bytes32 true if the action was properly registered ## Events ### ProvenanceAttributeRegistered event ProvenanceAttributeRegistered ( ) Provenance Events","title":"Return Values:"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#wasgeneratedby","text":"event WasGeneratedBy ( )","title":"WasGeneratedBy"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#used","text":"event Used ( )","title":"Used"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#wasderivedfrom","text":"event WasDerivedFrom ( )","title":"WasDerivedFrom"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#wasassociatedwith","text":"event WasAssociatedWith ( )","title":"WasAssociatedWith"},{"location":"architecture/contracts/contracts/registry/ProvenanceRegistry/#actedonbehalf","text":"event ActedOnBehalf ( )","title":"ActedOnBehalf"},{"location":"architecture/contracts/contracts/templates/AccessTemplate/","text":"Implementation of Access Agreement Template Access template is use case specific template. Anyone (consumer/provider/publisher) can use this template in order to setup an on-chain SEA. The template is a composite of three basic conditions. Once the agreement is created, the consumer will lock an amount of tokens (as listed in the DID document - off-chain metadata) to the the lock reward contract which in turn will fire an event. ON the other hand the provider is listening to all the emitted events, the provider will catch the event and grant permissions to the consumer through secret store contract, the consumer now is able to download the data set by asking the off-chain component of secret store to decrypt the DID and encrypt it using the consumer's public key. Then the secret store will provide an on-chain proof that the consumer had access to the data set. Finally, the provider can call the escrow reward condition in order to release the payment. Every condition has a time window (time lock and time out). This implies that if the provider didn't grant the access to the consumer through secret store within this time window, the consumer can ask for refund. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress , address _accessConditionAddress , address _lockConditionAddress , address payable _escrowConditionAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access , lock payment and escrow payment conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address _accessConditionAddress address access condition address _lockConditionAddress address lock reward condition contract address _escrowConditionAddress address payable escrow reward contract address","title":"AccessTemplate"},{"location":"architecture/contracts/contracts/templates/AccessTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/AccessTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress , address _accessConditionAddress , address _lockConditionAddress , address payable _escrowConditionAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access , lock payment and escrow payment conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/AccessTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address _accessConditionAddress address access condition address _lockConditionAddress address lock reward condition contract address _escrowConditionAddress address payable escrow reward contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/","text":"Implementation of Agreement Template Agreement template is a reference template where it has the ability to create agreements from whitelisted template Functions \u00b6 createAgreement \u00b6 function createAgreement ( bytes32 _id , bytes32 _did , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts ) public returns ( uint256 size ) createAgreement create new agreement Parameters: \u00b6 Name Type Description _id bytes32 agreement unique identifier _did bytes32 refers to decentralized identifier (a bytes32 length ID). _conditionIds bytes32[] list of condition identifiers _timeLocks uint256[] list of time locks, each time lock will be assigned to the same condition that has the same index _timeOuts uint256[] list of time outs, each time out will be assigned to the same condition that has the same index Return Values: \u00b6 Name Type Description size bytes32 the index of the created agreement ### getConditionTypes function getConditionTypes ( ) public returns ( address []) getConditionTypes gets the conditions addresses list for the current template returns list of condition contracts addresses Return Values: \u00b6 Name Type Description list of conditions contract addresses","title":"AgreementTemplate"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/#createagreement","text":"function createAgreement ( bytes32 _id , bytes32 _did , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts ) public returns ( uint256 size ) createAgreement create new agreement","title":"createAgreement"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/#parameters","text":"Name Type Description _id bytes32 agreement unique identifier _did bytes32 refers to decentralized identifier (a bytes32 length ID). _conditionIds bytes32[] list of condition identifiers _timeLocks uint256[] list of time locks, each time lock will be assigned to the same condition that has the same index _timeOuts uint256[] list of time outs, each time out will be assigned to the same condition that has the same index","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/#return-values","text":"Name Type Description size bytes32 the index of the created agreement ### getConditionTypes function getConditionTypes ( ) public returns ( address []) getConditionTypes gets the conditions addresses list for the current template returns list of condition contracts addresses","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/AgreementTemplate/#return-values_1","text":"Name Type Description list of conditions contract addresses","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/","text":"Functions \u00b6 createAgreement \u00b6 function createAgreement ( bytes32 _id , bytes32 _did , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts , address _accessConsumer ) public returns ( uint256 size ) createAgreement creates agreements through agreement template this function initializes the agreement by setting the DID, conditions ID, timeouts, time locks and the consumer address. The DID provider/owner is automatically detected by the DID Registry Parameters: \u00b6 Name Type Description _id bytes32 SEA agreement unique identifier _did bytes32 Decentralized Identifier (DID) _conditionIds bytes32[] conditions ID associated with the condition types _timeLocks uint256[] the starting point of the time window ,time lock is in block number not seconds _timeOuts uint256[] the ending point of the time window ,time lock is in block number not seconds _accessConsumer address consumer address Return Values: \u00b6 Name Type Description size bytes32 the agreement index ### getAgreementData function getAgreementData ( bytes32 _id ) external returns ( address accessConsumer , address accessProvider ) getAgreementData return the agreement Data Parameters: \u00b6 Name Type Description _id bytes32 SEA agreement unique identifier Return Values: \u00b6 Name Type Description accessConsumer bytes32 the agreement consumer accessProvider the provider addresses ## Events ### AgreementCreated event AgreementCreated ( )","title":"BaseEscrowTemplate"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#createagreement","text":"function createAgreement ( bytes32 _id , bytes32 _did , bytes32 [] _conditionIds , uint256 [] _timeLocks , uint256 [] _timeOuts , address _accessConsumer ) public returns ( uint256 size ) createAgreement creates agreements through agreement template this function initializes the agreement by setting the DID, conditions ID, timeouts, time locks and the consumer address. The DID provider/owner is automatically detected by the DID Registry","title":"createAgreement"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#parameters","text":"Name Type Description _id bytes32 SEA agreement unique identifier _did bytes32 Decentralized Identifier (DID) _conditionIds bytes32[] conditions ID associated with the condition types _timeLocks uint256[] the starting point of the time window ,time lock is in block number not seconds _timeOuts uint256[] the ending point of the time window ,time lock is in block number not seconds _accessConsumer address consumer address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#return-values","text":"Name Type Description size bytes32 the agreement index ### getAgreementData function getAgreementData ( bytes32 _id ) external returns ( address accessConsumer , address accessProvider ) getAgreementData return the agreement Data","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#parameters_1","text":"Name Type Description _id bytes32 SEA agreement unique identifier","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/BaseEscrowTemplate/#return-values_1","text":"Name Type Description accessConsumer bytes32 the agreement consumer accessProvider the provider addresses ## Events ### AgreementCreated event AgreementCreated ( )","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/DIDSalesTemplate/","text":"Implementation of DID Sales Template The DID Sales template supports an scenario where an Asset owner can sell that asset to a new Owner. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing an Asset owner to get transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer DID Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the ownership transfer of an asset from the current owner for a specific DID. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _lockConditionAddress , address _transferConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _lockConditionAddress address lock reward condition contract address _transferConditionAddress address transfer ownership condition contract address _escrowPaymentAddress address payable escrow reward condition contract address","title":"DIDSalesTemplate"},{"location":"architecture/contracts/contracts/templates/DIDSalesTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/DIDSalesTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _lockConditionAddress , address _transferConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/DIDSalesTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _lockConditionAddress address lock reward condition contract address _transferConditionAddress address transfer ownership condition contract address _escrowPaymentAddress address payable escrow reward condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/","text":"Implementation of Agreement Template This is a dynamic template that allows to setup flexible conditions depending on the use case. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address addTemplateCondition \u00b6 function addTemplateCondition ( address _conditionAddress ) external returns ( uint256 length ) addTemplateCondition adds a new condition to the template Parameters: \u00b6 Name Type Description _conditionAddress address condition contract address Return Values: \u00b6 Name Type Description length address conditionTypes array size ### removeLastTemplateCondition function removeLastTemplateCondition ( ) external returns ( address []) removeLastTemplateCondition removes last condition added to the template Return Values: \u00b6 Name Type Description conditionTypes existing in the array","title":"DynamicAccessTemplate"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#addtemplatecondition","text":"function addTemplateCondition ( address _conditionAddress ) external returns ( uint256 length ) addTemplateCondition adds a new condition to the template","title":"addTemplateCondition"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#parameters_1","text":"Name Type Description _conditionAddress address condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#return-values","text":"Name Type Description length address conditionTypes array size ### removeLastTemplateCondition function removeLastTemplateCondition ( ) external returns ( address []) removeLastTemplateCondition removes last condition added to the template","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/DynamicAccessTemplate/#return-values_1","text":"Name Type Description conditionTypes existing in the array","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/EscrowComputeExecutionTemplate/","text":"Implementation of a Compute Execution Agreement Template EscrowComputeExecutionTemplate is use case specific template. Anyone (consumer/provider/publisher) can use this template in order to setup an on-chain SEA. The template is a composite of three basic conditions. Once the agreement is created, the consumer will lock an amount of tokens (as listed in the DID document - off-chain metadata) to the the lock reward contract which in turn will fire an event. ON the other hand the provider is listening to all the emitted events, the provider will catch the event and grant permissions to trigger a computation granting the execution via the ComputeExecutionCondition contract. The consumer now is able to trigger that computation by asking the off-chain gateway to start the execution of a compute workflow. Finally, the provider can call the escrow reward condition in order to release the payment. Every condition has a time window (time lock and time out). This implies that if the provider didn't grant the execution to the consumer within this time window, the consumer can ask for refund. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress , address _computeExecutionConditionAddress , address _lockPaymentConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including service executor condition, lock reward and escrow reward conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address _computeExecutionConditionAddress address service executor condition contract address _lockPaymentConditionAddress address lock reward condition contract address _escrowPaymentAddress address payable escrow reward contract address","title":"EscrowComputeExecutionTemplate"},{"location":"architecture/contracts/contracts/templates/EscrowComputeExecutionTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/EscrowComputeExecutionTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _didRegistryAddress , address _computeExecutionConditionAddress , address _lockPaymentConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including service executor condition, lock reward and escrow reward conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/EscrowComputeExecutionTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _didRegistryAddress address DID registry contract address _computeExecutionConditionAddress address service executor condition contract address _lockPaymentConditionAddress address lock reward condition contract address _escrowPaymentAddress address payable escrow reward contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/NFTAccessTemplate/","text":"Implementation of NFT Access Template The NFT Access template is use case specific template. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing NFT holders to get access to Nevermined services. The template is a composite of 2 basic conditions: - NFT Holding Condition - Access Condition Once the agreement is created, the consumer can demonstrate is holding a NFT for a specific DID. If that's the case the Access condition can be fulfilled by the asset owner or provider and all the agreement is fulfilled. This can be used in scenarios where a data or services owner, can allow users to get access to exclusive services only when they demonstrate the are holding a specific number of NFTs of a DID. This is very useful in use cases like arts. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _nftHolderConditionAddress , address _accessConditionAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _nftHolderConditionAddress address lock reward condition contract address _accessConditionAddress address access condition contract address","title":"NFTAccessTemplate"},{"location":"architecture/contracts/contracts/templates/NFTAccessTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/NFTAccessTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _nftHolderConditionAddress , address _accessConditionAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/NFTAccessTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _nftHolderConditionAddress address lock reward condition contract address _accessConditionAddress address access condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/NFTSalesTemplate/","text":"Implementation of NFT Sales Template The NFT Sales template supports an scenario where a NFT owner can sell that asset to a new Owner. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing a NFT owner to transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer NFT Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the transfer of the NFT from the current owner for a specific DID. Functions \u00b6 initialize \u00b6 function initialize ( address _owner , address _agreementStoreManagerAddress , address _lockPaymentConditionAddress , address _transferConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions. Parameters: \u00b6 Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _lockPaymentConditionAddress address lock reward condition contract address _transferConditionAddress address transfer NFT condition contract address _escrowPaymentAddress address payable escrow reward condition contract address","title":"NFTSalesTemplate"},{"location":"architecture/contracts/contracts/templates/NFTSalesTemplate/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/NFTSalesTemplate/#initialize","text":"function initialize ( address _owner , address _agreementStoreManagerAddress , address _lockPaymentConditionAddress , address _transferConditionAddress , address payable _escrowPaymentAddress ) external initialize init the contract with the following parameters. this function is called only once during the contract initialization. It initializes the ownable feature, and set push the required condition types including access secret store, lock reward and escrow reward conditions.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/NFTSalesTemplate/#parameters","text":"Name Type Description _owner address contract's owner account address _agreementStoreManagerAddress address agreement store manager contract address _lockPaymentConditionAddress address lock reward condition contract address _transferConditionAddress address transfer NFT condition contract address _escrowPaymentAddress address payable escrow reward condition contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/","text":"Implementation of the Template Store Library. Templates are blueprints for modular SEAs. When creating an Agreement, a templateId defines the condition and reward types that are instantiated in the ConditionStore. Functions \u00b6 propose \u00b6 function propose ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal returns ( uint256 size ) propose new template Parameters: \u00b6 Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address proposed template contract address Return Values: \u00b6 Name Type Description size struct TemplateStoreLibrary.TemplateList which is the index of the proposed template ### approve function approve ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal approve new template Parameters: \u00b6 Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address proposed template contract address revoke \u00b6 function revoke ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal revoke new template Parameters: \u00b6 Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address approved template contract address","title":"TemplateStoreLibrary"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#propose","text":"function propose ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal returns ( uint256 size ) propose new template","title":"propose"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#parameters","text":"Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address proposed template contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#return-values","text":"Name Type Description size struct TemplateStoreLibrary.TemplateList which is the index of the proposed template ### approve function approve ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal approve new template","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#parameters_1","text":"Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address proposed template contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#revoke","text":"function revoke ( struct TemplateStoreLibrary . TemplateList _self , address _id ) internal revoke new template","title":"revoke"},{"location":"architecture/contracts/contracts/templates/TemplateStoreLibrary/#parameters_2","text":"Name Type Description _self struct TemplateStoreLibrary.TemplateList is the TemplateList storage pointer _id address approved template contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/","text":"Implementation of the Template Store Manager. Templates are blueprints for modular SEAs. When creating an Agreement, a templateId defines the condition and reward types that are instantiated in the ConditionStore. This contract manages the life cycle of the template ( Propose \u2192 Approve \u2192 Revoke ). Functions \u00b6 initialize \u00b6 function initialize ( address _owner ) public initialize TemplateStoreManager Initializer Initializes Ownable. Only on contract creation. Parameters: \u00b6 Name Type Description _owner address refers to the owner of the contract proposeTemplate \u00b6 function proposeTemplate ( address _id ) external returns ( uint256 size ) proposeTemplate proposes a new template Parameters: \u00b6 Name Type Description _id address unique template identifier which is basically the template contract address approveTemplate \u00b6 function approveTemplate ( address _id ) external approveTemplate approves a template Parameters: \u00b6 Name Type Description _id address unique template identifier which is basically the template contract address. Only template store manager owner (i.e OPNF) can approve this template. revokeTemplate \u00b6 function revokeTemplate ( address _id ) external revokeTemplate revoke a template Parameters: \u00b6 Name Type Description _id address unique template identifier which is basically the template contract address. Only template store manager owner (i.e OPNF) or template owner can revoke this template. getTemplate \u00b6 function getTemplate ( address _id ) external returns ( enum TemplateStoreLibrary . TemplateState state , address owner , address lastUpdatedBy , uint256 blockNumberUpdated ) getTemplate get more information about a template Parameters: \u00b6 Name Type Description _id address unique template identifier which is basically the template contract address. Return Values: \u00b6 Name Type Description state address template status owner template owner lastUpdatedBy last updated by blockNumberUpdated last updated at. ### getTemplateListSize function getTemplateListSize ( ) external returns ( uint256 size ) getTemplateListSize number of templates Return Values: \u00b6 Name Type Description size number of templates ### isTemplateApproved function isTemplateApproved ( address _id ) external returns ( bool ) isTemplateApproved check whether the template is approved Parameters: \u00b6 Name Type Description _id address unique template identifier which is basically the template contract address. Return Values: \u00b6 Name Type Description true address if the template is approved","title":"TemplateStoreManager"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#initialize","text":"function initialize ( address _owner ) public initialize TemplateStoreManager Initializer Initializes Ownable. Only on contract creation.","title":"initialize"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters","text":"Name Type Description _owner address refers to the owner of the contract","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#proposetemplate","text":"function proposeTemplate ( address _id ) external returns ( uint256 size ) proposeTemplate proposes a new template","title":"proposeTemplate"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters_1","text":"Name Type Description _id address unique template identifier which is basically the template contract address","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#approvetemplate","text":"function approveTemplate ( address _id ) external approveTemplate approves a template","title":"approveTemplate"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters_2","text":"Name Type Description _id address unique template identifier which is basically the template contract address. Only template store manager owner (i.e OPNF) can approve this template.","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#revoketemplate","text":"function revokeTemplate ( address _id ) external revokeTemplate revoke a template","title":"revokeTemplate"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters_3","text":"Name Type Description _id address unique template identifier which is basically the template contract address. Only template store manager owner (i.e OPNF) or template owner can revoke this template.","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#gettemplate","text":"function getTemplate ( address _id ) external returns ( enum TemplateStoreLibrary . TemplateState state , address owner , address lastUpdatedBy , uint256 blockNumberUpdated ) getTemplate get more information about a template","title":"getTemplate"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters_4","text":"Name Type Description _id address unique template identifier which is basically the template contract address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#return-values","text":"Name Type Description state address template status owner template owner lastUpdatedBy last updated by blockNumberUpdated last updated at. ### getTemplateListSize function getTemplateListSize ( ) external returns ( uint256 size ) getTemplateListSize number of templates","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#return-values_1","text":"Name Type Description size number of templates ### isTemplateApproved function isTemplateApproved ( address _id ) external returns ( bool ) isTemplateApproved check whether the template is approved","title":"Return Values:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#parameters_5","text":"Name Type Description _id address unique template identifier which is basically the template contract address.","title":"Parameters:"},{"location":"architecture/contracts/contracts/templates/TemplateStoreManager/#return-values_2","text":"Name Type Description true address if the template is approved","title":"Return Values:"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerChangeFunctionSignature/","text":"Functions \u00b6 createAgreement \u00b6 function createAgreement ( ) public returns ( uint256 size )","title":"AgreementStoreManagerChangeFunctionSignature"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerChangeFunctionSignature/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerChangeFunctionSignature/#createagreement","text":"function createAgreement ( ) public returns ( uint256 size )","title":"createAgreement"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerChangeInStorage/","text":"","title":"AgreementStoreManagerChangeInStorage"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerChangeInStorageAndLogic/","text":"","title":"AgreementStoreManagerChangeInStorageAndLogic"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerExtraFunctionality/","text":"Functions \u00b6 dummyFunction \u00b6 function dummyFunction ( ) public returns ( bool )","title":"AgreementStoreManagerExtraFunctionality"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerExtraFunctionality/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerExtraFunctionality/#dummyfunction","text":"function dummyFunction ( ) public returns ( bool )","title":"dummyFunction"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerWithBug/","text":"Functions \u00b6 getAgreementListSize \u00b6 function getAgreementListSize ( ) public returns ( uint256 size )","title":"AgreementStoreManagerWithBug"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerWithBug/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/AgreementStoreManager/AgreementStoreManagerWithBug/#getagreementlistsize","text":"function getAgreementListSize ( ) public returns ( uint256 size )","title":"getAgreementListSize"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreChangeFunctionSignature/","text":"Functions \u00b6 createCondition \u00b6 function createCondition ( ) public returns ( uint256 size )","title":"ConditionStoreChangeFunctionSignature"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreChangeFunctionSignature/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreChangeFunctionSignature/#createcondition","text":"function createCondition ( ) public returns ( uint256 size )","title":"createCondition"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreChangeInStorage/","text":"","title":"ConditionStoreChangeInStorage"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreChangeInStorageAndLogic/","text":"","title":"ConditionStoreChangeInStorageAndLogic"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreExtraFunctionality/","text":"Functions \u00b6 dummyFunction \u00b6 function dummyFunction ( ) public returns ( bool )","title":"ConditionStoreExtraFunctionality"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreExtraFunctionality/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreExtraFunctionality/#dummyfunction","text":"function dummyFunction ( ) public returns ( bool )","title":"dummyFunction"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreWithBug/","text":"Functions \u00b6 getConditionState \u00b6 function getConditionState ( ) public returns ( enum ConditionStoreLibrary . ConditionState )","title":"ConditionStoreWithBug"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreWithBug/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/ConditionStoreManager/ConditionStoreWithBug/#getconditionstate","text":"function getConditionState ( ) public returns ( enum ConditionStoreLibrary . ConditionState )","title":"getConditionState"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryChangeFunctionSignature/","text":"Functions \u00b6 registerAttribute \u00b6 function registerAttribute ( ) public returns ( uint256 size )","title":"DIDRegistryChangeFunctionSignature"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryChangeFunctionSignature/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryChangeFunctionSignature/#registerattribute","text":"function registerAttribute ( ) public returns ( uint256 size )","title":"registerAttribute"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryChangeInStorage/","text":"","title":"DIDRegistryChangeInStorage"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryChangeInStorageAndLogic/","text":"","title":"DIDRegistryChangeInStorageAndLogic"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryExtraFunctionality/","text":"Functions \u00b6 getNumber \u00b6 function getNumber ( ) public returns ( uint256 )","title":"DIDRegistryExtraFunctionality"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryExtraFunctionality/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryExtraFunctionality/#getnumber","text":"function getNumber ( ) public returns ( uint256 )","title":"getNumber"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryWithBug/","text":"Functions \u00b6 registerAttribute \u00b6 function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] _url ) public returns ( uint256 size ) registerAttribute is called only by DID owner. this function registers DID attributes Parameters: \u00b6 Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _checksum bytes32 includes a one-way HASH calculated using the DDO content _url address[] refers to the attribute value","title":"DIDRegistryWithBug"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryWithBug/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryWithBug/#registerattribute","text":"function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] _url ) public returns ( uint256 size ) registerAttribute is called only by DID owner. this function registers DID attributes","title":"registerAttribute"},{"location":"architecture/contracts/contracts/test/DIDRegistry/DIDRegistryWithBug/#parameters","text":"Name Type Description _did bytes32 refers to decentralized identifier (a byte32 length ID) _checksum bytes32 includes a one-way HASH calculated using the DDO content _url address[] refers to the attribute value","title":"Parameters:"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreChangeFunctionSignature/","text":"Functions \u00b6 proposeTemplate \u00b6 function proposeTemplate ( ) external returns ( uint256 size )","title":"TemplateStoreChangeFunctionSignature"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreChangeFunctionSignature/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreChangeFunctionSignature/#proposetemplate","text":"function proposeTemplate ( ) external returns ( uint256 size )","title":"proposeTemplate"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreChangeInStorage/","text":"","title":"TemplateStoreChangeInStorage"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreChangeInStorageAndLogic/","text":"","title":"TemplateStoreChangeInStorageAndLogic"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreExtraFunctionality/","text":"Functions \u00b6 dummyFunction \u00b6 function dummyFunction ( ) public returns ( bool )","title":"TemplateStoreExtraFunctionality"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreExtraFunctionality/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreExtraFunctionality/#dummyfunction","text":"function dummyFunction ( ) public returns ( bool )","title":"dummyFunction"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreWithBug/","text":"Functions \u00b6 getTemplateListSize \u00b6 function getTemplateListSize ( ) external returns ( uint256 size )","title":"TemplateStoreWithBug"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreWithBug/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/TemplateStoreManager/TemplateStoreWithBug/#gettemplatelistsize","text":"function getTemplateListSize ( ) external returns ( uint256 size )","title":"getTemplateListSize"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/","text":"Functions \u00b6 areRoyaltiesValid \u00b6 function areRoyaltiesValid ( ) public returns ( bool ) updateDIDOwner \u00b6 function updateDIDOwner ( ) public update \u00b6 function update ( ) public returns ( uint256 size ) initializeNftConfig \u00b6 function initializeNftConfig ( ) public getDIDInfo \u00b6 function getDIDInfo ( ) public returns ( address owner , address creator , uint256 royalties )","title":"DIDRegistryLibraryProxy"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#areroyaltiesvalid","text":"function areRoyaltiesValid ( ) public returns ( bool )","title":"areRoyaltiesValid"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#updatedidowner","text":"function updateDIDOwner ( ) public","title":"updateDIDOwner"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#update","text":"function update ( ) public returns ( uint256 size )","title":"update"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#initializenftconfig","text":"function initializeNftConfig ( ) public","title":"initializeNftConfig"},{"location":"architecture/contracts/contracts/test/libraries/DIDRegistryLibraryProxy/#getdidinfo","text":"function getDIDInfo ( ) public returns ( address owner , address creator , uint256 royalties )","title":"getDIDInfo"},{"location":"architecture/contracts/contracts/test/libraries/EpochLibraryProxy/","text":"Functions \u00b6 create \u00b6 function create ( ) external","title":"EpochLibraryProxy"},{"location":"architecture/contracts/contracts/test/libraries/EpochLibraryProxy/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/libraries/EpochLibraryProxy/#create","text":"function create ( ) external","title":"create"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/","text":"Functions \u00b6 initialize \u00b6 function initialize ( ) public hash \u00b6 function hash ( ) public returns ( bytes32 ) add \u00b6 function add ( ) external returns ( bool ) add \u00b6 function add ( ) external returns ( bool ) update \u00b6 function update ( ) external returns ( bool ) index \u00b6 function index ( ) external returns ( bool ) has \u00b6 function has ( ) external returns ( bool ) remove \u00b6 function remove ( ) external returns ( bool ) get \u00b6 function get ( ) external returns ( bytes32 ) size \u00b6 function size ( ) external returns ( uint256 ) all \u00b6 function all ( ) external returns ( bytes32 []) indexOf \u00b6 function indexOf ( ) external returns ( uint256 ) ownedBy \u00b6 function ownedBy ( ) external returns ( address ) isIndexed \u00b6 function isIndexed ( ) external returns ( bool )","title":"HashListLibraryProxy"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#initialize","text":"function initialize ( ) public","title":"initialize"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#hash","text":"function hash ( ) public returns ( bytes32 )","title":"hash"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#add","text":"function add ( ) external returns ( bool )","title":"add"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#add_1","text":"function add ( ) external returns ( bool )","title":"add"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#update","text":"function update ( ) external returns ( bool )","title":"update"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#index","text":"function index ( ) external returns ( bool )","title":"index"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#has","text":"function has ( ) external returns ( bool )","title":"has"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#remove","text":"function remove ( ) external returns ( bool )","title":"remove"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#get","text":"function get ( ) external returns ( bytes32 )","title":"get"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#size","text":"function size ( ) external returns ( uint256 )","title":"size"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#all","text":"function all ( ) external returns ( bytes32 [])","title":"all"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#indexof","text":"function indexOf ( ) external returns ( uint256 )","title":"indexOf"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#ownedby","text":"function ownedBy ( ) external returns ( address )","title":"ownedBy"},{"location":"architecture/contracts/contracts/test/libraries/HashListLibraryProxy/#isindexed","text":"function isIndexed ( ) external returns ( bool )","title":"isIndexed"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/","text":"Implementation of the basic standard multi-token. See https://eips.ethereum.org/EIPS/eip-1155 Originally based on code by Enjin: https://github.com/enjin/erc-1155 Available since v3.1. Functions \u00b6 __NFTUpgradeable_init \u00b6 function __NFTUpgradeable_init ( ) internal See {_setURI}. __ERC1155_init_unchained \u00b6 function __ERC1155_init_unchained ( ) internal uri \u00b6 function uri ( ) external returns ( string ) See {IERC1155MetadataURI-uri}. This implementation returns the same URI for all token types. It relies on the token type ID substitution mechanism https://eips.ethereum.org/EIPS/eip-1155#metadata[defined in the EIP]. Clients calling this function must replace the \\{id\\} substring with the actual token type ID. burn \u00b6 function burn ( ) public burnBatch \u00b6 function burnBatch ( ) public balanceOf \u00b6 function balanceOf ( ) public returns ( uint256 ) See {IERC1155-balanceOf}. Requirements: account cannot be the zero address. balanceOf \u00b6 function balanceOf ( ) external returns ( uint256 ) Returns the amount of tokens of token type id owned by account . Requirements: account cannot be the zero address. balanceOfBatch \u00b6 function balanceOfBatch ( ) public returns ( uint256 []) See {IERC1155-balanceOfBatch}. Requirements: accounts and ids must have the same length. setApprovalForAll \u00b6 function setApprovalForAll ( ) public See {IERC1155-setApprovalForAll}. setProxyApproval \u00b6 function setProxyApproval ( ) public isApprovedForAll \u00b6 function isApprovedForAll ( ) public returns ( bool ) See {IERC1155-isApprovedForAll}. isHolder \u00b6 function isHolder ( ) public returns ( bool ) safeTransferFrom \u00b6 function safeTransferFrom ( ) public See {IERC1155-safeTransferFrom}. safeBatchTransferFrom \u00b6 function safeBatchTransferFrom ( ) public See {IERC1155-safeBatchTransferFrom}. _mint \u00b6 function _mint ( ) internal Creates amount tokens of token type id , and assigns them to account . Emits a {TransferSingle} event. Requirements: account cannot be the zero address. If to refers to a smart contract, it must implement {IERC1155Receiver-onERC1155Received} and return the acceptance magic value. _mintBatch \u00b6 function _mintBatch ( ) internal xref:ROOT:erc1155.adoc#batch-operations[Batched] version of {_mint}. Requirements: ids and amounts must have the same length. If to refers to a smart contract, it must implement {IERC1155Receiver-onERC1155BatchReceived} and return the acceptance magic value. _burn \u00b6 function _burn ( ) internal Destroys amount tokens of token type id from account Requirements: account cannot be the zero address. account must have at least amount tokens of token type id . _burnBatch \u00b6 function _burnBatch ( ) internal xref:ROOT:erc1155.adoc#batch-operations[Batched] version of {_burn}. Requirements: ids and amounts must have the same length. _beforeTokenTransfer \u00b6 function _beforeTokenTransfer ( ) internal Hook that is called before any token transfer. This includes minting and burning, as well as batched variants. The same hook is called on both single and batched variants. For single transfers, the length of the id and amount arrays will be 1. Calling conditions (for each id and amount pair): When from and to are both non-zero, amount of from 's tokens of token type id will be transferred to to . When from is zero, amount tokens of token type id will be minted for to . when to is zero, amount of from 's tokens of token type id will be burned. from and to are never both zero. ids and amounts have the same, non-zero length. To learn more about hooks, head to xref:ROOT:extending-contracts.adoc#using-hooks[Using Hooks].","title":"NFTUpgradeable"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#functions","text":"","title":"Functions"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#__nftupgradeable_init","text":"function __NFTUpgradeable_init ( ) internal See {_setURI}.","title":"__NFTUpgradeable_init"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#__erc1155_init_unchained","text":"function __ERC1155_init_unchained ( ) internal","title":"__ERC1155_init_unchained"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#uri","text":"function uri ( ) external returns ( string ) See {IERC1155MetadataURI-uri}. This implementation returns the same URI for all token types. It relies on the token type ID substitution mechanism https://eips.ethereum.org/EIPS/eip-1155#metadata[defined in the EIP]. Clients calling this function must replace the \\{id\\} substring with the actual token type ID.","title":"uri"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#burn","text":"function burn ( ) public","title":"burn"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#burnbatch","text":"function burnBatch ( ) public","title":"burnBatch"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#balanceof","text":"function balanceOf ( ) public returns ( uint256 ) See {IERC1155-balanceOf}. Requirements: account cannot be the zero address.","title":"balanceOf"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#balanceof_1","text":"function balanceOf ( ) external returns ( uint256 ) Returns the amount of tokens of token type id owned by account . Requirements: account cannot be the zero address.","title":"balanceOf"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#balanceofbatch","text":"function balanceOfBatch ( ) public returns ( uint256 []) See {IERC1155-balanceOfBatch}. Requirements: accounts and ids must have the same length.","title":"balanceOfBatch"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#setapprovalforall","text":"function setApprovalForAll ( ) public See {IERC1155-setApprovalForAll}.","title":"setApprovalForAll"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#setproxyapproval","text":"function setProxyApproval ( ) public","title":"setProxyApproval"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#isapprovedforall","text":"function isApprovedForAll ( ) public returns ( bool ) See {IERC1155-isApprovedForAll}.","title":"isApprovedForAll"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#isholder","text":"function isHolder ( ) public returns ( bool )","title":"isHolder"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#safetransferfrom","text":"function safeTransferFrom ( ) public See {IERC1155-safeTransferFrom}.","title":"safeTransferFrom"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#safebatchtransferfrom","text":"function safeBatchTransferFrom ( ) public See {IERC1155-safeBatchTransferFrom}.","title":"safeBatchTransferFrom"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#_mint","text":"function _mint ( ) internal Creates amount tokens of token type id , and assigns them to account . Emits a {TransferSingle} event. Requirements: account cannot be the zero address. If to refers to a smart contract, it must implement {IERC1155Receiver-onERC1155Received} and return the acceptance magic value.","title":"_mint"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#_mintbatch","text":"function _mintBatch ( ) internal xref:ROOT:erc1155.adoc#batch-operations[Batched] version of {_mint}. Requirements: ids and amounts must have the same length. If to refers to a smart contract, it must implement {IERC1155Receiver-onERC1155BatchReceived} and return the acceptance magic value.","title":"_mintBatch"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#_burn","text":"function _burn ( ) internal Destroys amount tokens of token type id from account Requirements: account cannot be the zero address. account must have at least amount tokens of token type id .","title":"_burn"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#_burnbatch","text":"function _burnBatch ( ) internal xref:ROOT:erc1155.adoc#batch-operations[Batched] version of {_burn}. Requirements: ids and amounts must have the same length.","title":"_burnBatch"},{"location":"architecture/contracts/contracts/token/erc1155/NFTUpgradeable/#_beforetokentransfer","text":"function _beforeTokenTransfer ( ) internal Hook that is called before any token transfer. This includes minting and burning, as well as batched variants. The same hook is called on both single and batched variants. For single transfers, the length of the id and amount arrays will be 1. Calling conditions (for each id and amount pair): When from and to are both non-zero, amount of from 's tokens of token type id will be transferred to to . When from is zero, amount tokens of token type id will be minted for to . when to is zero, amount of from 's tokens of token type id will be burned. from and to are never both zero. ids and amounts have the same, non-zero length. To learn more about hooks, head to xref:ROOT:extending-contracts.adoc#using-hooks[Using Hooks].","title":"_beforeTokenTransfer"},{"location":"architecture/integrations/filecoin/filecoin-storage/","text":"Integration of Filecoin as decentralized storage for Nevermined users \u00b6 shortname: FIL-STO name: Filecoin Storage Integration type: Standard status: Draft version: 0.1 Nevermined is an Open Source solution developed by Keyko , offering the users the ability to build data sharing ecosystems where untrusted parties can share and monetize their data in a way that\u2019s efficient, secure and privacy preserving. As data creation continues to proliferate, entities have the necessity of organising, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing and Data In-Situ Computation solutions that allow organizations to unlock data for a more insights-driven approach. What we call a Data Ecosystem is an environment where independent organizations can cooperate with each other to publish, discover, and access data and the associated assets and services. Nevermined enables the usage of data without the members of these ecosystems having to lose control of their assets. One of the main principles of Nevermined is that Data Owners and Providers always keep control of their data. The solution is designed to be integrated with existing Big Data environments and allows for the execution of models or algorithms in-situ, or where the data resides. With Nevermined, the data never moves; instead the algorithms and models move to where the data sits. Currently Nevermined integrated with the most popular centralized/cloud based storage providers (Amazon S3, Azure, etc.). This document details the integration of Nevermined with Filecoin allowing to: Use Filecoin as one of the options supported allowing Nevermined users to publish & share their data via Filecoin Facilitate access control & data monetization of Filecoin existing data Enable a decentralized storage solution where users don't need to upload their data to any existing centralized solution Nevermined & Filecoin High Level integration Value \u00b6 The integration of Filecoin into Nevermined brings is valuable for Filecoin community because: Increase the usage of Filecoin network Provides utility to Filecoin network via integration with existing and mature Open Source software Filecoin doesn't provide a granular access control allowing the data owners or publishers to decided when, and from whom their data can be accessed Allows user using centralized data storage based on cloud providers to use Filecoin as alternative Nevermined is L2 solution, network independent, and can be deployed in public or private networks. Via this integration, Filecoin could be used in any Nevermined user deployment Nevermined provides compute to the data and provenance (based on W3C PROV) capabilities. Via the integration, the Filecoin community would be able to use high value capabilities on top of their data Integration Details \u00b6 The integration of Filecoin as a fully supported storage provider require the modification and delivery of the following components: The Nevermined Gateway . This component is in charge of making available Nevermined users data. Before this integration the gateway supports different storage providers (Amazon S3, Azure, On Premise, etc.). This integration adds support to Filecoin as storage mechanism allowing to decrypt user urls and resolve Filecoin CIDs. The Nevermined SDKs. To facilitate user adoption, Nevermined support SDKs in 3 different programming languages: Javascript SDK , to facilitate the integration of Nevermined in web interfaces and DApps Python SDK , to facilitate the integration of Nevermined in data science tools It will deliver a modification of the 3 SDKs allowing to the users to publish in Nevermined Filecoin contents (CIDs) Java SDK , to facilitate the integration of Nevermined with existing industry big data solutions. Marketplace . It's a frontend application where users can publish and share files. The intention is to modify this application to support data sharing of assets stored in the Filecoin network. User Flows \u00b6 The final goal is to have a fully functional end to end integration, allowing for the registering of existing Filecoin assets into the Nevermined network: Registering of Filecoin assets into Nevermined After this publishing flow, it's intended to provide the downloading functionality (after access control) of Filecoin contents registered in the Nevermined network: Data Access of Filecoin assets existing into Nevermined Architecture \u00b6 The Nevermined architecture is evolved to integrate Powergate as gateway for supporting Filecoin data store. That integration requires the following modifications: SDKs \u00b6 The publishing flow of Nevermined assets allows to include CIDs as files The consumption flow of Nevermined assets integrates the gateway and work with assets including Filecoin files The SDK will include in the Metadata files attribute a URL using the cid prefix. Example: \"files\" : [ { \"url\" : \"cid://QmW68jbcqSRtqSQb6xkukQ6tfonZGhu1VrZv9zAicNmovs\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"contentType\" : \"text/csv\" , \"encoding\" : \"UTF-8\" , \"compression\" : \"zip\" } ] In the case of a Filecoin asset, the CID included in the url field of the DDO can include the following information: CID Hash - Identifier of the content in the Filecoin network Powergate host - Hostname of the powergate node that can be used to fetch the file Powergate port - Port where is running the powergate service that can be used to fetch the file Powergate token - Token to use to fetch the file Deal Id - Identifier of the Deal that allow to pin the file to IPFS Here some examples of Filecoin CIDs urls: cid://POWERGATE_TOKEN:DEAL_ID@POWERGATE_HOST:POWERGATE_PORT/CID_HASH cid://POWERGATE_HOST:POWERGATE_PORT/CID_HASH cid://POWERGATE_TOKEN:DEAL_ID@CID_HASH cid://POWERGATE_TOKEN:@CID_HASH cid://:DEAL_ID@CID_HASH cid://CID_HASH As in the regular Nevermined Access flow the URL will be encrypted for the client and decrypted during the consumption phase by the gateway. See more about the File Attributes in the Metadata Specs . Gateway integration \u00b6 The Gateway supports the connectivity with the Filecoin network via Powergate. This behavior can be enabled/disabled from the Gateway via configuration. The Gateway support the usage of an existing Filecoin wallet. When a Nevermined asset is resolved and includes a CID, the gateway is capable of resolving that file and return it to the final user The Filecoin connectivity is encapsulated in the Filecoin Driver . Marketplace \u00b6 The visual publishing flow of Nevermined assets allow to include CIDs as files The consumption flow of Nevermined assets integrates the gateway and work with assets including Filecoin files","title":"Filecoin Storage"},{"location":"architecture/integrations/filecoin/filecoin-storage/#integration-of-filecoin-as-decentralized-storage-for-nevermined-users","text":"shortname: FIL-STO name: Filecoin Storage Integration type: Standard status: Draft version: 0.1 Nevermined is an Open Source solution developed by Keyko , offering the users the ability to build data sharing ecosystems where untrusted parties can share and monetize their data in a way that\u2019s efficient, secure and privacy preserving. As data creation continues to proliferate, entities have the necessity of organising, understanding, using and sharing their data internally and externally. Nevermined provides Data Sharing and Data In-Situ Computation solutions that allow organizations to unlock data for a more insights-driven approach. What we call a Data Ecosystem is an environment where independent organizations can cooperate with each other to publish, discover, and access data and the associated assets and services. Nevermined enables the usage of data without the members of these ecosystems having to lose control of their assets. One of the main principles of Nevermined is that Data Owners and Providers always keep control of their data. The solution is designed to be integrated with existing Big Data environments and allows for the execution of models or algorithms in-situ, or where the data resides. With Nevermined, the data never moves; instead the algorithms and models move to where the data sits. Currently Nevermined integrated with the most popular centralized/cloud based storage providers (Amazon S3, Azure, etc.). This document details the integration of Nevermined with Filecoin allowing to: Use Filecoin as one of the options supported allowing Nevermined users to publish & share their data via Filecoin Facilitate access control & data monetization of Filecoin existing data Enable a decentralized storage solution where users don't need to upload their data to any existing centralized solution Nevermined & Filecoin High Level integration","title":"Integration of Filecoin as decentralized storage for Nevermined users"},{"location":"architecture/integrations/filecoin/filecoin-storage/#value","text":"The integration of Filecoin into Nevermined brings is valuable for Filecoin community because: Increase the usage of Filecoin network Provides utility to Filecoin network via integration with existing and mature Open Source software Filecoin doesn't provide a granular access control allowing the data owners or publishers to decided when, and from whom their data can be accessed Allows user using centralized data storage based on cloud providers to use Filecoin as alternative Nevermined is L2 solution, network independent, and can be deployed in public or private networks. Via this integration, Filecoin could be used in any Nevermined user deployment Nevermined provides compute to the data and provenance (based on W3C PROV) capabilities. Via the integration, the Filecoin community would be able to use high value capabilities on top of their data","title":"Value"},{"location":"architecture/integrations/filecoin/filecoin-storage/#integration-details","text":"The integration of Filecoin as a fully supported storage provider require the modification and delivery of the following components: The Nevermined Gateway . This component is in charge of making available Nevermined users data. Before this integration the gateway supports different storage providers (Amazon S3, Azure, On Premise, etc.). This integration adds support to Filecoin as storage mechanism allowing to decrypt user urls and resolve Filecoin CIDs. The Nevermined SDKs. To facilitate user adoption, Nevermined support SDKs in 3 different programming languages: Javascript SDK , to facilitate the integration of Nevermined in web interfaces and DApps Python SDK , to facilitate the integration of Nevermined in data science tools It will deliver a modification of the 3 SDKs allowing to the users to publish in Nevermined Filecoin contents (CIDs) Java SDK , to facilitate the integration of Nevermined with existing industry big data solutions. Marketplace . It's a frontend application where users can publish and share files. The intention is to modify this application to support data sharing of assets stored in the Filecoin network.","title":"Integration Details"},{"location":"architecture/integrations/filecoin/filecoin-storage/#user-flows","text":"The final goal is to have a fully functional end to end integration, allowing for the registering of existing Filecoin assets into the Nevermined network: Registering of Filecoin assets into Nevermined After this publishing flow, it's intended to provide the downloading functionality (after access control) of Filecoin contents registered in the Nevermined network: Data Access of Filecoin assets existing into Nevermined","title":"User Flows"},{"location":"architecture/integrations/filecoin/filecoin-storage/#architecture","text":"The Nevermined architecture is evolved to integrate Powergate as gateway for supporting Filecoin data store. That integration requires the following modifications:","title":"Architecture"},{"location":"architecture/integrations/filecoin/filecoin-storage/#sdks","text":"The publishing flow of Nevermined assets allows to include CIDs as files The consumption flow of Nevermined assets integrates the gateway and work with assets including Filecoin files The SDK will include in the Metadata files attribute a URL using the cid prefix. Example: \"files\" : [ { \"url\" : \"cid://QmW68jbcqSRtqSQb6xkukQ6tfonZGhu1VrZv9zAicNmovs\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"contentType\" : \"text/csv\" , \"encoding\" : \"UTF-8\" , \"compression\" : \"zip\" } ] In the case of a Filecoin asset, the CID included in the url field of the DDO can include the following information: CID Hash - Identifier of the content in the Filecoin network Powergate host - Hostname of the powergate node that can be used to fetch the file Powergate port - Port where is running the powergate service that can be used to fetch the file Powergate token - Token to use to fetch the file Deal Id - Identifier of the Deal that allow to pin the file to IPFS Here some examples of Filecoin CIDs urls: cid://POWERGATE_TOKEN:DEAL_ID@POWERGATE_HOST:POWERGATE_PORT/CID_HASH cid://POWERGATE_HOST:POWERGATE_PORT/CID_HASH cid://POWERGATE_TOKEN:DEAL_ID@CID_HASH cid://POWERGATE_TOKEN:@CID_HASH cid://:DEAL_ID@CID_HASH cid://CID_HASH As in the regular Nevermined Access flow the URL will be encrypted for the client and decrypted during the consumption phase by the gateway. See more about the File Attributes in the Metadata Specs .","title":"SDKs"},{"location":"architecture/integrations/filecoin/filecoin-storage/#gateway-integration","text":"The Gateway supports the connectivity with the Filecoin network via Powergate. This behavior can be enabled/disabled from the Gateway via configuration. The Gateway support the usage of an existing Filecoin wallet. When a Nevermined asset is resolved and includes a CID, the gateway is capable of resolving that file and return it to the final user The Filecoin connectivity is encapsulated in the Filecoin Driver .","title":"Gateway integration"},{"location":"architecture/integrations/filecoin/filecoin-storage/#marketplace","text":"The visual publishing flow of Nevermined assets allow to include CIDs as files The consumption flow of Nevermined assets integrates the gateway and work with assets including Filecoin files","title":"Marketplace"},{"location":"architecture/specs/access/","text":"ACCESS SPEC: Decentralized Access Control \u00b6 shortname: ACCESS name: Decentralized Access Control type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: ACCESS SPEC: Decentralized Access Control Motivation Actors and Technical Components Payment Crypto Currencies Rewards Distribution Royalties in the secondary market Flows Publishing Assets Constructing an Asset DDO Service Agreement Templates Access Execution of the service agreement Lock Payment Condition Grant Access Condition Release Payment Condition Consuming the Data Consuming without direct integration of Secret Store Abort Conditions Encryption and Decryption Encryption Process Authorization Types Using Secret Store Using the Data Gateway PSK ECDSA PSK RSA This SPEC introduces an integration pattern for the use of Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") as contracts between parties interacting in a transaction. This SPEC uses the SEAs as the core element to orchestrate the publish/consume transactions for multiple services. Motivation \u00b6 The main motivations of this SPEC are: Understand how in an environment where different actors don't trust each other, a decentralized access control can work Detail the interaction between parties allowing to grant access to assets in a decentralized manner Identify the API methods exposed via the different libraries Actors and Technical Components \u00b6 PUBLISHERS - Provide access to assets and/or services CONSUMERS - Want to get access to assets and/or services MARKETPLACES - Store the DDO (including metadata) associated with the assets and/or services Note: Below, we write \"assets\" to mean \"assets and/or services.\" The following technical components are involved with the publishing flow or the consumption flow: MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets. SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. SECRET STORE - Included as part of the Parity Ethereum client. Allows the PUBLISHER to encrypt the asset URL. Integrates with the SA to authorize (on-chain) the decryption of the asset URL by the CONSUMER. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). Actors running Components Payment \u00b6 Crypto Currencies \u00b6 Nevermined allows the asset publishers to define the crypto-currencies they accept. This gives the flexibility of decide different payments and prices depending on the currency and the service attached to the asset. In Nevermined is possible to define multiple services (access, compute, transfer ownership, nft sales, etc). Each service can have different payment options depending on publisher interest. This provides a high level of flexibility allowing to get paid using the following options: Payment of a service using the Nevermined ERC20 token Payment using an external ERC20 token Payment using ETH The combination of the above for the same service. What means for the same service I can ask 1000 NVM Tokens, 10 xDAI or 1 ETH. This can be achieved specifying multiple times a service with prices in different currencies. All the prices are expressed in the DDOs with the crypto-currency lower level denominator. This is wei for ETH or drops for any other ERC20 token. This configuration is possible using the _tokenAddress parameter in the LockPayment and EscrowPayment conditions. The value options are: If the value is 0x0 means the payment is in ETH If the value is empty means the payment is in the Nevermined ERC20 Token If the value is an address means the payment is using the ERC20 Token deployed on that address In the following example is using a ETH payment: { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"0x0\" } Rewards Distribution \u00b6 In combination with the above, Nevermined allows the definition of payment schemes where multiple users can be paid for providing a service associated to an asset. For example, it's typical for a marketplace to get a commission for a sale because the infrastructure provided. This can be defined case by case, each marketplace could require different commissions, and can include multiple reward addresses to receive the payment as part of the sales flow. This configuration is possible using the _amounts and _receivers parameters in the LockPayment and EscrowPayment conditions. In the following example, as part of the DDO we define that address starting by 0xa99 is going to receive a payment of 10 drops or wei (depending on the token used), and the address starting by 0x068 a payment of 2. Example: { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [ \"10\" , \"2\" ] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [ \"0xa99d43d86a0758d5632313b8fa3972b6088a21bb\" , \"0x068ed00cf0441e4829d9784fcbe7b9e26d4bd8d0\" ] } Royalties in the secondary market \u00b6 Asset creators can define what are the royalties they want to receive in the secondary market. These royalties must be between 0 and 100 percent. The royalties can not be changed after they are initialized. This protects the buyers of an Asset or NFT to have to pay for a different commission to the one agreed during the purchase of that Asset or NFT. In Nevermined the Assets or NFTs can be transferred, what means the owner can be different to the original creator, but the original creator can't be modified in the Smart Contracts once the asset is defined. Flows \u00b6 This section describes the asset publishing flow and the asset consuming flow in detail. It should be straightforward to implement those flows by reading it, although the actual implementation may deviate slightly. The detailed description is an attempt to account for important edge cases and to create a good reference for the authors of particular implementations. The intention of the Access flow is to be as lean as possible, allowing data sharing solution with low friction. In the below image you can see a high level view of the Nevermined Data Sharing flow: Nevermined Data Sharing flow The following parameters are used: did - Decentralized Identifier (DID). See DID SPEC . agreementId or serviceAgreementId - The unique ID referring to a Service Agreement established between a PUBLISHER and a CONSUMER. The CONSUMER (via SDK) is the one creating this unique ID. serviceDefinitionId - Identifies one service in the array of services included in the DDO. It is created by the PUBLISHER (via SDK) upon DDO creation. templateId - Identifies a unique Service Agreement template. Publishing Assets \u00b6 When a PUBLISHER uses the Nevermined SDK to publish (register) an asset, here is a summary of what the SDK does: Construct a new DDO (JSON object describing the asset). Calculate the checksum of all the services (access, provenance, etc) included as part of the DDO Calculates an unique DID Register using the Smart Contracts the DID, checksum of the DDO and the URL pointing to the METADATA API resolving the DDO Store the DDO off-chain in the METADATA API Those steps are explained in more detail below. The PUBLISHER is able to publish (register) an asset by making a single SDK call. where metadata is a dict containing the METADATA SPEC metadata about the asset. We now expand on the publishing (registration) steps in more detail. Constructing an Asset DDO \u00b6 An asset DDO is a DID Document conforming with the Decentralized Identifiers (DIDs) spec . Validate the metadata to ensure that it conforms with METADATA SPEC . (It should be in \"local metadata\" form at this point.) Compute a DID following DID SPEC . Create an empty DDO and add the following things to it: DID Public key of the PUBLISHER Authentication section (with RSA public key) Encrypt the URLs in the attributes.main.files array of the metadata. The PUBLISHER must specify which encryption service/procedure/plugin they wish to use. That encryption service gets recorded in the asset DDO. For details, see the section about Encryption and Decryption below. Note: This step changes the metadata and also the \"service\" section of the DDO. Sign the checksum using the publisher_account (i.e. compute a signature) and add the computed signature to the proof attribute. Add the rest of the services to the DDO. Each service in the list contains certain information depending on its type. Here we document two types of services required for purchasing and consuming an asset. A service of type \"Access\" contains: Service Definition ID ( serviceDefinitionId ); this helps PUBLISHER find the service definition of a DDO signed by CONSUMER Service Agreement Template ID ( templateId ); points to an unique instance of a template of a Service Agreement Service endpoint ( serviceEndpoint ); CONSUMERS signing this service send their signatures to this endpoint A list of condition keys; condition key is the keccak256 hash of the following: SLA template ID controller contract address (obtained from the solidity contract json file matching the contract name in the SLA condition) controller contract function fingerprint (referred to as function signature or selector) For each condition, a list is required of its parameter values, a timeout, a set of fields determining what conditions depend on other conditions, and a mapping of events emitted by the condition to the off-chain handlers of these events Each event is identified by name. Each event handler is a function from a whitelisted module Service Agreement contract address and the event mapping in the same format as the condition events, for off-chain listeners An integer defining when the agreement is fulfilled in case there are multiple terminal conditions, according to the Service Agreement smart contract A service of type \"Access\" contains 2 different endpoints: serviceEndpoint - A URL to initialize the Service Agreement consumeEndpoint - A URL to fetch data decryption keys from An example of a complete DDO can be found here . Please do note that the condition's order in the DID document should reflect the same order in on-chain service agreement. PUBLISHER registers the DID, associating the asset DID to the METADATA API link that resolves the DID to a DDO. To do that, the SDK needs to integrate the DIDRegistry contract using the registerAttribute method. function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] memory _providers , string memory _value ) The parameters to pass are: bytes32 _did - The hash part of the DID, the part just after did:nv: bytes32 _checksum - The checksum generated after compute the DID address[] _providers - The list of providers which PUBLISHER delegates URL decryption capabilities and SEA management string _value - The Metadata service endpoint. In the above DDO its: http://metadata.org/api/v1/metadata/assets/ddo/{did } Publishing Flow The SMART CONTRACT will emit the DIDAttributeRegistered including the did , checksum and url registered. Service Agreement Templates \u00b6 It represents a standard template of a Service Agreement between parties. A template includes standard conditions allowing to be used by Nevermined users as reference during the negotiation between parties to establish a formal agreement on-chain. A Service Agreement Template includes: * A template identifier: `templateId` * A list of Conditions * Timeouts To facilitate the creation of agreements between parties, the templates provide standard agreements ready to be used during the creation of Service Agreement instances between parties. Interaction with templates can be done via the TemplateStoreManager contract. For the Data Sharing use case, Nevermined provides the EscrowAccessSecretStore template. The EscrowAccessSecretStore Service Agreement template has the following shape: const agreement = { id : id , did : did , templateId : templateId , conditionIds : [ conditionIdAccess , conditionIdLock , conditionIdEscrow ], timeLocks : [ timeLockAccess , 0 , 0 ], timeOuts : [ timeOutAccess , 0 , 0 ], actors : [ actors ] } For the different conditionIds, the CONSUMER needs to generate those and add them to the agreement to be defined on-chain. This requires to generate the hash including the agreementId and all the values of the specific condition: const conditionIdAccess = await accessCondition . generateId ( agreementId , await accessCondition . hashValues ( did , receiver )) const conditionIdLock = await lockPaymentConditon . generateId ( agreementId , await lockPaymentConditon . hashValues ( escrowPayment . address , escrowAmount )) const conditionIdEscrow = await escrowPayment . generateId ( agreementId , await escrowPayment . hashValues ( escrowAmount , receiver , sender , conditionIdLock , conditionIdAccess )) PUBLISHER publishes the DDO in the METADATA API. Access \u00b6 Using SDK calls, a CONSUMER can discover, purchase and get access to assets. Steps for leveraging SDK: The CONSUMER uses the search method to find relevant assets related with his query. It returns a list of DDO's. assets = nevermined.assets.search(\"weather Germany 2019\") The CONSUMER chooses a service inside a DDO (the CONSUMER selects a serviceDefinitionId ). The Service Agreement needs to have an associated unique serviceAgreementId that can be generated/provided by the CONSUMER. In the Smart Contracts, this serviceAgreementId will be stored as a bytes32 . This serviceAgreementId is generated randomly and is represented by a 64-character hex string (using the characters 0-9 and a-f). The CONSUMER can generate the serviceAgreementId using any kind of implementation providing enough randomness to generate this ID (64-characters hex string). The CONSUMER signs the service details. The signature contains (templateId, valuesHashList, timeoutValues, agreementId) . The agreementId is provided by the CONSUMER and has to be globally unique. Each ith item in values_hash_list lists corresponds to the ith condition in conditions list values_hash_list : a hash of the parameters types and values of each condition This signature is used to correlate events and to prevent the PUBLISHER from instantiating multiple Service Agreements from a single request. The CONSUMER sends (did, serviceAgreementId, serviceDefinitionId, signature, consumerAddress ) to the service endpoint (GATEWAY). serviceDefinitionId tells the PUBLISHER where to find the preimage to verify the signature. The DID tells the PUBLISHER which asset to serve under these terms. HTTP POST /api/v1/GATEWAY/services/access/initialize { \"did\": \"did:nv:08a429b8529856d59867503f8056903a680935a76950bb9649785cc97869a43d\", \"serviceAgreementId\": \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\", \"index\": 0, \"signature\": \"cade376598342cdae231321a0097876aeda656a567a67c6767fd8710129a9dc1\", \"consumerAddress\": \"0x00a329c0648769A73afAc7F9381E08FB43dBEA72\" } The execution of this endpoint should return a HTTP 201 if everything goes okay. Satisfactory conditions include: When GATEWAY receives a signature from the service endpoint and verifies the signature. Having the did , GATEWAY fetches the DDO related with this did . GATEWAY records the serviceAgreementId as corresponding to the given did . GATEWAY executes the Service Agreement by calling EscrowAccessSecretStoreTemplate.createAgreement , providing it with the agreementId and all the agreement values GATEWAY starts listening for the publisher events from the events section of the service definition. After receiving the HTTP response confirmation from GATEWAY, the CONSUMER starts listening for the AgreementCreated events specified in the corresponding service definition, filtering them by agreementId . Execution of the service agreement \u00b6 Consider an asset purchase example. CONSUMER locks the payment. Then PUBLISHER grants access to the document. Then payment is released. Now CONSUMER may decrypt the document. In general, there is a broad range of conditions which can be implemented and integrated into the described workflow. Lock Payment Condition \u00b6 Consider a sample of a service definition. \"serviceAgreementTemplate\": { \"contractName\": \"EscrowAccessSecretStoreTemplate\", \"events\": [{ \"name\": \"AgreementCreated\", \"actorType\": \"consumer\", \"handler\": { \"moduleName\": \"escrowAccessSecretStoreTemplate\", \"functionName\": \"fulfillLockPaymentCondition\", \"version\": \"0.1\" } }] } According to this sample, the CONSUMER listens for the AgreementCreated event emitted in the very beginning of Service Agreement execution, filtering it by agreementId . Note that the structure of serviceAgreementContract.events is identical to conditions.events . SDK needs to offer a utility that subscribes the specified callbacks to the events from both lists. When the CONSUMER receives this event it means the agreement is in place and can perform the lock reward: await token.approve(lockPaymentConditon.address, escrowAmount, { from: sender }) await lockPaymentConditon.fulfill(agreementId, escrowPayment.address, escrowAmount) If everything goes right, it will emit LockPaymentCondition.Fulfilled and thus will trigger the next condition. Grant Access Condition \u00b6 PUBLISHER (via GATEWAY) listens for LockPaymentCondition.Fulfilled event filtered by agreementId to confirm the reward was locked by the CONSUMER. \"conditions\": [{ \"events\": [{ \"name\": \"Fulfilled\", \"actorType\": \"publisher\", \"handler\": { \"moduleName\": \"lockPaymentConditon\", \"functionName\": \"fulfillAccessCondition\", \"version\": \"0.1\" } }] }] In this case the PUBLISHER can grant access to the CONSUMER for a specific agreementId and documentId using in this case the AccessCondition.fulfill : await accessCondition.fulfill(agreementId, agreement.did, receiver) If everything goes right, the Smart Contract will emit the AccessCondition.Fulfilled event. Release Payment Condition \u00b6 PUBLISHER (via GATEWAY) listens for AccessCondition.Fulfilled event to transfer tokens to PUBLISHER's account. \"conditions\": [{ \"events\": [{ \"name\": \"Fulfilled\", \"actorType\": \"publisher\", \"handler\": { \"moduleName\": \"access\", \"functionName\": \"fulfillEscrowPaymentCondition\", \"version\": \"0.1\" } }] }] So when the PUBLISHER receives the AccessCondition.Fulfilled he can call the EscrowPayment.fulfill method to receive the reward: await escrowPayment.fulfill(agreementId, escrowAmount, receiver, sender, agreement.conditionIds[1], agreement.conditionIds[0]) Consuming the Data \u00b6 CONSUMER (via SDK) listens for AccessCondition.Fulfilled event to access the document. \"conditions\": [{ \"events\": [{{ \"name\": \"TimedOut\", \"actorType\": \"consumer\", \"handler\": { \"moduleName\": \"access\", \"functionName\": \"fulfillEscrowPaymentCondition\", \"version\": \"0.1\" } }] }] The following are steps that have to be performed by the CONSUMER to receive the data. CONSUMER decrypts the URL using the SDK. This only requires the encryptedUrl existing in the DDO and the DID. A Parity EVM client (local or remote) and SECRET STORE cluster can be used for that. CONSUMER retrieves data by calling the dedicated GATEWAY endpoint ( serviceEndpoint in the service definition) providing it with Consumer ethereum address, service agreement ID, and decrypted URL. The consume URL may look like: HTTP GET /api/v1/GATEWAY/services/access/consume?consumerAddress=${consumerAddress}&serviceAgreementId={serviceAgreementId}&url={url}` This method will return a HTTP 200 status code if everything was okay and the data file. When CONSUMER requests purchased data, GATEWAY gets 3 parameters: Consumer ethereum address: consumerAddress Service Agreement ID: serviceAgreementId Decrypted URL: url . This URL is only valid if GATEWAY acts as a gateway. CONSUMER cannot download using the URL if it's not done through GATEWAY. Using those parameters, GATEWAY does the following things: Find the did by the given serviceAgreementId Verify the given service is allowed to be consumed by the given consumerAddress and did using the checkPermissions method of the SLA Smart Contract. If CONSUMER has permissions to consume, download and provide data for the given DID Consuming Flow Consuming without direct integration of Secret Store \u00b6 If the CONSUMER (via SDK) can't integrate directly SECRET STORE for decryption (nevermined-sdk-js using Metamask can't provide the account password), it's possible to call GATEWAY with an alternative consume method. In this scenario, the GATEWAY is in charge of decrypting the content in behalf of the CONSUMER. The consume URL may look like: HTTP GET /api/v1/gateway/services/access/consume?pubKey=${pubKey}&serviceAgreementId={serviceAgreementId}&signature={signature}&index={index}` This method will return an HTTP 200 status code if everything was okay, plus the URL required to get access to the data. When CONSUMER requests purchased data, GATEWAY gets 3 parameters: Consumer public key: pubKey Service Agreement ID: serviceAgreementId Signature: signature . The signed serviceAgreementId value by the CONSUMER to validate his/her identity Index: index . Integer value representing the position of the content to download in the DDO.files array Abort Conditions \u00b6 Every condition can be fulfilled or aborted using the configured timeout. For example it would allows to the CONSUMER to cancel the payment after locking it but not receiving access to the asset for a long period of time. Mechanisms implemented in the Service Agreement contract ensure there are no race conditions. Encryption and Decryption \u00b6 The PUBLISHER can define how they want to encrypt the URLs included in the attributes.main.files array of the metadata. This information must be added to the DDO to allow CONSUMERs (via SDK) to understand how to deal with the URLs. Below is an example of how to add an encryption service to the service section of a DDO. \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"service\" : \"SecretStore\" , \"serviceEndpoint\" : \"http://secretstore.org:12001\" , \"config\" : { \"threshold\" : 3 }, }, \u2026 ] The encryption service is one object with the following attributes: type - Differentiate this kind of service with the word Authorization index - Existing in all the DDO services to differentiate one entry in the services list serviceEndpoint (optional) - URL used during the encryption and decryption process. attributes.main - List of mandatory attributes specific of the type service - The authorization service type. It could be SecretStore , PSK_ECDSA or PSK_RSA . The encryption/authorization service is optional. If it's not provided, the usual SECRET STORE cluster defined in the SDK configuration will be used. Encryption Process \u00b6 Suppose the attributes.main.files array in the metadata has three URLs: \"files\" : [ { \"url\" : \"https://example.com/data-file-0.csv\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"resourceId\" : \"access-log2018-02-13-15-17-29-18386C502CAEA932\" }, { \"url\" : \"https://example.com/data-file-1.csv\" , \"index\" : 1 , \"checksum\" : \"085340abffh21495345af97c6b0e761\" , \"contentLength\" : \"12324\" }, { \"url\" : \"https://example.com/data-file-2.csv\" , \"index\" : 2 } ] The attributes.main.files array is encrypted as follows. First it is converted into a string like so: [{ \"url\" : \"https://example.com/data-file-0.csv\" , \"index\" : 0 , \u2026 , \"index\" : 2 }] where all spaces are removed (except inside the string values). Also, all newlines, line feeds, and carriage returns are removed. That JSON string can then be encrypted. After encryption, all \"url\" keys and values are removed from the attributes.main.files array objects, and a new attributes.encryptedFiles key and value are added to the metadata, e.g. \"encryptedFiles\" : \"0x2e48ceefcca7abb024f90\u2026f3fec0e1c\" We now describe the supported encryption procedures. Authorization Types \u00b6 The system supports different implementation for managing the authorization of the encryption/decryption of secrets. The authorization type can be found in attributes.main.service attribute. The authorization mechanisms supported are: SecretStore - Parity Secret Store PK-ECDSA - ECDSA Pre-Shared Keys PK-RSA - RSA Pre-Shared Keys Using Secret Store \u00b6 The SECRET STORE cluster to use during the encryption and decryption is specified in the serviceEndpoint attribute, e.g. \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"SecretStore\" , \"threshold\" : \"1\" } }, \"serviceEndpoint\" : \"http://secretstore.org:12001\" }, \u2026 ] More information about the integration of a SECRET STORE can be found Parity Secret Store page . Using the Data Gateway \u00b6 For those clients not able to integrate SECRET STORE directly, GATEWAY will support an encryption endpoint supporting the following parameters: HTTP POST /api/v1/gateway/services/encrypt { \"id\": \"did:nv:08a429b8529856d59867503f8056903a680935a76950bb9649785cc97869a43d\", \"document\": [ { \"url\": \"234ab87234acbd09543085340abffh21983ddhiiee982143827423421\", \"checksum\": \"efb2c764274b745f5fc37f97c6b0e761\", \"contentLength\": \"4535431\", \"resourceId\": \"access-log2018-02-13-15-17-29-18386C502CAEA932\" }, { \"url\": \"234ab87234acbd6894237582309543085340abffh21983ddhiiee982143827423421\", \"checksum\": \"085340abffh21495345af97c6b0e761\", \"contentLength\": \"12324\" }, { \"url\":\"80684089027358963495379879a543085340abffh21983ddhiiee982143827abcc2\" } ] } That is, the value of document should be the attributes.main.files array. This endpoint will return the content encrypted using the GATEWAY account. The GATEWAY will expose the public keys using for encryption in the following endpoint: http://0.0.0.0:8030/ In the JSON returned there will be the *-public-key entries with the different public keys enabled in the GATEWAY: { ... \"ecdsa-public-key\" : \"0xaaaaa\" , \"rsa-public-key\" : \"0xaaaaa\" , ... } PSK ECDSA \u00b6 In a DDO definition, can be defined a Pre-Shared ECDSA mechanism using the following configuration: \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"PSK-ECDSA\" , \"publicKey\" : \"0xaaaa\" // ECDSA Public Key o f t he Ga te way } }, \"serviceEndpoint\" : \"http://mygateway.net/\" }, \u2026 ] PSK RSA \u00b6 In a DDO definition, can be defined a Pre-Shared RSA mechanism using the following configuration: \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"PSK-RSA\" , \"publicKey\" : \"0xaaaa\" // RSA Public Key o f t he Ga te way } }, \"serviceEndpoint\" : \"http://mygateway.net/\" }, \u2026 ]","title":"Access Control"},{"location":"architecture/specs/access/#access-spec-decentralized-access-control","text":"shortname: ACCESS name: Decentralized Access Control type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: ACCESS SPEC: Decentralized Access Control Motivation Actors and Technical Components Payment Crypto Currencies Rewards Distribution Royalties in the secondary market Flows Publishing Assets Constructing an Asset DDO Service Agreement Templates Access Execution of the service agreement Lock Payment Condition Grant Access Condition Release Payment Condition Consuming the Data Consuming without direct integration of Secret Store Abort Conditions Encryption and Decryption Encryption Process Authorization Types Using Secret Store Using the Data Gateway PSK ECDSA PSK RSA This SPEC introduces an integration pattern for the use of Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") as contracts between parties interacting in a transaction. This SPEC uses the SEAs as the core element to orchestrate the publish/consume transactions for multiple services.","title":"ACCESS SPEC: Decentralized Access Control"},{"location":"architecture/specs/access/#motivation","text":"The main motivations of this SPEC are: Understand how in an environment where different actors don't trust each other, a decentralized access control can work Detail the interaction between parties allowing to grant access to assets in a decentralized manner Identify the API methods exposed via the different libraries","title":"Motivation"},{"location":"architecture/specs/access/#actors-and-technical-components","text":"PUBLISHERS - Provide access to assets and/or services CONSUMERS - Want to get access to assets and/or services MARKETPLACES - Store the DDO (including metadata) associated with the assets and/or services Note: Below, we write \"assets\" to mean \"assets and/or services.\" The following technical components are involved with the publishing flow or the consumption flow: MARKETPLACE - Exposes a web interface allowing users to publish and purchase assets. It also facilitates the discovery of assets. SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. SECRET STORE - Included as part of the Parity Ethereum client. Allows the PUBLISHER to encrypt the asset URL. Integrates with the SA to authorize (on-chain) the decryption of the asset URL by the CONSUMER. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). Actors running Components","title":"Actors and Technical Components"},{"location":"architecture/specs/access/#payment","text":"","title":"Payment"},{"location":"architecture/specs/access/#crypto-currencies","text":"Nevermined allows the asset publishers to define the crypto-currencies they accept. This gives the flexibility of decide different payments and prices depending on the currency and the service attached to the asset. In Nevermined is possible to define multiple services (access, compute, transfer ownership, nft sales, etc). Each service can have different payment options depending on publisher interest. This provides a high level of flexibility allowing to get paid using the following options: Payment of a service using the Nevermined ERC20 token Payment using an external ERC20 token Payment using ETH The combination of the above for the same service. What means for the same service I can ask 1000 NVM Tokens, 10 xDAI or 1 ETH. This can be achieved specifying multiple times a service with prices in different currencies. All the prices are expressed in the DDOs with the crypto-currency lower level denominator. This is wei for ETH or drops for any other ERC20 token. This configuration is possible using the _tokenAddress parameter in the LockPayment and EscrowPayment conditions. The value options are: If the value is 0x0 means the payment is in ETH If the value is empty means the payment is in the Nevermined ERC20 Token If the value is an address means the payment is using the ERC20 Token deployed on that address In the following example is using a ETH payment: { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"0x0\" }","title":"Crypto Currencies"},{"location":"architecture/specs/access/#rewards-distribution","text":"In combination with the above, Nevermined allows the definition of payment schemes where multiple users can be paid for providing a service associated to an asset. For example, it's typical for a marketplace to get a commission for a sale because the infrastructure provided. This can be defined case by case, each marketplace could require different commissions, and can include multiple reward addresses to receive the payment as part of the sales flow. This configuration is possible using the _amounts and _receivers parameters in the LockPayment and EscrowPayment conditions. In the following example, as part of the DDO we define that address starting by 0xa99 is going to receive a payment of 10 drops or wei (depending on the token used), and the address starting by 0x068 a payment of 2. Example: { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [ \"10\" , \"2\" ] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [ \"0xa99d43d86a0758d5632313b8fa3972b6088a21bb\" , \"0x068ed00cf0441e4829d9784fcbe7b9e26d4bd8d0\" ] }","title":"Rewards Distribution"},{"location":"architecture/specs/access/#royalties-in-the-secondary-market","text":"Asset creators can define what are the royalties they want to receive in the secondary market. These royalties must be between 0 and 100 percent. The royalties can not be changed after they are initialized. This protects the buyers of an Asset or NFT to have to pay for a different commission to the one agreed during the purchase of that Asset or NFT. In Nevermined the Assets or NFTs can be transferred, what means the owner can be different to the original creator, but the original creator can't be modified in the Smart Contracts once the asset is defined.","title":"Royalties in the secondary market"},{"location":"architecture/specs/access/#flows","text":"This section describes the asset publishing flow and the asset consuming flow in detail. It should be straightforward to implement those flows by reading it, although the actual implementation may deviate slightly. The detailed description is an attempt to account for important edge cases and to create a good reference for the authors of particular implementations. The intention of the Access flow is to be as lean as possible, allowing data sharing solution with low friction. In the below image you can see a high level view of the Nevermined Data Sharing flow: Nevermined Data Sharing flow The following parameters are used: did - Decentralized Identifier (DID). See DID SPEC . agreementId or serviceAgreementId - The unique ID referring to a Service Agreement established between a PUBLISHER and a CONSUMER. The CONSUMER (via SDK) is the one creating this unique ID. serviceDefinitionId - Identifies one service in the array of services included in the DDO. It is created by the PUBLISHER (via SDK) upon DDO creation. templateId - Identifies a unique Service Agreement template.","title":"Flows"},{"location":"architecture/specs/access/#publishing-assets","text":"When a PUBLISHER uses the Nevermined SDK to publish (register) an asset, here is a summary of what the SDK does: Construct a new DDO (JSON object describing the asset). Calculate the checksum of all the services (access, provenance, etc) included as part of the DDO Calculates an unique DID Register using the Smart Contracts the DID, checksum of the DDO and the URL pointing to the METADATA API resolving the DDO Store the DDO off-chain in the METADATA API Those steps are explained in more detail below. The PUBLISHER is able to publish (register) an asset by making a single SDK call. where metadata is a dict containing the METADATA SPEC metadata about the asset. We now expand on the publishing (registration) steps in more detail.","title":"Publishing Assets"},{"location":"architecture/specs/access/#constructing-an-asset-ddo","text":"An asset DDO is a DID Document conforming with the Decentralized Identifiers (DIDs) spec . Validate the metadata to ensure that it conforms with METADATA SPEC . (It should be in \"local metadata\" form at this point.) Compute a DID following DID SPEC . Create an empty DDO and add the following things to it: DID Public key of the PUBLISHER Authentication section (with RSA public key) Encrypt the URLs in the attributes.main.files array of the metadata. The PUBLISHER must specify which encryption service/procedure/plugin they wish to use. That encryption service gets recorded in the asset DDO. For details, see the section about Encryption and Decryption below. Note: This step changes the metadata and also the \"service\" section of the DDO. Sign the checksum using the publisher_account (i.e. compute a signature) and add the computed signature to the proof attribute. Add the rest of the services to the DDO. Each service in the list contains certain information depending on its type. Here we document two types of services required for purchasing and consuming an asset. A service of type \"Access\" contains: Service Definition ID ( serviceDefinitionId ); this helps PUBLISHER find the service definition of a DDO signed by CONSUMER Service Agreement Template ID ( templateId ); points to an unique instance of a template of a Service Agreement Service endpoint ( serviceEndpoint ); CONSUMERS signing this service send their signatures to this endpoint A list of condition keys; condition key is the keccak256 hash of the following: SLA template ID controller contract address (obtained from the solidity contract json file matching the contract name in the SLA condition) controller contract function fingerprint (referred to as function signature or selector) For each condition, a list is required of its parameter values, a timeout, a set of fields determining what conditions depend on other conditions, and a mapping of events emitted by the condition to the off-chain handlers of these events Each event is identified by name. Each event handler is a function from a whitelisted module Service Agreement contract address and the event mapping in the same format as the condition events, for off-chain listeners An integer defining when the agreement is fulfilled in case there are multiple terminal conditions, according to the Service Agreement smart contract A service of type \"Access\" contains 2 different endpoints: serviceEndpoint - A URL to initialize the Service Agreement consumeEndpoint - A URL to fetch data decryption keys from An example of a complete DDO can be found here . Please do note that the condition's order in the DID document should reflect the same order in on-chain service agreement. PUBLISHER registers the DID, associating the asset DID to the METADATA API link that resolves the DID to a DDO. To do that, the SDK needs to integrate the DIDRegistry contract using the registerAttribute method. function registerAttribute ( bytes32 _did , bytes32 _checksum , address [] memory _providers , string memory _value ) The parameters to pass are: bytes32 _did - The hash part of the DID, the part just after did:nv: bytes32 _checksum - The checksum generated after compute the DID address[] _providers - The list of providers which PUBLISHER delegates URL decryption capabilities and SEA management string _value - The Metadata service endpoint. In the above DDO its: http://metadata.org/api/v1/metadata/assets/ddo/{did } Publishing Flow The SMART CONTRACT will emit the DIDAttributeRegistered including the did , checksum and url registered.","title":"Constructing an Asset DDO"},{"location":"architecture/specs/access/#service-agreement-templates","text":"It represents a standard template of a Service Agreement between parties. A template includes standard conditions allowing to be used by Nevermined users as reference during the negotiation between parties to establish a formal agreement on-chain. A Service Agreement Template includes: * A template identifier: `templateId` * A list of Conditions * Timeouts To facilitate the creation of agreements between parties, the templates provide standard agreements ready to be used during the creation of Service Agreement instances between parties. Interaction with templates can be done via the TemplateStoreManager contract. For the Data Sharing use case, Nevermined provides the EscrowAccessSecretStore template. The EscrowAccessSecretStore Service Agreement template has the following shape: const agreement = { id : id , did : did , templateId : templateId , conditionIds : [ conditionIdAccess , conditionIdLock , conditionIdEscrow ], timeLocks : [ timeLockAccess , 0 , 0 ], timeOuts : [ timeOutAccess , 0 , 0 ], actors : [ actors ] } For the different conditionIds, the CONSUMER needs to generate those and add them to the agreement to be defined on-chain. This requires to generate the hash including the agreementId and all the values of the specific condition: const conditionIdAccess = await accessCondition . generateId ( agreementId , await accessCondition . hashValues ( did , receiver )) const conditionIdLock = await lockPaymentConditon . generateId ( agreementId , await lockPaymentConditon . hashValues ( escrowPayment . address , escrowAmount )) const conditionIdEscrow = await escrowPayment . generateId ( agreementId , await escrowPayment . hashValues ( escrowAmount , receiver , sender , conditionIdLock , conditionIdAccess )) PUBLISHER publishes the DDO in the METADATA API.","title":"Service Agreement Templates"},{"location":"architecture/specs/access/#access","text":"Using SDK calls, a CONSUMER can discover, purchase and get access to assets. Steps for leveraging SDK: The CONSUMER uses the search method to find relevant assets related with his query. It returns a list of DDO's. assets = nevermined.assets.search(\"weather Germany 2019\") The CONSUMER chooses a service inside a DDO (the CONSUMER selects a serviceDefinitionId ). The Service Agreement needs to have an associated unique serviceAgreementId that can be generated/provided by the CONSUMER. In the Smart Contracts, this serviceAgreementId will be stored as a bytes32 . This serviceAgreementId is generated randomly and is represented by a 64-character hex string (using the characters 0-9 and a-f). The CONSUMER can generate the serviceAgreementId using any kind of implementation providing enough randomness to generate this ID (64-characters hex string). The CONSUMER signs the service details. The signature contains (templateId, valuesHashList, timeoutValues, agreementId) . The agreementId is provided by the CONSUMER and has to be globally unique. Each ith item in values_hash_list lists corresponds to the ith condition in conditions list values_hash_list : a hash of the parameters types and values of each condition This signature is used to correlate events and to prevent the PUBLISHER from instantiating multiple Service Agreements from a single request. The CONSUMER sends (did, serviceAgreementId, serviceDefinitionId, signature, consumerAddress ) to the service endpoint (GATEWAY). serviceDefinitionId tells the PUBLISHER where to find the preimage to verify the signature. The DID tells the PUBLISHER which asset to serve under these terms. HTTP POST /api/v1/GATEWAY/services/access/initialize { \"did\": \"did:nv:08a429b8529856d59867503f8056903a680935a76950bb9649785cc97869a43d\", \"serviceAgreementId\": \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\", \"index\": 0, \"signature\": \"cade376598342cdae231321a0097876aeda656a567a67c6767fd8710129a9dc1\", \"consumerAddress\": \"0x00a329c0648769A73afAc7F9381E08FB43dBEA72\" } The execution of this endpoint should return a HTTP 201 if everything goes okay. Satisfactory conditions include: When GATEWAY receives a signature from the service endpoint and verifies the signature. Having the did , GATEWAY fetches the DDO related with this did . GATEWAY records the serviceAgreementId as corresponding to the given did . GATEWAY executes the Service Agreement by calling EscrowAccessSecretStoreTemplate.createAgreement , providing it with the agreementId and all the agreement values GATEWAY starts listening for the publisher events from the events section of the service definition. After receiving the HTTP response confirmation from GATEWAY, the CONSUMER starts listening for the AgreementCreated events specified in the corresponding service definition, filtering them by agreementId .","title":"Access"},{"location":"architecture/specs/access/#execution-of-the-service-agreement","text":"Consider an asset purchase example. CONSUMER locks the payment. Then PUBLISHER grants access to the document. Then payment is released. Now CONSUMER may decrypt the document. In general, there is a broad range of conditions which can be implemented and integrated into the described workflow.","title":"Execution of the service agreement"},{"location":"architecture/specs/access/#lock-payment-condition","text":"Consider a sample of a service definition. \"serviceAgreementTemplate\": { \"contractName\": \"EscrowAccessSecretStoreTemplate\", \"events\": [{ \"name\": \"AgreementCreated\", \"actorType\": \"consumer\", \"handler\": { \"moduleName\": \"escrowAccessSecretStoreTemplate\", \"functionName\": \"fulfillLockPaymentCondition\", \"version\": \"0.1\" } }] } According to this sample, the CONSUMER listens for the AgreementCreated event emitted in the very beginning of Service Agreement execution, filtering it by agreementId . Note that the structure of serviceAgreementContract.events is identical to conditions.events . SDK needs to offer a utility that subscribes the specified callbacks to the events from both lists. When the CONSUMER receives this event it means the agreement is in place and can perform the lock reward: await token.approve(lockPaymentConditon.address, escrowAmount, { from: sender }) await lockPaymentConditon.fulfill(agreementId, escrowPayment.address, escrowAmount) If everything goes right, it will emit LockPaymentCondition.Fulfilled and thus will trigger the next condition.","title":"Lock Payment Condition"},{"location":"architecture/specs/access/#grant-access-condition","text":"PUBLISHER (via GATEWAY) listens for LockPaymentCondition.Fulfilled event filtered by agreementId to confirm the reward was locked by the CONSUMER. \"conditions\": [{ \"events\": [{ \"name\": \"Fulfilled\", \"actorType\": \"publisher\", \"handler\": { \"moduleName\": \"lockPaymentConditon\", \"functionName\": \"fulfillAccessCondition\", \"version\": \"0.1\" } }] }] In this case the PUBLISHER can grant access to the CONSUMER for a specific agreementId and documentId using in this case the AccessCondition.fulfill : await accessCondition.fulfill(agreementId, agreement.did, receiver) If everything goes right, the Smart Contract will emit the AccessCondition.Fulfilled event.","title":"Grant Access Condition"},{"location":"architecture/specs/access/#release-payment-condition","text":"PUBLISHER (via GATEWAY) listens for AccessCondition.Fulfilled event to transfer tokens to PUBLISHER's account. \"conditions\": [{ \"events\": [{ \"name\": \"Fulfilled\", \"actorType\": \"publisher\", \"handler\": { \"moduleName\": \"access\", \"functionName\": \"fulfillEscrowPaymentCondition\", \"version\": \"0.1\" } }] }] So when the PUBLISHER receives the AccessCondition.Fulfilled he can call the EscrowPayment.fulfill method to receive the reward: await escrowPayment.fulfill(agreementId, escrowAmount, receiver, sender, agreement.conditionIds[1], agreement.conditionIds[0])","title":"Release Payment Condition"},{"location":"architecture/specs/access/#consuming-the-data","text":"CONSUMER (via SDK) listens for AccessCondition.Fulfilled event to access the document. \"conditions\": [{ \"events\": [{{ \"name\": \"TimedOut\", \"actorType\": \"consumer\", \"handler\": { \"moduleName\": \"access\", \"functionName\": \"fulfillEscrowPaymentCondition\", \"version\": \"0.1\" } }] }] The following are steps that have to be performed by the CONSUMER to receive the data. CONSUMER decrypts the URL using the SDK. This only requires the encryptedUrl existing in the DDO and the DID. A Parity EVM client (local or remote) and SECRET STORE cluster can be used for that. CONSUMER retrieves data by calling the dedicated GATEWAY endpoint ( serviceEndpoint in the service definition) providing it with Consumer ethereum address, service agreement ID, and decrypted URL. The consume URL may look like: HTTP GET /api/v1/GATEWAY/services/access/consume?consumerAddress=${consumerAddress}&serviceAgreementId={serviceAgreementId}&url={url}` This method will return a HTTP 200 status code if everything was okay and the data file. When CONSUMER requests purchased data, GATEWAY gets 3 parameters: Consumer ethereum address: consumerAddress Service Agreement ID: serviceAgreementId Decrypted URL: url . This URL is only valid if GATEWAY acts as a gateway. CONSUMER cannot download using the URL if it's not done through GATEWAY. Using those parameters, GATEWAY does the following things: Find the did by the given serviceAgreementId Verify the given service is allowed to be consumed by the given consumerAddress and did using the checkPermissions method of the SLA Smart Contract. If CONSUMER has permissions to consume, download and provide data for the given DID Consuming Flow","title":"Consuming the Data"},{"location":"architecture/specs/access/#consuming-without-direct-integration-of-secret-store","text":"If the CONSUMER (via SDK) can't integrate directly SECRET STORE for decryption (nevermined-sdk-js using Metamask can't provide the account password), it's possible to call GATEWAY with an alternative consume method. In this scenario, the GATEWAY is in charge of decrypting the content in behalf of the CONSUMER. The consume URL may look like: HTTP GET /api/v1/gateway/services/access/consume?pubKey=${pubKey}&serviceAgreementId={serviceAgreementId}&signature={signature}&index={index}` This method will return an HTTP 200 status code if everything was okay, plus the URL required to get access to the data. When CONSUMER requests purchased data, GATEWAY gets 3 parameters: Consumer public key: pubKey Service Agreement ID: serviceAgreementId Signature: signature . The signed serviceAgreementId value by the CONSUMER to validate his/her identity Index: index . Integer value representing the position of the content to download in the DDO.files array","title":"Consuming without direct integration of Secret Store"},{"location":"architecture/specs/access/#abort-conditions","text":"Every condition can be fulfilled or aborted using the configured timeout. For example it would allows to the CONSUMER to cancel the payment after locking it but not receiving access to the asset for a long period of time. Mechanisms implemented in the Service Agreement contract ensure there are no race conditions.","title":"Abort Conditions"},{"location":"architecture/specs/access/#encryption-and-decryption","text":"The PUBLISHER can define how they want to encrypt the URLs included in the attributes.main.files array of the metadata. This information must be added to the DDO to allow CONSUMERs (via SDK) to understand how to deal with the URLs. Below is an example of how to add an encryption service to the service section of a DDO. \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"service\" : \"SecretStore\" , \"serviceEndpoint\" : \"http://secretstore.org:12001\" , \"config\" : { \"threshold\" : 3 }, }, \u2026 ] The encryption service is one object with the following attributes: type - Differentiate this kind of service with the word Authorization index - Existing in all the DDO services to differentiate one entry in the services list serviceEndpoint (optional) - URL used during the encryption and decryption process. attributes.main - List of mandatory attributes specific of the type service - The authorization service type. It could be SecretStore , PSK_ECDSA or PSK_RSA . The encryption/authorization service is optional. If it's not provided, the usual SECRET STORE cluster defined in the SDK configuration will be used.","title":"Encryption and Decryption"},{"location":"architecture/specs/access/#encryption-process","text":"Suppose the attributes.main.files array in the metadata has three URLs: \"files\" : [ { \"url\" : \"https://example.com/data-file-0.csv\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"resourceId\" : \"access-log2018-02-13-15-17-29-18386C502CAEA932\" }, { \"url\" : \"https://example.com/data-file-1.csv\" , \"index\" : 1 , \"checksum\" : \"085340abffh21495345af97c6b0e761\" , \"contentLength\" : \"12324\" }, { \"url\" : \"https://example.com/data-file-2.csv\" , \"index\" : 2 } ] The attributes.main.files array is encrypted as follows. First it is converted into a string like so: [{ \"url\" : \"https://example.com/data-file-0.csv\" , \"index\" : 0 , \u2026 , \"index\" : 2 }] where all spaces are removed (except inside the string values). Also, all newlines, line feeds, and carriage returns are removed. That JSON string can then be encrypted. After encryption, all \"url\" keys and values are removed from the attributes.main.files array objects, and a new attributes.encryptedFiles key and value are added to the metadata, e.g. \"encryptedFiles\" : \"0x2e48ceefcca7abb024f90\u2026f3fec0e1c\" We now describe the supported encryption procedures.","title":"Encryption Process"},{"location":"architecture/specs/access/#authorization-types","text":"The system supports different implementation for managing the authorization of the encryption/decryption of secrets. The authorization type can be found in attributes.main.service attribute. The authorization mechanisms supported are: SecretStore - Parity Secret Store PK-ECDSA - ECDSA Pre-Shared Keys PK-RSA - RSA Pre-Shared Keys","title":"Authorization Types"},{"location":"architecture/specs/access/#using-secret-store","text":"The SECRET STORE cluster to use during the encryption and decryption is specified in the serviceEndpoint attribute, e.g. \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"SecretStore\" , \"threshold\" : \"1\" } }, \"serviceEndpoint\" : \"http://secretstore.org:12001\" }, \u2026 ] More information about the integration of a SECRET STORE can be found Parity Secret Store page .","title":"Using Secret Store"},{"location":"architecture/specs/access/#using-the-data-gateway","text":"For those clients not able to integrate SECRET STORE directly, GATEWAY will support an encryption endpoint supporting the following parameters: HTTP POST /api/v1/gateway/services/encrypt { \"id\": \"did:nv:08a429b8529856d59867503f8056903a680935a76950bb9649785cc97869a43d\", \"document\": [ { \"url\": \"234ab87234acbd09543085340abffh21983ddhiiee982143827423421\", \"checksum\": \"efb2c764274b745f5fc37f97c6b0e761\", \"contentLength\": \"4535431\", \"resourceId\": \"access-log2018-02-13-15-17-29-18386C502CAEA932\" }, { \"url\": \"234ab87234acbd6894237582309543085340abffh21983ddhiiee982143827423421\", \"checksum\": \"085340abffh21495345af97c6b0e761\", \"contentLength\": \"12324\" }, { \"url\":\"80684089027358963495379879a543085340abffh21983ddhiiee982143827abcc2\" } ] } That is, the value of document should be the attributes.main.files array. This endpoint will return the content encrypted using the GATEWAY account. The GATEWAY will expose the public keys using for encryption in the following endpoint: http://0.0.0.0:8030/ In the JSON returned there will be the *-public-key entries with the different public keys enabled in the GATEWAY: { ... \"ecdsa-public-key\" : \"0xaaaaa\" , \"rsa-public-key\" : \"0xaaaaa\" , ... }","title":"Using the Data Gateway"},{"location":"architecture/specs/access/#psk-ecdsa","text":"In a DDO definition, can be defined a Pre-Shared ECDSA mechanism using the following configuration: \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"PSK-ECDSA\" , \"publicKey\" : \"0xaaaa\" // ECDSA Public Key o f t he Ga te way } }, \"serviceEndpoint\" : \"http://mygateway.net/\" }, \u2026 ]","title":"PSK ECDSA"},{"location":"architecture/specs/access/#psk-rsa","text":"In a DDO definition, can be defined a Pre-Shared RSA mechanism using the following configuration: \"service\" : [{ \"type\" : \"authorization\" , \"index\" : 0 , \"attributes\" : { \"main\" : { \"service\" : \"PSK-RSA\" , \"publicKey\" : \"0xaaaa\" // RSA Public Key o f t he Ga te way } }, \"serviceEndpoint\" : \"http://mygateway.net/\" }, \u2026 ]","title":"PSK RSA"},{"location":"architecture/specs/compute/","text":"COMPUTE SPEC: Data in situ Computation \u00b6 shortname: COMPUTE name: Data In Situ Computation type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: COMPUTE SPEC: Data in situ Computation Execution of Remote Compute Services using Service Agreements Motivation Actors Technical components Flow Terminology Requirements Workflows Publishing an Asset including Compute Services Setting up the Service Execution Agreement Registering Asset Consuming Asset Execution phase Infrastructure Orchestration Services Provided by the Operator Orchestration Steps Infrastructure Operator Volumes Network isolation Execution of Remote Compute Services using Service Agreements \u00b6 This SPEC introduces the integration pattern for the usage of Service Execution Agreements (SEA) (also called Service Agreements or Agreements) as contracts between parties interacting in the execution of a Compute Service transaction. This SPEC using the SEA as core element, orchestrates the publishing/execution of this type of compute services. The intention of this SPEC is to describe the flow and integration pattern independently of the infrastructure Cloud Compute Service. This SPEC MUST be valid for integrating classical infrastructure cloud providers like Amazon EC2 or Azure, but also can be used to integrate other compute providers or On-Premise infrastructure. It's out of the scope to detail the Service Execution Agreements implementation. Motivation \u00b6 The main motivations of this SPEC are: Identify the actors involved on the definition and execution of a Nevermined Compute service Detail the main characteristics of this interaction Specify the pros and cons of this approach Identify the API methods exposed via the different libraries Actors \u00b6 The different actors interacting in this flow are: PROVIDERS - Give access to the Compute Services CONSUMERS - Want to make use of the Compute Services MARKETPLACES or DOMAINS - Store the DDO/Metadata related with the Assets/services INFRASTRUCTURE - Cloud or on-premise infrastructure services providing computing. Typically Amazon, Azure, etc. Technical components \u00b6 The following technical components are involved in an end-to-end publishing and consumption flow: MARKETPLACE - Exposes a web interface allowing the users to publish and purchase assets and services associated to these assets. It also facilitates the discovery of assets. SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.). Flow \u00b6 This section describes the Asset Compute Service flow in detail. There are some parameters used in this flow: DID - See DID SPEC . serviceAgreementId - Is the unique ID referring to a Service Execution Agreement established between a PUBLISHER and a CONSUMER. The CONSUMER (via SDK) is the one creating this random unique serviceAgreementId. serviceDefinitionId - Identifies one service in the array of services included in the DDO. It is created by the PUBLISHER (via SDK) upon DDO creation and is associated with different services. templateId - Identifies a unique Service Agreement template. Terminology \u00b6 Compute Provider - Entity providing a compute service for a price (or for free). Compute Service - Service offered by a Compute Provider. It could have different conditions like the type of services, price, etc. Workflow - It describes an execution pipeline where you put together input data and an algorithm to process this data and you run using a Compute Service. Requirements \u00b6 A COMPUTE PROVIDER or PROVIDER define the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources A COMPUTE PROVIDER defines a Compute Service in the scope of the Asset (DID/DDO) of the dataset that can be computed A CONSUMER defines the task to execute modeling it in a Workflow (including configuration, input, transformations and output) A workflow is a new type of Asset. It can be resolvable and be used across multiple independent compute services A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute A CONSUMER can purchase a service given by a PROVIDER and execute multiple times till the timeout expires A CONSUMER could purchase a service and execute later, the purchase MUST be totally decoupled of execution The previous two points could support to buy once a compute service and execute for example the service every night at 3 am Data in situ Computation Workflows \u00b6 From a high-level point of view, a workflow may be considered a view or representation of a real work. A workflow consists of an orchestrated and repeatable pattern of activities transformed into tasks that transform or process information. In Nevermined, we use the concept of workflow to represent a list of tasks to accomplish with the intention of process data. From a technical point of view, a workflow is a type of Asset (it takes advantage of all the Nevermined plumbing of registering, metadata publishing, resolving, etc.). The main objective of a workflow is to describe an execution pipeline. A workflow can be split in sequential stages, having each stage an input, transformation (via algorithm) and output. In the below example, a workflow is modeled in a JSON document with the following characteristics: It has a list of sorted stages by the stages.index parameter to be executed sequentially Each stage has a list of minimum requirements, like the image required to support the execution of the algorithm, minimum cpu, memory, etc. Each stage has an array of sorted input parameters. Each input parameter may be: A DID (example: \"id\": \"did:nv:12345\" ) The output of a previous stage (example: \"previousIndexStage\": 0 ) Each stage has one transformation entry. It includes the id (DID) of the asset in charge of process the input to generate some output Each stage includes an entry with some additional output details. This could be a DID or a specific detail about the expected output. Workflow JSON Model Example of a Workflow: { \"service\" : [{ \"index\" : \"0\" , \"type\" : \"metadata\" , \"serviceEndpoint\" : \"https://service/api/v1/metadata/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : { \"type\" : \"workflow\" , \"workflow\" : { \"stages\" : [{ \"index\" : 0 , \"stageType\" : \"Filtering\" , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [{ \"index\" : 0 , \"id\" : \"did:nv:12345\" }, { \"index\" : 1 , \"id\" : \"did:nv:67890\" }], \"transformation\" : { \"id\" : \"did:nv:abcde\" }, \"output\" : {} }, { \"index\" : 1 , \"stageType\" : \"Transformation\" , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [{ \"index\" : 0 , \"previousStage\" : 0 }], \"transformation\" : { \"id\" : \"did:nv:999999\" }, \"output\" : {} }] } }, \"additional\" : {}, \"curation\" : {} } }, {} ] } A Workflow is a new type of Asset (a part of datasets, algorithms, etc.). You can find a complete DDO of type workflow in the ddo.workflow.json example file . As a new kind of asset, the workflow details will be persisted inside a DDO as part of the \"Metadata\" service where the type is workflow . An Asset of type workflow, will include in the DDO the following information: The Workflow model as part of the DDO.services[\"metadata\"].main.workflow entity The rest of the Workflow metadata information (title, author, ect.) as part of the existing Metadata service A workflow, as every DDO in Nevermined, can be resolved using the Asset Id (DID). By the time being, the workflow definition supports the execution of sequential stages. It's not supported yet the execution of parallel stages. Publishing an Asset including Compute Services \u00b6 The Compute services are published as part of the asset (dataset) metadata as an additional service offered for that specific asset. The complete flow of publishing an asset with a compute service attached is: PUBLISHER generates a DID. See How to compute a DID . PUBLISHER creates a DDO including the following information: DID Metadata. It contains the asset name, description, etc. For more details see METADATA SPEC . Public key of the PUBLISHER A list of services (Access, etc). For more details see ACCESS SPEC . Each service in the list contains certain information depending on its type. Here we document the Compute service. The Access and Metadata services where discussed in the scope of the ACCESS SPEC . A service of type \"compute\" contains: Service Definition ID ( serviceDefinitionId ); this helps PUBLISHER find the service definition of a DDO signed by CONSUMER Service Agreement Template ID ( templateId ); points to an instance of a Service Agreement Template stored by the Template Store Manager. In this case is a template implementing the Compute end to end flow Service endpoint ( serviceEndpoint ); CONSUMERS signing this service send their signatures to this endpoint to request the execution of a workflow A list of condition keys; condition key is the keccak256 hash of the following: SLA template ID controller contract address (obtained from the solidity contract json file matching the contract name in the SLA condition) controller contract function fingerprint (referred to as function signature or selector) For each condition, a list is required of its parameter values, a timeout, a set of fields determining what conditions depend on other conditions, and a mapping of events emitted by the condition to the off-chain handlers of these events Each event is identified by name. Each event handler is a function from a whitelisted module Service Agreement contract address and the event mapping in the same format as the condition events, for off-chain listeners An integer defining when the agreement is fulfilled in case there are multiple terminal conditions, according to the Service Agreement smart contract A service of type \"compute\" contains one endpoint: - serviceEndpoint - A URL to call when the CONSUMER request the execution of a workflow An example of a complete DDO can be found [here](/tree/master/docs/architecture/specs/compute/examples/ddo.workflow.json). Please do note that the condition's order in the DID document should reflect the same order in on-chain service agreement. PUBLISHER publishes the DDO in the METADATA-API . This DDO must include at least one service of type \"compute\". here you have an example of the DDO including a Compute service. Below you can find a small fraction of this: \"container\": \"service\" : [{ \"type\" : \"compute\" , \"serviceDefinitionId\" : \"2\" , \"serviceEndpoint\" : \"http://mygateway.org/api/v1/gateway/services/execute\" , \"templateId\" : \"804932804923850985093485039850349850439583409583404534231321131a\" , \"attributes\" : { \"main\" : { \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"price\" : \"10\" , \"timeout\" : 86400 , \"provider\" : { \"type\" : \"Azure\" , \"description\" : \"\" , \"environment\" : { \"cluster\" : { \"type\" : \"Kubernetes\" , \"url\" : \"http://10.0.0.17/xxx\" }, \"supportedContainers\" : [{ \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }, { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }], \"supportedServers\" : [{ \"serverId\" : \"1\" , \"serverType\" : \"xlsize\" , \"price\" : \"5000000000000000000\" , \"cpu\" : \"16\" , \"gpu\" : \"0\" , \"memory\" : \"128gb\" , \"disk\" : \"160gb\" , \"maxExecutionTime\" : 86400 }, { \"containerId\" : \"2\" , \"typeContainer\" : \"medium\" , \"price\" : \"1000000000000000000\" , \"cpu\" : \"2\" , \"gpu\" : \"0\" , \"memory\" : \"8gb\" , \"disk\" : \"80gb\" , \"maxExecutionTime\" : 86400 }] } }, \"serviceAgreementTemplate\" : { \"contractName\" : \"ServiceExecutionTemplate\" , \"events\" : [{ \"name\" : \"AgreementCreated\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"serviceExecutionTemplate\" , \"functionName\" : \"fulfillLockPaymentCondition\" , \"version\" : \"0.1\" } }], \"fulfillmentOrder\" : [ \"lockPayment.fulfill\" , \"serviceExecution.fulfill\" , \"escrowPayment.fulfill\" ], \"conditionDependency\" : { \"lockPayment\" : [], \"serviceExecution\" : [], \"releaseReward\" : [ \"lockPayment\" , \"serviceExecution\" ] }, \"conditions\" : [{ \"name\" : \"lockPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"LockPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_rewardAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"lockPaymentConditon\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }] }, { \"name\" : \"execCompute\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"ComputeExecutionCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [{ \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_grantee\" , \"type\" : \"address\" , \"value\" : \"\" } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }, { \"name\" : \"TimedOut\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"escrowPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"EscrowPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] }, { \"name\" : \"_sender\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_lockCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_releaseCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"escrowPaymentConditon\" , \"functionName\" : \"verifyRewardTokens\" , \"version\" : \"0.1\" } }] } ] } } } }] PUBLISHER registers the DID, associating the Asset DID to the METADATA API URL that resolves the DID to a DDO. To do that, the SDK integrates the DIDRegistry contract using the registerAttribute method. Publishing & Executing a Compute Service Setting up the Service Execution Agreement \u00b6 Registering Asset \u00b6 Using only one SDK call registerAsset(asset_metadata, services_description, publisher_public_key) , the PUBLISHER should be able to register an Asset including a Compute service. The services_description attribute includes the different services (like compute) associated to this asset. Consuming Asset \u00b6 During this phase, through the CONSUMER and the PROVIDER (via GATEWAY) negotiation, the Service Execution Agreement (SEA) is created and initialized. Using the SDK, a CONSUMER can discover, purchase and use the PROVIDER Compute services. The complete flow for setting up the SEA is: The CONSUMER chooses a service inside a DDO (the CONSUMER selects a serviceDefinitionId ). The Service Agreement needs to have an associated unique serviceAgreementId that can be generated/provided by the CONSUMER. In the Smart Contracts, this serviceAgreementId will be stored as a bytes32 . This serviceAgreementId is random and is represented by a 64-character hex string (using the characters 0-9 and a-f). The CONSUMER can generate the serviceAgreementId using any kind of implementation providing enough randomness to generate this ID (64-characters hex string). The CONSUMER signs the service details. The signature contains (templateId, conditionTypes, valuesHashList, timeoutValues, serviceAgreementId) . serviceAgreementId is provided by the CONSUMER and has to be globally unique. Each ith item in values_hash_list and timeoutValues lists corresponds to the ith condition in conditionKeys values_hash_list : a hash of the parameters types and values of each condition timeoutValues : list of numbers to specify a timeout value for each condition. It is used to correlate events and to prevent the PUBLISHER from instantiating multiple Service Agreements from a single request. The CONSUMER initializes the SEA on-chain (did, serviceAgreementId, serviceDefinitionId, signature, consumerAddress, workflowId ). The CONSUMER locks the payment on-chain through the LockPaymentCondition Smart Contract The PROVIDER via GATEWAY, receives the LockPayment.Fulfilled event where he/she is the provider for this agreement The PROVIDER grants the execution permissions for the computation on-chain calling the executeComputeCondition.Fullfill method The CONSUMER gets the executeComputeCondition.Fullfilled event. When he/she receives the event, can call the GATEWAY serviceEndpoint url added in the DDO to start the execution of the computation workflow. Typically: HTTP POST /api/v1/gateway/services/exec The GATEWAY receives the CONSUMER request, and calls the checkPermissions method to validate if the CONSUMER address is granted to execute the service. If user is granted, the GATEWAY triggers the Execute Algorithm action in the infrastructure Execution phase \u00b6 During this phase, if and only if the CONSUMER is granted, the CONSUMER can request the start of the Computation in the PUBLISHER infrastructure via GATEWAY. The complete flow for the Execution phase is: The GATEWAY after receiving the execution request from CONSUMER, validates the permissions using the checkPermissions function If the CONSUMER is authorized, the GATEWAY resolves the DID of the Workflow associated with the Service Agreement. The workflow includes the details of the pipeline to execute, including the different stages, inputs and outputs. The GATEWAY starts the communicates with the OPERATOR SERVICE, this register a new execution in the PROVIDER INFRASTRUCTURE (cloud or on-premise). The sends a \"Workflow Registration\" HTTP REST request to the Infrastructure Operator (aka OPERATOR SERVICE). This request must include the serviceAgreementId and the Workflow (JSON) The OPERATOR SERVICE receives a \"Workflow Registration\" request and: Validates in K8s there is no an existing/running workflow with the same serviceAgreementId Creates an unique workflowExecutionId identifying a unique execution of the service Validates the container flavour defined by the CONSUMER in the Workflow is supported in the compute service (DDO) Register the workflow in Kubernetes (K8s) All the actions made by the OPERATOR in the infrastructure via K8s MUST include the serviceAgreementId and workflowExecutionId as tags/labels For each stage in the workflow, the OPERATOR orchestrates Orchestration Steps When a new Workflow is created in K8s, the OPERATOR ENGINE fetch the event and execute the following 3 steps: Configuration - The OPERATOR ENGINE starts the \"Configuration Pod\". This pod is in charge of prepare the environment connecting the input volumes to a secure container. Also is in charge of resolving all the DID's involved into the real assets and leave everything ready for further execution. After finishing the pod is stopped. Executing - The OPERATOR ENGINE starts the \"Compute Pod\". This pod is in charge of using the data & algorithm existing in the input volumes, execute the algorithm. The pod only can write data to the output volume. After finishing the execution of the algorithm the pod is stopped. Publishing - The OPERATOR ENGINE starts the \"Publishing Pod\". This pod is in charge of publishing as a new Asset the result generated to the output volume. The ownership of the asset is transferred to the user triggering the computation workflow (typically the data scientist/engineer). After finishing the pod is stopped. The OPERATOR requests the deletion of all the containers and volumes created in the Kubernetes cluster The OPERATOR retrieves from the INFRASTRUCTURE (if it's available) a receipt demonstrating the execution of the service The CONSUMER receives an event including the DID of the new ASSET created The GATEWAY or any other user may requests the releasePayment through the SMART CONTRACTS. It commits on-chain the HASH of the receipt ticket collected from the INFRASTRUCTURE provider. Execution Flow Infrastructure Orchestration \u00b6 To facilitate the infrastructure orchestration the GATEWAY integrates with Kubernetes (aka K8s) via the OPERATOR component. The OPERATOR allows to abstract the execution of Docker containers with compute services independently of the backend (Amazon, Azure, On-Premise). To support that OPERATOR includes the kubernetes driver allowing to wrap the complete execution including: Download of the container images Setting up the pods Creation of volumes Starting and stopping the service Retrieval of logs Registering the new Asset Destroy the pods The OPERATOR handles 3 types of K8s Pods: Configuration Pod is in charge of resolve the Workflow resources necessary for the execution of the algorithm. It copies the data and algorithm in volumes Compute Pod is in charge of run the algorithm. This pod has access in read-only mode to the volumes with the input data and write mode to the output volume Publishing Pod is in charge of having all the data and logs generated in the output volume to publish this data in Nevermined as a new asset and handover the ownership to the CONSUMER Services Provided by the Operator \u00b6 The services provided by the OPERATOR are: Registering a new Workflow execution. Given a serviceAgreementId and a Workflow payload, starts the execution of the Workflow. It returns a workflowExecutionId valid to track the execution of the Workflow. Retrieve logs. Given a serviceAgreementId and workflowExecutionId retrieve the logs associated to that execution Stop workflow execution. Given a serviceAgreementId and workflowExecutionId stop/delete all the containers associated with them Orchestration Steps \u00b6 The compute scenario requires a complete orchestration of different stages in order to provide an end to end flow. The steps included in this scenario are: The CONSUMER send a request to the GATEWAY using the compute/exec method in order to trigger the Workflow execution The GATEWAY receives this request and check on-chain via SMART CONTRACTS if the CONSUMER has grants to execute the Workflow. If the CONSUMER has grants will continue the Infrastructure Operation integration, if not will return an error message. The GATEWAY calls the Infrastructure Operator (aka OPERATOR SERVICE) giving the Workflow that needs to be executed The OPERATOR SERVICE communicates with the K8s cluster to register the Workflow in Kubernetes The OPERATOR ENGINE is registered to the new Workflow Events. When this happens The OPERATOR via K8s starts a generic Configuration Pod . The responsibilities of the configuration pod are: Parses the Workflow document Resolves the DID resources necessary to run the Workflow Pulls the docker image from the Docker registry Plugs the different data inputs as volumes in the Compute Pod Plugs the output for data and logs as volumes in the Compute Pod After all the above steps the Configuration Pod must be stopped If the Configuration Pod ends successfully the OPERATOR via K8s starts the Compute Pod using the flavour specified by the user in the Workflow definition The Compute Pod starts and runs the compute-entrypoint.sh part of the algorithm downloaded by the Configuration Pod When the Compute Pod ends or the duration is too long (timeout), the OPERATOR via K8s stop and delete the Compute Pod If the Compute Pod ends, the OPERATOR start a new instance of the Publishing Pod . The responsibilities of the Publishing Pod are: List of the Log files generated in the Log volume and copy to the output List of the Output data generated in the Output volume Generate a new Asset Metadata using the information provided by the CONSUMER Register a new Asset in Nevermined including the Output & Log data generated Transfer the ownership of the new Asset created to the CONSUMER At this point the CONSUMER could get an event of a new created asset where he/she is the owner Infrastructure Orchestration Infrastructure Operator \u00b6 In this SPEC the PROVIDER of a computation service is in charge of defining the requirements to allow the execution of algorithms on top of the data assets. It means only the images specified in the DDO by the publisher with a specific DID and checksum will be allowed to be executed in the Runtime environment. The OPERATOR SERVICE is in charge of setting up the runtime environment speaking with the infrastructure provider via Kubernetes. The images defined in the DDO and defined by the PUBLISHER only SHOULD include the minimum libraries specified, it will reduce the risk of executing unexpected software via external libraries. In addition to this, it's recommended that the images running in the runtime environment don't have network connectivity a part of the minimum required to get access to the Assets. Volumes \u00b6 The input assets will be added to the runtime environment as read only volumes. The complete paths to the folders where the volumes are mounted will be given to the algorithm as parameters, using the same order of the parameters specified in the Workflow definition. The new derived Asset generated as a result of the execution of the algorithm MUST be written in the output volume. The pods will be destroyed after the execution, so only the data stored in the output or logs volumes should be used. Type Permissions CLI Parameter Input Read --input1=/mnt/volume1 --input2=/mnt/volume2 Output Read, Write --output=/mnt/output Logs Read, Write --logs=/mnt/logs Network isolation \u00b6 The runtime environment doesn't need to have network connectivity to external networks to be executed. To avoid sending the internal information about the data, it's recommended to restrict the output connectivity.","title":"Data In Situ Computation"},{"location":"architecture/specs/compute/#compute-spec-data-in-situ-computation","text":"shortname: COMPUTE name: Data In Situ Computation type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: COMPUTE SPEC: Data in situ Computation Execution of Remote Compute Services using Service Agreements Motivation Actors Technical components Flow Terminology Requirements Workflows Publishing an Asset including Compute Services Setting up the Service Execution Agreement Registering Asset Consuming Asset Execution phase Infrastructure Orchestration Services Provided by the Operator Orchestration Steps Infrastructure Operator Volumes Network isolation","title":"COMPUTE SPEC: Data in situ Computation"},{"location":"architecture/specs/compute/#execution-of-remote-compute-services-using-service-agreements","text":"This SPEC introduces the integration pattern for the usage of Service Execution Agreements (SEA) (also called Service Agreements or Agreements) as contracts between parties interacting in the execution of a Compute Service transaction. This SPEC using the SEA as core element, orchestrates the publishing/execution of this type of compute services. The intention of this SPEC is to describe the flow and integration pattern independently of the infrastructure Cloud Compute Service. This SPEC MUST be valid for integrating classical infrastructure cloud providers like Amazon EC2 or Azure, but also can be used to integrate other compute providers or On-Premise infrastructure. It's out of the scope to detail the Service Execution Agreements implementation.","title":"Execution of Remote Compute Services using Service Agreements"},{"location":"architecture/specs/compute/#motivation","text":"The main motivations of this SPEC are: Identify the actors involved on the definition and execution of a Nevermined Compute service Detail the main characteristics of this interaction Specify the pros and cons of this approach Identify the API methods exposed via the different libraries","title":"Motivation"},{"location":"architecture/specs/compute/#actors","text":"The different actors interacting in this flow are: PROVIDERS - Give access to the Compute Services CONSUMERS - Want to make use of the Compute Services MARKETPLACES or DOMAINS - Store the DDO/Metadata related with the Assets/services INFRASTRUCTURE - Cloud or on-premise infrastructure services providing computing. Typically Amazon, Azure, etc.","title":"Actors"},{"location":"architecture/specs/compute/#technical-components","text":"The following technical components are involved in an end-to-end publishing and consumption flow: MARKETPLACE - Exposes a web interface allowing the users to publish and purchase assets and services associated to these assets. It also facilitates the discovery of assets. SDK - Software library encapsulating the Nevermined business logic. It's used to interact with all the components & APIs of the system. It's currently implemented in the following packages: nevermined-sdk-js - JavaScript version of the Nevermined SDK to be integrated with front-end applications. nevermined-sdk-py - Python version of the Nevermined SDK to be integrated with back-end applications. The primary users are data scientists. nevermined-sdk-java - Java version of the Nevermined SDK to be integrated with JVM applications. The primary users are data engineers. SMART CONTRACTS - Solidity Smart Contracts providing the Service Agreements business logic. GATEWAY - Microservice to be executed by PUBLISHERS. It exposes an HTTP REST API permitting access to PUBLISHER assets or additional services such as computation. METADATA-API - Microservice to be executed by MARKETPLACES. Facilitates creating, updating, deleting and searching the asset metadata registered by the PUBLISHERS. This metadata is included as part of a DDO (see DID SPEC and METADATA SPEC ) and also includes the services associated with the asset (consumption, computation, etc.).","title":"Technical components"},{"location":"architecture/specs/compute/#flow","text":"This section describes the Asset Compute Service flow in detail. There are some parameters used in this flow: DID - See DID SPEC . serviceAgreementId - Is the unique ID referring to a Service Execution Agreement established between a PUBLISHER and a CONSUMER. The CONSUMER (via SDK) is the one creating this random unique serviceAgreementId. serviceDefinitionId - Identifies one service in the array of services included in the DDO. It is created by the PUBLISHER (via SDK) upon DDO creation and is associated with different services. templateId - Identifies a unique Service Agreement template.","title":"Flow"},{"location":"architecture/specs/compute/#terminology","text":"Compute Provider - Entity providing a compute service for a price (or for free). Compute Service - Service offered by a Compute Provider. It could have different conditions like the type of services, price, etc. Workflow - It describes an execution pipeline where you put together input data and an algorithm to process this data and you run using a Compute Service.","title":"Terminology"},{"location":"architecture/specs/compute/#requirements","text":"A COMPUTE PROVIDER or PROVIDER define the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources A COMPUTE PROVIDER defines a Compute Service in the scope of the Asset (DID/DDO) of the dataset that can be computed A CONSUMER defines the task to execute modeling it in a Workflow (including configuration, input, transformations and output) A workflow is a new type of Asset. It can be resolvable and be used across multiple independent compute services A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute A CONSUMER can purchase a service given by a PROVIDER and execute multiple times till the timeout expires A CONSUMER could purchase a service and execute later, the purchase MUST be totally decoupled of execution The previous two points could support to buy once a compute service and execute for example the service every night at 3 am Data in situ Computation","title":"Requirements"},{"location":"architecture/specs/compute/#workflows","text":"From a high-level point of view, a workflow may be considered a view or representation of a real work. A workflow consists of an orchestrated and repeatable pattern of activities transformed into tasks that transform or process information. In Nevermined, we use the concept of workflow to represent a list of tasks to accomplish with the intention of process data. From a technical point of view, a workflow is a type of Asset (it takes advantage of all the Nevermined plumbing of registering, metadata publishing, resolving, etc.). The main objective of a workflow is to describe an execution pipeline. A workflow can be split in sequential stages, having each stage an input, transformation (via algorithm) and output. In the below example, a workflow is modeled in a JSON document with the following characteristics: It has a list of sorted stages by the stages.index parameter to be executed sequentially Each stage has a list of minimum requirements, like the image required to support the execution of the algorithm, minimum cpu, memory, etc. Each stage has an array of sorted input parameters. Each input parameter may be: A DID (example: \"id\": \"did:nv:12345\" ) The output of a previous stage (example: \"previousIndexStage\": 0 ) Each stage has one transformation entry. It includes the id (DID) of the asset in charge of process the input to generate some output Each stage includes an entry with some additional output details. This could be a DID or a specific detail about the expected output. Workflow JSON Model Example of a Workflow: { \"service\" : [{ \"index\" : \"0\" , \"type\" : \"metadata\" , \"serviceEndpoint\" : \"https://service/api/v1/metadata/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : { \"type\" : \"workflow\" , \"workflow\" : { \"stages\" : [{ \"index\" : 0 , \"stageType\" : \"Filtering\" , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [{ \"index\" : 0 , \"id\" : \"did:nv:12345\" }, { \"index\" : 1 , \"id\" : \"did:nv:67890\" }], \"transformation\" : { \"id\" : \"did:nv:abcde\" }, \"output\" : {} }, { \"index\" : 1 , \"stageType\" : \"Transformation\" , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [{ \"index\" : 0 , \"previousStage\" : 0 }], \"transformation\" : { \"id\" : \"did:nv:999999\" }, \"output\" : {} }] } }, \"additional\" : {}, \"curation\" : {} } }, {} ] } A Workflow is a new type of Asset (a part of datasets, algorithms, etc.). You can find a complete DDO of type workflow in the ddo.workflow.json example file . As a new kind of asset, the workflow details will be persisted inside a DDO as part of the \"Metadata\" service where the type is workflow . An Asset of type workflow, will include in the DDO the following information: The Workflow model as part of the DDO.services[\"metadata\"].main.workflow entity The rest of the Workflow metadata information (title, author, ect.) as part of the existing Metadata service A workflow, as every DDO in Nevermined, can be resolved using the Asset Id (DID). By the time being, the workflow definition supports the execution of sequential stages. It's not supported yet the execution of parallel stages.","title":"Workflows"},{"location":"architecture/specs/compute/#publishing-an-asset-including-compute-services","text":"The Compute services are published as part of the asset (dataset) metadata as an additional service offered for that specific asset. The complete flow of publishing an asset with a compute service attached is: PUBLISHER generates a DID. See How to compute a DID . PUBLISHER creates a DDO including the following information: DID Metadata. It contains the asset name, description, etc. For more details see METADATA SPEC . Public key of the PUBLISHER A list of services (Access, etc). For more details see ACCESS SPEC . Each service in the list contains certain information depending on its type. Here we document the Compute service. The Access and Metadata services where discussed in the scope of the ACCESS SPEC . A service of type \"compute\" contains: Service Definition ID ( serviceDefinitionId ); this helps PUBLISHER find the service definition of a DDO signed by CONSUMER Service Agreement Template ID ( templateId ); points to an instance of a Service Agreement Template stored by the Template Store Manager. In this case is a template implementing the Compute end to end flow Service endpoint ( serviceEndpoint ); CONSUMERS signing this service send their signatures to this endpoint to request the execution of a workflow A list of condition keys; condition key is the keccak256 hash of the following: SLA template ID controller contract address (obtained from the solidity contract json file matching the contract name in the SLA condition) controller contract function fingerprint (referred to as function signature or selector) For each condition, a list is required of its parameter values, a timeout, a set of fields determining what conditions depend on other conditions, and a mapping of events emitted by the condition to the off-chain handlers of these events Each event is identified by name. Each event handler is a function from a whitelisted module Service Agreement contract address and the event mapping in the same format as the condition events, for off-chain listeners An integer defining when the agreement is fulfilled in case there are multiple terminal conditions, according to the Service Agreement smart contract A service of type \"compute\" contains one endpoint: - serviceEndpoint - A URL to call when the CONSUMER request the execution of a workflow An example of a complete DDO can be found [here](/tree/master/docs/architecture/specs/compute/examples/ddo.workflow.json). Please do note that the condition's order in the DID document should reflect the same order in on-chain service agreement. PUBLISHER publishes the DDO in the METADATA-API . This DDO must include at least one service of type \"compute\". here you have an example of the DDO including a Compute service. Below you can find a small fraction of this: \"container\": \"service\" : [{ \"type\" : \"compute\" , \"serviceDefinitionId\" : \"2\" , \"serviceEndpoint\" : \"http://mygateway.org/api/v1/gateway/services/execute\" , \"templateId\" : \"804932804923850985093485039850349850439583409583404534231321131a\" , \"attributes\" : { \"main\" : { \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"price\" : \"10\" , \"timeout\" : 86400 , \"provider\" : { \"type\" : \"Azure\" , \"description\" : \"\" , \"environment\" : { \"cluster\" : { \"type\" : \"Kubernetes\" , \"url\" : \"http://10.0.0.17/xxx\" }, \"supportedContainers\" : [{ \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }, { \"image\" : \"tensorflow/tensorflow\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }], \"supportedServers\" : [{ \"serverId\" : \"1\" , \"serverType\" : \"xlsize\" , \"price\" : \"5000000000000000000\" , \"cpu\" : \"16\" , \"gpu\" : \"0\" , \"memory\" : \"128gb\" , \"disk\" : \"160gb\" , \"maxExecutionTime\" : 86400 }, { \"containerId\" : \"2\" , \"typeContainer\" : \"medium\" , \"price\" : \"1000000000000000000\" , \"cpu\" : \"2\" , \"gpu\" : \"0\" , \"memory\" : \"8gb\" , \"disk\" : \"80gb\" , \"maxExecutionTime\" : 86400 }] } }, \"serviceAgreementTemplate\" : { \"contractName\" : \"ServiceExecutionTemplate\" , \"events\" : [{ \"name\" : \"AgreementCreated\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"serviceExecutionTemplate\" , \"functionName\" : \"fulfillLockPaymentCondition\" , \"version\" : \"0.1\" } }], \"fulfillmentOrder\" : [ \"lockPayment.fulfill\" , \"serviceExecution.fulfill\" , \"escrowPayment.fulfill\" ], \"conditionDependency\" : { \"lockPayment\" : [], \"serviceExecution\" : [], \"releaseReward\" : [ \"lockPayment\" , \"serviceExecution\" ] }, \"conditions\" : [{ \"name\" : \"lockPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"LockPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_rewardAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"lockPaymentConditon\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }] }, { \"name\" : \"execCompute\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"ComputeExecutionCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [{ \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_grantee\" , \"type\" : \"address\" , \"value\" : \"\" } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }, { \"name\" : \"TimedOut\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"escrowPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"EscrowPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] }, { \"name\" : \"_sender\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_lockCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_releaseCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" } ], \"events\" : [{ \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"escrowPaymentConditon\" , \"functionName\" : \"verifyRewardTokens\" , \"version\" : \"0.1\" } }] } ] } } } }] PUBLISHER registers the DID, associating the Asset DID to the METADATA API URL that resolves the DID to a DDO. To do that, the SDK integrates the DIDRegistry contract using the registerAttribute method. Publishing & Executing a Compute Service","title":"Publishing an Asset including Compute Services"},{"location":"architecture/specs/compute/#setting-up-the-service-execution-agreement","text":"","title":"Setting up the Service Execution Agreement"},{"location":"architecture/specs/compute/#registering-asset","text":"Using only one SDK call registerAsset(asset_metadata, services_description, publisher_public_key) , the PUBLISHER should be able to register an Asset including a Compute service. The services_description attribute includes the different services (like compute) associated to this asset.","title":"Registering Asset"},{"location":"architecture/specs/compute/#consuming-asset","text":"During this phase, through the CONSUMER and the PROVIDER (via GATEWAY) negotiation, the Service Execution Agreement (SEA) is created and initialized. Using the SDK, a CONSUMER can discover, purchase and use the PROVIDER Compute services. The complete flow for setting up the SEA is: The CONSUMER chooses a service inside a DDO (the CONSUMER selects a serviceDefinitionId ). The Service Agreement needs to have an associated unique serviceAgreementId that can be generated/provided by the CONSUMER. In the Smart Contracts, this serviceAgreementId will be stored as a bytes32 . This serviceAgreementId is random and is represented by a 64-character hex string (using the characters 0-9 and a-f). The CONSUMER can generate the serviceAgreementId using any kind of implementation providing enough randomness to generate this ID (64-characters hex string). The CONSUMER signs the service details. The signature contains (templateId, conditionTypes, valuesHashList, timeoutValues, serviceAgreementId) . serviceAgreementId is provided by the CONSUMER and has to be globally unique. Each ith item in values_hash_list and timeoutValues lists corresponds to the ith condition in conditionKeys values_hash_list : a hash of the parameters types and values of each condition timeoutValues : list of numbers to specify a timeout value for each condition. It is used to correlate events and to prevent the PUBLISHER from instantiating multiple Service Agreements from a single request. The CONSUMER initializes the SEA on-chain (did, serviceAgreementId, serviceDefinitionId, signature, consumerAddress, workflowId ). The CONSUMER locks the payment on-chain through the LockPaymentCondition Smart Contract The PROVIDER via GATEWAY, receives the LockPayment.Fulfilled event where he/she is the provider for this agreement The PROVIDER grants the execution permissions for the computation on-chain calling the executeComputeCondition.Fullfill method The CONSUMER gets the executeComputeCondition.Fullfilled event. When he/she receives the event, can call the GATEWAY serviceEndpoint url added in the DDO to start the execution of the computation workflow. Typically: HTTP POST /api/v1/gateway/services/exec The GATEWAY receives the CONSUMER request, and calls the checkPermissions method to validate if the CONSUMER address is granted to execute the service. If user is granted, the GATEWAY triggers the Execute Algorithm action in the infrastructure","title":"Consuming Asset"},{"location":"architecture/specs/compute/#execution-phase","text":"During this phase, if and only if the CONSUMER is granted, the CONSUMER can request the start of the Computation in the PUBLISHER infrastructure via GATEWAY. The complete flow for the Execution phase is: The GATEWAY after receiving the execution request from CONSUMER, validates the permissions using the checkPermissions function If the CONSUMER is authorized, the GATEWAY resolves the DID of the Workflow associated with the Service Agreement. The workflow includes the details of the pipeline to execute, including the different stages, inputs and outputs. The GATEWAY starts the communicates with the OPERATOR SERVICE, this register a new execution in the PROVIDER INFRASTRUCTURE (cloud or on-premise). The sends a \"Workflow Registration\" HTTP REST request to the Infrastructure Operator (aka OPERATOR SERVICE). This request must include the serviceAgreementId and the Workflow (JSON) The OPERATOR SERVICE receives a \"Workflow Registration\" request and: Validates in K8s there is no an existing/running workflow with the same serviceAgreementId Creates an unique workflowExecutionId identifying a unique execution of the service Validates the container flavour defined by the CONSUMER in the Workflow is supported in the compute service (DDO) Register the workflow in Kubernetes (K8s) All the actions made by the OPERATOR in the infrastructure via K8s MUST include the serviceAgreementId and workflowExecutionId as tags/labels For each stage in the workflow, the OPERATOR orchestrates Orchestration Steps When a new Workflow is created in K8s, the OPERATOR ENGINE fetch the event and execute the following 3 steps: Configuration - The OPERATOR ENGINE starts the \"Configuration Pod\". This pod is in charge of prepare the environment connecting the input volumes to a secure container. Also is in charge of resolving all the DID's involved into the real assets and leave everything ready for further execution. After finishing the pod is stopped. Executing - The OPERATOR ENGINE starts the \"Compute Pod\". This pod is in charge of using the data & algorithm existing in the input volumes, execute the algorithm. The pod only can write data to the output volume. After finishing the execution of the algorithm the pod is stopped. Publishing - The OPERATOR ENGINE starts the \"Publishing Pod\". This pod is in charge of publishing as a new Asset the result generated to the output volume. The ownership of the asset is transferred to the user triggering the computation workflow (typically the data scientist/engineer). After finishing the pod is stopped. The OPERATOR requests the deletion of all the containers and volumes created in the Kubernetes cluster The OPERATOR retrieves from the INFRASTRUCTURE (if it's available) a receipt demonstrating the execution of the service The CONSUMER receives an event including the DID of the new ASSET created The GATEWAY or any other user may requests the releasePayment through the SMART CONTRACTS. It commits on-chain the HASH of the receipt ticket collected from the INFRASTRUCTURE provider. Execution Flow","title":"Execution phase"},{"location":"architecture/specs/compute/#infrastructure-orchestration","text":"To facilitate the infrastructure orchestration the GATEWAY integrates with Kubernetes (aka K8s) via the OPERATOR component. The OPERATOR allows to abstract the execution of Docker containers with compute services independently of the backend (Amazon, Azure, On-Premise). To support that OPERATOR includes the kubernetes driver allowing to wrap the complete execution including: Download of the container images Setting up the pods Creation of volumes Starting and stopping the service Retrieval of logs Registering the new Asset Destroy the pods The OPERATOR handles 3 types of K8s Pods: Configuration Pod is in charge of resolve the Workflow resources necessary for the execution of the algorithm. It copies the data and algorithm in volumes Compute Pod is in charge of run the algorithm. This pod has access in read-only mode to the volumes with the input data and write mode to the output volume Publishing Pod is in charge of having all the data and logs generated in the output volume to publish this data in Nevermined as a new asset and handover the ownership to the CONSUMER","title":"Infrastructure Orchestration"},{"location":"architecture/specs/compute/#services-provided-by-the-operator","text":"The services provided by the OPERATOR are: Registering a new Workflow execution. Given a serviceAgreementId and a Workflow payload, starts the execution of the Workflow. It returns a workflowExecutionId valid to track the execution of the Workflow. Retrieve logs. Given a serviceAgreementId and workflowExecutionId retrieve the logs associated to that execution Stop workflow execution. Given a serviceAgreementId and workflowExecutionId stop/delete all the containers associated with them","title":"Services Provided by the Operator"},{"location":"architecture/specs/compute/#orchestration-steps","text":"The compute scenario requires a complete orchestration of different stages in order to provide an end to end flow. The steps included in this scenario are: The CONSUMER send a request to the GATEWAY using the compute/exec method in order to trigger the Workflow execution The GATEWAY receives this request and check on-chain via SMART CONTRACTS if the CONSUMER has grants to execute the Workflow. If the CONSUMER has grants will continue the Infrastructure Operation integration, if not will return an error message. The GATEWAY calls the Infrastructure Operator (aka OPERATOR SERVICE) giving the Workflow that needs to be executed The OPERATOR SERVICE communicates with the K8s cluster to register the Workflow in Kubernetes The OPERATOR ENGINE is registered to the new Workflow Events. When this happens The OPERATOR via K8s starts a generic Configuration Pod . The responsibilities of the configuration pod are: Parses the Workflow document Resolves the DID resources necessary to run the Workflow Pulls the docker image from the Docker registry Plugs the different data inputs as volumes in the Compute Pod Plugs the output for data and logs as volumes in the Compute Pod After all the above steps the Configuration Pod must be stopped If the Configuration Pod ends successfully the OPERATOR via K8s starts the Compute Pod using the flavour specified by the user in the Workflow definition The Compute Pod starts and runs the compute-entrypoint.sh part of the algorithm downloaded by the Configuration Pod When the Compute Pod ends or the duration is too long (timeout), the OPERATOR via K8s stop and delete the Compute Pod If the Compute Pod ends, the OPERATOR start a new instance of the Publishing Pod . The responsibilities of the Publishing Pod are: List of the Log files generated in the Log volume and copy to the output List of the Output data generated in the Output volume Generate a new Asset Metadata using the information provided by the CONSUMER Register a new Asset in Nevermined including the Output & Log data generated Transfer the ownership of the new Asset created to the CONSUMER At this point the CONSUMER could get an event of a new created asset where he/she is the owner Infrastructure Orchestration","title":"Orchestration Steps"},{"location":"architecture/specs/compute/#infrastructure-operator","text":"In this SPEC the PROVIDER of a computation service is in charge of defining the requirements to allow the execution of algorithms on top of the data assets. It means only the images specified in the DDO by the publisher with a specific DID and checksum will be allowed to be executed in the Runtime environment. The OPERATOR SERVICE is in charge of setting up the runtime environment speaking with the infrastructure provider via Kubernetes. The images defined in the DDO and defined by the PUBLISHER only SHOULD include the minimum libraries specified, it will reduce the risk of executing unexpected software via external libraries. In addition to this, it's recommended that the images running in the runtime environment don't have network connectivity a part of the minimum required to get access to the Assets.","title":"Infrastructure Operator"},{"location":"architecture/specs/compute/#volumes","text":"The input assets will be added to the runtime environment as read only volumes. The complete paths to the folders where the volumes are mounted will be given to the algorithm as parameters, using the same order of the parameters specified in the Workflow definition. The new derived Asset generated as a result of the execution of the algorithm MUST be written in the output volume. The pods will be destroyed after the execution, so only the data stored in the output or logs volumes should be used. Type Permissions CLI Parameter Input Read --input1=/mnt/volume1 --input2=/mnt/volume2 Output Read, Write --output=/mnt/output Logs Read, Write --logs=/mnt/logs","title":"Volumes"},{"location":"architecture/specs/compute/#network-isolation","text":"The runtime environment doesn't need to have network connectivity to external networks to be executed. To avoid sending the internal information about the data, it's recommended to restrict the output connectivity.","title":"Network isolation"},{"location":"architecture/specs/did/","text":"DID SPEC: Decentralized Identifiers \u00b6 shortname: DID name: Decentralized Identifiers type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: DID SPEC: Decentralized Identifiers Motivation Specification Proposed Solution Decentralized IDs (DIDs) Publishing and Consumption Flow DID Documents (DDOs) DDO Services Integrity How to compute the integrity checksum DID Document Proof Length of a DID How to compute a DID Registry Resolver References This specification is based on the W3C DID specification , which was at version 0.11 as of August 2018. Motivation \u00b6 The main motivations of this SPEC are: Design a solution to extend the current architecture to use Decentralized Identifiers (DIDs) and DID Documents (DDOs) Understand how to register information on-chain with off-chain integrity associated Understand how to resolve DIDs into DDOs Design a solution facilitating alignment of on-chain and off-chain information Establishing the mechanism to know if the DDO associated with a DID was modified Defining the common mechanisms, interfaces and APIs to implemented the designed solution Define how Nevermined assets can be modeled with a DID/DDO data model Understand how DID hubs are formed, and how they integrate a business and storage layer Specification \u00b6 Requirements are: The DID resolving capabilities MUST be exposed in the client libraries, enabling to resolve a DDO directly in a totally transparent way ASSETS are DATA objects describing RESOURCES under control of a PUBLISHER DLT stores on-chain only the essential information about ASSETS PROVIDERS store the ASSET metadata off-chain DLT doesn't store any ASSET metadata Nevermined doesn't store ASSET contents (e.g. files) An ASSET is modeled in Nevermined as on-chain information stored in the DLT and metadata stored in METADATA API ASSETS on-chain information only can be modified by OWNERS or DELEGATED USERS ASSETS can be resolved using a Decentralized ID (DID) included on-chain and off-chain A DID Document (DDO) should include the ASSET metadata Any kind of object registered in Nevermined MUST have a DID allowing one to uniquely identify that object in the system ASSET DDO (and the metadata included as part of the DDO) is associated to the ASSET information stored on-chain using a common DID A DID can be resolved to get access to a DDO ASSET DDOs can be updated without updating the on-chain information ASSET information stored in the DLT will include a checksum attribute The ASSET on-chain checksum attribute SHOULD include a one-way HASH calculated using the DDO content After the DDO resolving, the DDO HASH can be calculated off-chain to validate if the on-chain and off-chain information is aligned A HASH not matching with the checksum on-chain means the DDO was modified without the on-chain update The function to calculate the hash MUST BE standard Proposed Solution \u00b6 Decentralized IDs (DIDs) \u00b6 A DID is a unique identifier that can be resolved or de-referenced to a standard resource describing the entity (a DID Document or DDO). If we apply this to Nevermined, the DID would be the unique identifier of an object represented in Nevermined (i.e. the Asset ID of an ASSET or the Actor ID of a USER). The DDO SHOULD include the METADATA information associated with this object. The DDO is stored off-chain in Nevermined. In Nevermined, a DID is a string that looks like: did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea which follows the generic DID scheme . Details about how to compute the DID are given below. Publishing and Consumption Flow \u00b6 Here you have the complete flow using as example a new ASSET: DID Resolver Steps: A Data Publisher, using the Smart Contracts, register the new Resource (ie. ASSET) providing the DID and the DID of the Provider acting as Public service returning the DDO of the Resource (ASSET) The DLT register the Resource using the Service Agreement Smart Contract and after of that register the identity using the DidRegistry Smart Contract. In this point, the attribute is raised as a new event The Data Publisher publishes the DDO in the Metadata api A Data Consumer (it could be a frontend application or a backend software), having a DID and using a client library (Python, Javascript, Java, etc) get the service-ddo attribute associated to the DID directly from the Smart Contracts The Data Consumer, using the provider public url, query directly to the provider passing the DID to obtain the DDO DID Documents (DDOs) \u00b6 If a DID is the index key in a key-value pair, then the DID Document is the value to which the index key points. The combination of a DID and its associated DID Document forms the root record for a decentralized identifier. A DDO document is composed of standard DDO attributes: @context id created updated publicKey authentication proof verifiableCredential service Asset metadata can be included as one of the objects inside the \"service\" array, with type \"metadata\" . DDO Services \u00b6 Each type of asset (dataset, algorithm, workflow, etc, ..) typically will have associated different kind of services. There are 2 type of services that are commonly added to all the assets: * metadata - describing the asset * provenance - describing the asset provenance Each service is distinguished by the DDO.service.type attribute. Each service has an attributes section where all the information related to the service is added. As mandatory content, the attributes section will have a main sub-section. This one is important because it must include all the mandatory information that a service has to provide and never change because it is used to calculate the integrity checksum of the service. A part of the attributes.main sub-section, other optional sub-sections can be added (like: attributes.curation or attributes.extra ) depending on the service type. Example: \"service\" : [ { \"index\" : 0 , \"type\" : \"metadata\" , \"serviceEndpoint\" : \"https://service/api/v1/metadata/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {}, \"curation\" : {} } }, { \"index\" : 1 , \"type\" : \"provenance\" , \"serviceEndpoint\" : \"https://service/api/v1/provenance/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } }, { \"index\" : 2 , \"type\" : \"access\" , \"serviceEndpoint\" : \"https://service/api/v1/access/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } } ] You can find a complete example of a DDO . You can find a complete reference of the asset metadata in METADATA SPEC . You can find a complete real world example of a DDO with extended services added, as part of the W3C DID spec. Integrity \u00b6 The Integrity policy for identity and metadata is a sub-specification allowing to validate the integrity of the Metadata associated to an on-chain object (initially an ASSET). How to compute the integrity checksum \u00b6 An ASSET in the system is composed by on-chain information maintained by the DLT and off-chain Metadata information (DDO) stored by the PROVIDER. Technically a user could update the DDO accessing directly to the off-chain database, modifying attributes (e.g. License information, description, etc.) relevant to a previous consumption agreement with an user. The motivation of this is to facilitate a mechanism allowing to the CONSUMER of an object, to validate if the DDO was modified after a previous agreement. This hash composing the integrity checksum is calculated in the following way: The complete content of the service[index].attributes.main is serialized in a common string The string generated is is Hashed using SHA3-256 algorithm (You might have to convert the string to bytes first.) The hash generated as a result of this process is stored in the proof.checksum[index].checksum attribute The previous 3 steps are repeated for every individual service include in the service array. The hash generated is always stored in the proof.checksum array using as key the index of the service computed During the serialization process, the objects to serialize ( service[index].attributes.main are prepared using the following process: The object is sorted alphabetically independently of the existing nested levels In the JSON generated, all the characters between entries are removed ( \\n , \\t , \\r , whitespaces, etc.) As a result must be generated a string of only one line After hashing, in the DDO, the checksums should be represented as a hex string beginning with 0x and ending with 64 hex characters (e.g. 0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377 ) After generating each individual checksum the complete proof.checksum entry is sorted, serialized and hashed as previously described in the other checksums The final hash generated as a result of hashing the checksums (DID CHECKSUM or DID HASH) will be the ID part of the DID (the string after the prefix did:nv: ) Because this DID HASH will be stored on-chain and emitted as an event, a validator could use this information to check if something changed regarding the initial registration. DID Document Proof \u00b6 A proof on a DID Document is cryptographic proof of the integrity of the DID Document. In the DID Specification the proof attribute is optional. We enforce the usage of the proof attribute to demonstrate the Owner of an Asset is signing the proof of integrity of some Asset attributes. The information to sign by the owner is the integrity checksum defined in the above section. const signature = Sign . signMessage ( DID ) The DID Document (DDO) SHOULD include the following proof information: type - Type of proof, in our case \"DDOIntegritySignature\" created - Date and time when the proof was created creator - Address of the user providing the proof signatureValue - Result of the signature given by the creator checksum - Checksums of the individual services included in the DDO Here is an example proof section to add in the DDO: \"proof\" : { \"type\" : \"DDOIntegritySignature\" , \"created\" : \"2016-02-08T16:02:20Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"0xc9eeb2b8106e\u20266abfdc5d1192641b\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"1\" : \"0x999999952b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3\" } } Using the proof information, a third-party with access to the DDO could validate the creator signed a specific integrity checksum referring to an Asset. Length of a DID \u00b6 The length of a DID must be compliant with the underlying storage layer and function calls. Given that decentralized virtual machines make use of contract languages such as Solidity and WASM, it is advised to fit the DID in structures such as bytes32 . It would be nice to store the did:nv: prefix in those 32 bytes, but that means fewer than 32 bytes would be left for storing the rest (25 bytes since \"did:nv:\" takes 7 bytes if using UTF-8). If the rest is a secure hash, then we need a 25-byte secure hash, but secure hashes typically have 28, 32 or more bytes, so that won't work. Only the hash value needs to be stored, not the did:nv: prefix, because it should be clear from context that the value is a Nevermined DID. How to compute a DID \u00b6 The DID ( id ) string begins with did:nv: and is followed by a string representation of a bytes32. As is described previously, the DID is calculating doing the Hash (SHA3-256) of the DDO.proof.checksum entry Registry \u00b6 To register the different kind of objects can be stored in a simple register contract named DidRegistry . This DidRegistry can act as generic/flexible way to associate Resources (ie. Assets) to the public providers resolving the DDO (and Metadata included) of those resources. The key of the Identity entity in Nevermined is the DID . Each entity will have a unique DID. To resolve the DDO associated to a Resource (Asset), associated to this Resource DID we have the DID of the Provider giving access to this Resource. The Provider will have associated a mapping (key - value) of attributes. One of those can be used to related with the public service returning the DDO of a specific resource. Applied to Assets, typically are part of a Service Agreement. The suggested approach to implement this is: Associate the Resource (ie. Asset DID) to the Provider DID Each Provider will have associated a Public URL where the provider is exposing the DDOs Here is a draft DidRegistry implementation: // This piece of code is for reference only! // Doesn't include any validation, types could be reviewed, enums, etc contract DidRegistry { event DIDAttributeRegistered ( bytes32 indexed did , address indexed owner , bytes32 indexed checksum , string value , uint updatedAt ); mapping ( bytes32 => DIDRegister ) private didRegister ; function registerAttribute ( bytes32 _did , bytes32 _checksum , string _value ) public { // .... emit DIDAttributeRegistered ( _did , msg.sender , _checksum , _value , block.number ); } } To register the provider publicly resolving the DDO associated to a DID, we will register an attribute with the public hostname of that provider: registerAttribute ( \"21tDAKCERh95uGgKbJNHYp\" , \"328aabb94534935864312\" , \"https://myprovider.example.com/ddo\" ) Resolver \u00b6 The resolving capabilities will be encapsulated in the Nevermined SDK libraries (JavaScript, Python, etc.), allowing to resolve a DDO directly speaking with the Smart Contracts. No third-party requests or API need to be integrated. This allows to have a simple a seam-less integration from the consumer side. This is a generic definition of what could be exposed in the client libraries from an API point of view: function DDO resolve ( String did ) { // black magic return ddo ; } To resolve a DID to the associated DDO, some information is stored on-chain associated to the DID. In the approach recommended in the scope of this SPEC, this is stored as an attribute associated to the DidAttributeRegistered event. Because the DID and key are indexed parameters of the event, a consumer in any supported web3 language could filter the DidAttributeRegistered events filtering by the DID and the key named \"service-ddo\" . A DDO pointing to a DID could be resolved hierarchically using the same mechanism. This is an example in JavaScript using web3.js: const event = contractInstance . DidAttributeRegistered ( { did : '21tDAKCERh95uGgKbJNHYp' }, { fromBlock : 0 , toBlock : 'latest' } ); Here in Python using web3.py: event = mycontract . events . DidAttributeRegistered . createFilter ( fromBlock = 'latest' , argument_filters = { 'did' : '21tDAKCERh95uGgKbJNHYp' }) This logic could be encapsulated in the client libraries ( SDK ) in different languages, allowing to the client applications to get the attributes enabling to resolve the DDO associated to the DID. Using this information a consumer can query directly to the provider able to return the DDO. References \u00b6 DID Spec from the W3C Credentials Community Group","title":"Decentralized Identifiers"},{"location":"architecture/specs/did/#did-spec-decentralized-identifiers","text":"shortname: DID name: Decentralized Identifiers type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: DID SPEC: Decentralized Identifiers Motivation Specification Proposed Solution Decentralized IDs (DIDs) Publishing and Consumption Flow DID Documents (DDOs) DDO Services Integrity How to compute the integrity checksum DID Document Proof Length of a DID How to compute a DID Registry Resolver References This specification is based on the W3C DID specification , which was at version 0.11 as of August 2018.","title":"DID SPEC: Decentralized Identifiers"},{"location":"architecture/specs/did/#motivation","text":"The main motivations of this SPEC are: Design a solution to extend the current architecture to use Decentralized Identifiers (DIDs) and DID Documents (DDOs) Understand how to register information on-chain with off-chain integrity associated Understand how to resolve DIDs into DDOs Design a solution facilitating alignment of on-chain and off-chain information Establishing the mechanism to know if the DDO associated with a DID was modified Defining the common mechanisms, interfaces and APIs to implemented the designed solution Define how Nevermined assets can be modeled with a DID/DDO data model Understand how DID hubs are formed, and how they integrate a business and storage layer","title":"Motivation"},{"location":"architecture/specs/did/#specification","text":"Requirements are: The DID resolving capabilities MUST be exposed in the client libraries, enabling to resolve a DDO directly in a totally transparent way ASSETS are DATA objects describing RESOURCES under control of a PUBLISHER DLT stores on-chain only the essential information about ASSETS PROVIDERS store the ASSET metadata off-chain DLT doesn't store any ASSET metadata Nevermined doesn't store ASSET contents (e.g. files) An ASSET is modeled in Nevermined as on-chain information stored in the DLT and metadata stored in METADATA API ASSETS on-chain information only can be modified by OWNERS or DELEGATED USERS ASSETS can be resolved using a Decentralized ID (DID) included on-chain and off-chain A DID Document (DDO) should include the ASSET metadata Any kind of object registered in Nevermined MUST have a DID allowing one to uniquely identify that object in the system ASSET DDO (and the metadata included as part of the DDO) is associated to the ASSET information stored on-chain using a common DID A DID can be resolved to get access to a DDO ASSET DDOs can be updated without updating the on-chain information ASSET information stored in the DLT will include a checksum attribute The ASSET on-chain checksum attribute SHOULD include a one-way HASH calculated using the DDO content After the DDO resolving, the DDO HASH can be calculated off-chain to validate if the on-chain and off-chain information is aligned A HASH not matching with the checksum on-chain means the DDO was modified without the on-chain update The function to calculate the hash MUST BE standard","title":"Specification"},{"location":"architecture/specs/did/#proposed-solution","text":"","title":"Proposed Solution"},{"location":"architecture/specs/did/#decentralized-ids-dids","text":"A DID is a unique identifier that can be resolved or de-referenced to a standard resource describing the entity (a DID Document or DDO). If we apply this to Nevermined, the DID would be the unique identifier of an object represented in Nevermined (i.e. the Asset ID of an ASSET or the Actor ID of a USER). The DDO SHOULD include the METADATA information associated with this object. The DDO is stored off-chain in Nevermined. In Nevermined, a DID is a string that looks like: did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea which follows the generic DID scheme . Details about how to compute the DID are given below.","title":"Decentralized IDs (DIDs)"},{"location":"architecture/specs/did/#publishing-and-consumption-flow","text":"Here you have the complete flow using as example a new ASSET: DID Resolver Steps: A Data Publisher, using the Smart Contracts, register the new Resource (ie. ASSET) providing the DID and the DID of the Provider acting as Public service returning the DDO of the Resource (ASSET) The DLT register the Resource using the Service Agreement Smart Contract and after of that register the identity using the DidRegistry Smart Contract. In this point, the attribute is raised as a new event The Data Publisher publishes the DDO in the Metadata api A Data Consumer (it could be a frontend application or a backend software), having a DID and using a client library (Python, Javascript, Java, etc) get the service-ddo attribute associated to the DID directly from the Smart Contracts The Data Consumer, using the provider public url, query directly to the provider passing the DID to obtain the DDO","title":"Publishing and Consumption Flow"},{"location":"architecture/specs/did/#did-documents-ddos","text":"If a DID is the index key in a key-value pair, then the DID Document is the value to which the index key points. The combination of a DID and its associated DID Document forms the root record for a decentralized identifier. A DDO document is composed of standard DDO attributes: @context id created updated publicKey authentication proof verifiableCredential service Asset metadata can be included as one of the objects inside the \"service\" array, with type \"metadata\" .","title":"DID Documents (DDOs)"},{"location":"architecture/specs/did/#ddo-services","text":"Each type of asset (dataset, algorithm, workflow, etc, ..) typically will have associated different kind of services. There are 2 type of services that are commonly added to all the assets: * metadata - describing the asset * provenance - describing the asset provenance Each service is distinguished by the DDO.service.type attribute. Each service has an attributes section where all the information related to the service is added. As mandatory content, the attributes section will have a main sub-section. This one is important because it must include all the mandatory information that a service has to provide and never change because it is used to calculate the integrity checksum of the service. A part of the attributes.main sub-section, other optional sub-sections can be added (like: attributes.curation or attributes.extra ) depending on the service type. Example: \"service\" : [ { \"index\" : 0 , \"type\" : \"metadata\" , \"serviceEndpoint\" : \"https://service/api/v1/metadata/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {}, \"curation\" : {} } }, { \"index\" : 1 , \"type\" : \"provenance\" , \"serviceEndpoint\" : \"https://service/api/v1/provenance/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } }, { \"index\" : 2 , \"type\" : \"access\" , \"serviceEndpoint\" : \"https://service/api/v1/access/assets/ddo/did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } } ] You can find a complete example of a DDO . You can find a complete reference of the asset metadata in METADATA SPEC . You can find a complete real world example of a DDO with extended services added, as part of the W3C DID spec.","title":"DDO Services"},{"location":"architecture/specs/did/#integrity","text":"The Integrity policy for identity and metadata is a sub-specification allowing to validate the integrity of the Metadata associated to an on-chain object (initially an ASSET).","title":"Integrity"},{"location":"architecture/specs/did/#how-to-compute-the-integrity-checksum","text":"An ASSET in the system is composed by on-chain information maintained by the DLT and off-chain Metadata information (DDO) stored by the PROVIDER. Technically a user could update the DDO accessing directly to the off-chain database, modifying attributes (e.g. License information, description, etc.) relevant to a previous consumption agreement with an user. The motivation of this is to facilitate a mechanism allowing to the CONSUMER of an object, to validate if the DDO was modified after a previous agreement. This hash composing the integrity checksum is calculated in the following way: The complete content of the service[index].attributes.main is serialized in a common string The string generated is is Hashed using SHA3-256 algorithm (You might have to convert the string to bytes first.) The hash generated as a result of this process is stored in the proof.checksum[index].checksum attribute The previous 3 steps are repeated for every individual service include in the service array. The hash generated is always stored in the proof.checksum array using as key the index of the service computed During the serialization process, the objects to serialize ( service[index].attributes.main are prepared using the following process: The object is sorted alphabetically independently of the existing nested levels In the JSON generated, all the characters between entries are removed ( \\n , \\t , \\r , whitespaces, etc.) As a result must be generated a string of only one line After hashing, in the DDO, the checksums should be represented as a hex string beginning with 0x and ending with 64 hex characters (e.g. 0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377 ) After generating each individual checksum the complete proof.checksum entry is sorted, serialized and hashed as previously described in the other checksums The final hash generated as a result of hashing the checksums (DID CHECKSUM or DID HASH) will be the ID part of the DID (the string after the prefix did:nv: ) Because this DID HASH will be stored on-chain and emitted as an event, a validator could use this information to check if something changed regarding the initial registration.","title":"How to compute the integrity checksum"},{"location":"architecture/specs/did/#did-document-proof","text":"A proof on a DID Document is cryptographic proof of the integrity of the DID Document. In the DID Specification the proof attribute is optional. We enforce the usage of the proof attribute to demonstrate the Owner of an Asset is signing the proof of integrity of some Asset attributes. The information to sign by the owner is the integrity checksum defined in the above section. const signature = Sign . signMessage ( DID ) The DID Document (DDO) SHOULD include the following proof information: type - Type of proof, in our case \"DDOIntegritySignature\" created - Date and time when the proof was created creator - Address of the user providing the proof signatureValue - Result of the signature given by the creator checksum - Checksums of the individual services included in the DDO Here is an example proof section to add in the DDO: \"proof\" : { \"type\" : \"DDOIntegritySignature\" , \"created\" : \"2016-02-08T16:02:20Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"0xc9eeb2b8106e\u20266abfdc5d1192641b\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"1\" : \"0x999999952b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3\" } } Using the proof information, a third-party with access to the DDO could validate the creator signed a specific integrity checksum referring to an Asset.","title":"DID Document Proof"},{"location":"architecture/specs/did/#length-of-a-did","text":"The length of a DID must be compliant with the underlying storage layer and function calls. Given that decentralized virtual machines make use of contract languages such as Solidity and WASM, it is advised to fit the DID in structures such as bytes32 . It would be nice to store the did:nv: prefix in those 32 bytes, but that means fewer than 32 bytes would be left for storing the rest (25 bytes since \"did:nv:\" takes 7 bytes if using UTF-8). If the rest is a secure hash, then we need a 25-byte secure hash, but secure hashes typically have 28, 32 or more bytes, so that won't work. Only the hash value needs to be stored, not the did:nv: prefix, because it should be clear from context that the value is a Nevermined DID.","title":"Length of a DID"},{"location":"architecture/specs/did/#how-to-compute-a-did","text":"The DID ( id ) string begins with did:nv: and is followed by a string representation of a bytes32. As is described previously, the DID is calculating doing the Hash (SHA3-256) of the DDO.proof.checksum entry","title":"How to compute a DID"},{"location":"architecture/specs/did/#registry","text":"To register the different kind of objects can be stored in a simple register contract named DidRegistry . This DidRegistry can act as generic/flexible way to associate Resources (ie. Assets) to the public providers resolving the DDO (and Metadata included) of those resources. The key of the Identity entity in Nevermined is the DID . Each entity will have a unique DID. To resolve the DDO associated to a Resource (Asset), associated to this Resource DID we have the DID of the Provider giving access to this Resource. The Provider will have associated a mapping (key - value) of attributes. One of those can be used to related with the public service returning the DDO of a specific resource. Applied to Assets, typically are part of a Service Agreement. The suggested approach to implement this is: Associate the Resource (ie. Asset DID) to the Provider DID Each Provider will have associated a Public URL where the provider is exposing the DDOs Here is a draft DidRegistry implementation: // This piece of code is for reference only! // Doesn't include any validation, types could be reviewed, enums, etc contract DidRegistry { event DIDAttributeRegistered ( bytes32 indexed did , address indexed owner , bytes32 indexed checksum , string value , uint updatedAt ); mapping ( bytes32 => DIDRegister ) private didRegister ; function registerAttribute ( bytes32 _did , bytes32 _checksum , string _value ) public { // .... emit DIDAttributeRegistered ( _did , msg.sender , _checksum , _value , block.number ); } } To register the provider publicly resolving the DDO associated to a DID, we will register an attribute with the public hostname of that provider: registerAttribute ( \"21tDAKCERh95uGgKbJNHYp\" , \"328aabb94534935864312\" , \"https://myprovider.example.com/ddo\" )","title":"Registry"},{"location":"architecture/specs/did/#resolver","text":"The resolving capabilities will be encapsulated in the Nevermined SDK libraries (JavaScript, Python, etc.), allowing to resolve a DDO directly speaking with the Smart Contracts. No third-party requests or API need to be integrated. This allows to have a simple a seam-less integration from the consumer side. This is a generic definition of what could be exposed in the client libraries from an API point of view: function DDO resolve ( String did ) { // black magic return ddo ; } To resolve a DID to the associated DDO, some information is stored on-chain associated to the DID. In the approach recommended in the scope of this SPEC, this is stored as an attribute associated to the DidAttributeRegistered event. Because the DID and key are indexed parameters of the event, a consumer in any supported web3 language could filter the DidAttributeRegistered events filtering by the DID and the key named \"service-ddo\" . A DDO pointing to a DID could be resolved hierarchically using the same mechanism. This is an example in JavaScript using web3.js: const event = contractInstance . DidAttributeRegistered ( { did : '21tDAKCERh95uGgKbJNHYp' }, { fromBlock : 0 , toBlock : 'latest' } ); Here in Python using web3.py: event = mycontract . events . DidAttributeRegistered . createFilter ( fromBlock = 'latest' , argument_filters = { 'did' : '21tDAKCERh95uGgKbJNHYp' }) This logic could be encapsulated in the client libraries ( SDK ) in different languages, allowing to the client applications to get the attributes enabling to resolve the DDO associated to the DID. Using this information a consumer can query directly to the provider able to return the DDO.","title":"Resolver"},{"location":"architecture/specs/did/#references","text":"DID Spec from the W3C Credentials Community Group","title":"References"},{"location":"architecture/specs/examples/","text":"Nevermind Specs Examples \u00b6 This folder includes examples of the DDO files related with the different Nevermind specs. You can use it as reference. These examples are used & validated in the Integration Tests flows of the Nevermind components.","title":"Nevermind Specs Examples"},{"location":"architecture/specs/examples/#nevermind-specs-examples","text":"This folder includes examples of the DDO files related with the different Nevermind specs. You can use it as reference. These examples are used & validated in the Integration Tests flows of the Nevermind components.","title":"Nevermind Specs Examples"},{"location":"architecture/specs/fl/","text":"COMPUTE FL: Nevermined Federated Learning Orchestration \u00b6 shortname: FL name: Nevermined Federated Learning Orchestration type: Draft status: Valid version: 0.1 editor: Rodolphe Marques <rodolphe@keyko.io> contributors: Aitor Argomaniz <aitor@keyko.io>, Enrique Ruiz <kike@keyko.io> COMPUTE FL: Nevermined Federated Learning Orchestration Federated Learning integration in the Nevermined Data in Situ Computation Terminology Motivation Actors Architecture Running the Coordinator Flow Running the Participants Flow Federated Learning Session Flow Federated Learning DDOs Coordinator Consumer DDO Coordinator Provider DDO Participant Consumer DDO Participant Provider DDO Federated Learning integration in the Nevermined Data in Situ Computation \u00b6 This SPEC introduces the integration pattern for the usage a Federated Learning backend in the Nevermined DISC architecture . The Nevermined Data in Situ Computation solution introduces a solution where different compute backends can be plugged in order to support different remote computation use cases. This spec details how Federated Learning sessions could be executed on Nevermined. Terminology \u00b6 Coordinator : All the components required to perform the coordination of a Federated Learning session. The components provided by the xain-fl framework (coordinator + aggregator) Participant : Component responsible for interacting with the coordinator and executing the machine learning task over the data. Federated Learning Session : The time from setup of the coordinator to the successful execution of the machine learning plan. Typically this involves coordinating the participants for a finite number or rounds and then storing the resulting model Motivation \u00b6 The main motivations of this SPEC are: Identify the actors involved in the execution of a Federated Learning session on Nevermined Identify the integration points between the xain framework components and the Nevermined components Detail the execution flow of a Federated Learning session on Nevermined Actors \u00b6 The different actors interacting in this flow are: PROVIDERS: Give access to the Compute Services and to the data CONSUMERS: Want to make use of the Compute Services and access to data MARKETPLACE or DOMAINS: Store the DDO/Metadata related to the Assets/services INFRASTRUCTURE: Infrastructure required to run the Nevermined compute stack Here we may have two types of providers. A normal provider like the one specified in Data in Situ Computation spec. And another type of provider that only provides compute but now access to the data (to run the coordinator). Architecture \u00b6 Running the Coordinator \u00b6 This section details how a Client/Data Scientist can setup and run a Coordinator using Nevermined Compute. The main requirements are: A COMPUTE PROVIDER or PROVIDER defines the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources Allow incoming connections for the Participants A COMSUMER defines the parameters of the coordinator and creates an execution workflow using a predefined coordinator workflow template This is a different type of workflow with no inputs, outputs and access to data A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute Setting up the Coordinator Flow \u00b6 The CONSUMER / Data Scientist locks the payment for the service The CONSUMER / Data scientist provides a DID for the workflow to execute The gateway could potentially provide specific endpoints for this since the workflow is always the same. The only thing that changes is the parameters to configure the coordinator The Gateway checks if the CONSUMER / Data scientist as the permissions to start a new coordinator The Nevermined compute stack starts a new coordinator The url to connect to the coordinator is published (need to figure out how) In the meantime participants will connect to the coordinator and the coordinator will orchestrate the Federated Learning session After the Federated Learning session is finished the coordinator publishes the resulting trained model and shuts down. Running the Participants \u00b6 This section details how a Client/Data Scientist can setup and run a set of Participants using Nevermined Compute. This should be simpler to integrate because it\u2019s very similar to the data in situ computation use case. The main difference being that the algorithm is actually wrapped around the xain python sdk and it needs to be able to perform outgoing network connection to connect to the coordinator. The main requirements are: A PROVIDER defines the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources A COMPUTE PROVIDER defines a Compute Service in the scope of the Asset (DID/DDO) of the dataset that can be computed A CONSUMER defines the task to execute modeling it in a Workflow (including configuration, input, participant) In this case the transformation is just the participant code It does not need to produce any output since that is handled by the coordinator A workflow is a new type of Asset. It can be resolvable and be used across multiple independent compute services A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute Running the participants Flow \u00b6 The CONSUMER / Data Scientist locks the payment The CONSUMER / Data Scientist requests the execution of the participant The Gateway checks if the CONSUMER / Data Scientist has the permissions to execute the participant on the data The Nevermined compute sets up the environment The participants access the data and performs the machine learning task The participant needs to be able to communicate with the coordinator throughout the entire Federated Learning session. The coordinator will be external to the Infrastructure Provider The participant does not need to create a new asset since that is handled by the coordinator Federated Learning Session Flow \u00b6 This section details a high level overview of a Federated Learning Session using two different data providers. Federated Learning Session Flow The Data Scientist starts by finding a provider to run the Coordinator compute job and the data that it requires (possibly using the marketplace). The flow is: The Data Scientist starts by setting the execution parameters for the coordinator and publishes it as a workflow/ddo The Data Scientist purchases data in situ computation for both Data Provider X and Y and defines the workflow/ddo with the code that will run the participants The Data Scientist purchases the Coordinator compute service The Data Scientist starts the Coordinator The Data Scientist starts the participants The Participants work together with the coordinator over the course of multiple rounds as defined in point 1. Once all rounds are finished the Coordinator publishes the final trained model The Data Scientist fetches the trained model. Federated Learning DDOs \u00b6 This section details the both the consumer and provider DDOs for coordinator and participant. Coordinator Consumer DDO \u00b6 { \"serviceAgreementId\" : \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\" , \"workflow\" : { \"@context\" : \"https://w3id.org/future-method/v1\" , \"authentication\" : [], \"created\" : \"2019-04-09T19:02:11Z\" , \"id\" : \"did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"proof\" : { \"created\" : \"2019-04-09T19:02:11Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"1cd57300733bcbcda0beb59b3e076de6419c0d7674e7befb77820b53c79e3aa8f1776effc64cf088bad8cb694cc4d71ebd74a13b2f75893df5a53f3f318f6cf828\" , \"type\" : \"DDOIntegritySignature\" }, \"publicKey\" : [ { \"id\" : \"did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"owner\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"type\" : \"EthereumECDSAKey\" } ], \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://172.15.0.15:5000/api/v1/metadata/assets/ddo/did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"dateCreated\" : \"2012-10-10T17:00:00Z\" , \"type\" : \"fl-coordinator\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"parameters\" : { \"minParticipants\" : 1 , \"participantsRatio\" : 1 , \"rounds\" : 10 , } \"workflow\" : { \"stages\" : [ { \"index\" : 0 , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } } } ] } } } } ] } } The main information that needs to be provided is: - tag : The version of the xain-fl image to use - minParticipants : The minimum number of participants required by the coordinator - participantsRation : The ratio of participants that will be selected in every round - rounds : The number of rounds the coordinator should do Note that service.main.type is set to fl-coordinator to indicate this is not a normal workflow Coordinator Provider DDO \u00b6 { \"@context\" : \"https://w3id.org/future-method/v1\" , \"authentication\" : [], \"created\" : \"2019-04-09T19:02:11Z\" , \"id\" : \"did:op:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"proof\" : { \"created\" : \"2019-04-09T19:02:11Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"1cd57300733bcbcda0beb59b3e076de6419c0d7674e7befb77820b53c79e3aa8f1776effc64cf088bad8cb694cc4d71ebd74a13b2f75893df5a53f3f318f6cf828\" , \"type\" : \"DDOIntegritySignature\" }, \"publicKey\" : [ { \"id\" : \"did:op:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"owner\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"type\" : \"EthereumECDSAKey\" } ], \"service\" : [ { \"type\" : \"metadata\" , \"index\" : 0 , \"serviceEndpoint\" : \"http://mymetadata-api.org/api/v1/metadata/assets/ddo/{did}\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } }, { \"type\" : \"fl-coordinator\" , \"index\" : 2 , \"serviceEndpoint\" : \"http://mygateway.org/api/v1/gateway/services/execute\" , \"templateId\" : \"804932804923850985093485039850349850439583409583404534231321131a\" , \"attributes\" : { \"main\" : { \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"price\" : \"10\" , \"timeout\" : 86400 , \"provider\" : { \"type\" : \"Azure\" , \"description\" : \"\" , \"environment\" : { \"cluster\" : { \"type\" : \"Kubernetes\" , \"url\" : \"http://10.0.0.17/xxx\" }, \"supportedContainers\" : [ { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }, { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"v1\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } ], \"supportedServers\" : [ { \"serverId\" : \"1\" , \"serverType\" : \"xlsize\" , \"price\" : \"50\" , \"cpu\" : \"16\" , \"gpu\" : \"0\" , \"memory\" : \"128gb\" , \"disk\" : \"160gb\" , \"maxExecutionTime\" : 86400 }, { \"serverId\" : \"2\" , \"serverType\" : \"medium\" , \"price\" : \"10\" , \"cpu\" : \"2\" , \"gpu\" : \"0\" , \"memory\" : \"8gb\" , \"disk\" : \"80gb\" , \"maxExecutionTime\" : 86400 } ] } } }, \"additionalInformation\" : {} }, \"serviceAgreementTemplate\" : { \"contractName\" : \"ServiceExecutionTemplate\" , \"events\" : [ { \"name\" : \"AgreementCreated\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"serviceExecutionTemplate\" , \"functionName\" : \"fulfillLockPaymentCondition\" , \"version\" : \"0.1\" } } ], \"fulfillmentOrder\" : [ \"lockPayment.fulfill\" , \"serviceExecution.fulfill\" , \"escrowPayment.fulfill\" ], \"conditionDependency\" : { \"lockPayment\" : [], \"serviceExecution\" : [], \"releaseReward\" : [ \"lockPayment\" , \"serviceExecution\" ] }, \"conditions\" : [ { \"name\" : \"lockPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"LockPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_rewardAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"lockPaymentConditon\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"execCompute\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"ComputeExecutionCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_grantee\" , \"type\" : \"address\" , \"value\" : \"\" } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }, { \"name\" : \"TimedOut\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"escrowPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"EscrowPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] }, { \"name\" : \"_sender\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_lockCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_releaseCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"escrowPaymentConditon\" , \"functionName\" : \"verifyRewardTokens\" , \"version\" : \"0.1\" } } ] } ] } } ] } Participant Consumer DDO \u00b6 { \"serviceAgreementId\" : \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\" , \"workflow\" : { \"@context\" : \"https://w3id.org/did/v1\" , \"authentication\" : [ { \"type\" : \"RsaSignatureAuthentication2018\" , \"publicKey\" : \"did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" } ], \"created\" : \"2019-02-08T08:13:49Z\" , \"updated\" : \"2019-06-30T14:53:09Z\" , \"id\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"proof\" : { \"created\" : \"2019-02-08T08:13:41Z\" , \"creator\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"signatureValue\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"type\" : \"DDOIntegritySignature\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"1\" : \"0x999999952b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3\" } }, \"publicKey\" : [ { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-1\" , \"type\" : \"RsaVerificationKey2018\" , \"owner\" : \"did:nv:6027c1e7cbae06a91fce0557ee53195284825f56a7100be0c53cbf4391aa26cc\" , \"publicKeyPem\" : \"-----BEGIN PUBLIC KEY...END PUBLIC KEY-----\\r\\n\" }, { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-2\" , \"type\" : \"Ed25519VerificationKey2018\" , \"owner\" : \"did:nv:4c27a254e607cdf91a1206480e7eb8c74856102316c1a462277d4f21c02373b6\" , \"publicKeyBase58\" : \"H3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\" }, { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-3\" , \"type\" : \"RsaPublicKeyExchangeKey2018\" , \"owner\" : \"did:nv:5f6b885202ffb9643874be529302eb00d55e226959f1fbacaeda592c5b5c9484\" , \"publicKeyPem\" : \"-----BEGIN PUBLIC KEY...END PUBLIC KEY-----\\r\\n\" } ], \"verifiableCredential\" : [ { \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://www.w3.org/2018/credentials/examples/v1\" ], \"id\" : \"1872\" , \"type\" : [ \"read\" , \"update\" , \"deactivate\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : { \"id\" : \"0x89328493849328493284932\" }, \"proof\" : { \"type\" : \"RsaSignature2018\" , \"created\" : \"2019-01-01T19:73:24Z\" , \"proofPurpose\" : \"assertionMethod\" , \"signatureValue\" : \"ABCJSDAO23...1tzjn4w==\" } } ], \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"author\" : \"John Doe\" , \"checksum\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"datePublished\" : \"2019-05-08T08:13:49Z\" , \"license\" : \"CC-BY\" , \"name\" : \"My workflow\" , \"price\" : \"1\" , \"type\" : \"workflow\" , \"workflow\" : { \"stages\" : [ { \"index\" : 0 , \"stageType\" : \"Participant\" , \"requirements\" : { \"container\" : { \"image\" : \"keykoio/xain-participant\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [ { \"index\" : 0 , \"id\" : \"did:nv:12345\" } ], \"transformation\" : { \"id\" : \"did:nv:abcde\" }, \"output\" : { } } ] } }, \"additionalInformation\" : { \"description\" : \"Workflow to aggregate weather information\" , \"tags\" : [ \"weather\" , \"uk\" , \"2011\" , \"workflow\" , \"aggregation\" ], \"copyrightHolder\" : \"John Doe\" } } } ] } } This is a normal data in situ computation workflow with one stage, a set of inputs, one transformation and no output since the participant shouldn't need to generate any data. Participant Provider DDO \u00b6","title":"Federated Learning"},{"location":"architecture/specs/fl/#compute-fl-nevermined-federated-learning-orchestration","text":"shortname: FL name: Nevermined Federated Learning Orchestration type: Draft status: Valid version: 0.1 editor: Rodolphe Marques <rodolphe@keyko.io> contributors: Aitor Argomaniz <aitor@keyko.io>, Enrique Ruiz <kike@keyko.io> COMPUTE FL: Nevermined Federated Learning Orchestration Federated Learning integration in the Nevermined Data in Situ Computation Terminology Motivation Actors Architecture Running the Coordinator Flow Running the Participants Flow Federated Learning Session Flow Federated Learning DDOs Coordinator Consumer DDO Coordinator Provider DDO Participant Consumer DDO Participant Provider DDO","title":"COMPUTE FL: Nevermined Federated Learning Orchestration"},{"location":"architecture/specs/fl/#federated-learning-integration-in-the-nevermined-data-in-situ-computation","text":"This SPEC introduces the integration pattern for the usage a Federated Learning backend in the Nevermined DISC architecture . The Nevermined Data in Situ Computation solution introduces a solution where different compute backends can be plugged in order to support different remote computation use cases. This spec details how Federated Learning sessions could be executed on Nevermined.","title":"Federated Learning integration in the Nevermined Data in Situ Computation"},{"location":"architecture/specs/fl/#terminology","text":"Coordinator : All the components required to perform the coordination of a Federated Learning session. The components provided by the xain-fl framework (coordinator + aggregator) Participant : Component responsible for interacting with the coordinator and executing the machine learning task over the data. Federated Learning Session : The time from setup of the coordinator to the successful execution of the machine learning plan. Typically this involves coordinating the participants for a finite number or rounds and then storing the resulting model","title":"Terminology"},{"location":"architecture/specs/fl/#motivation","text":"The main motivations of this SPEC are: Identify the actors involved in the execution of a Federated Learning session on Nevermined Identify the integration points between the xain framework components and the Nevermined components Detail the execution flow of a Federated Learning session on Nevermined","title":"Motivation"},{"location":"architecture/specs/fl/#actors","text":"The different actors interacting in this flow are: PROVIDERS: Give access to the Compute Services and to the data CONSUMERS: Want to make use of the Compute Services and access to data MARKETPLACE or DOMAINS: Store the DDO/Metadata related to the Assets/services INFRASTRUCTURE: Infrastructure required to run the Nevermined compute stack Here we may have two types of providers. A normal provider like the one specified in Data in Situ Computation spec. And another type of provider that only provides compute but now access to the data (to run the coordinator).","title":"Actors"},{"location":"architecture/specs/fl/#architecture","text":"","title":"Architecture"},{"location":"architecture/specs/fl/#running-the-coordinator","text":"This section details how a Client/Data Scientist can setup and run a Coordinator using Nevermined Compute. The main requirements are: A COMPUTE PROVIDER or PROVIDER defines the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources Allow incoming connections for the Participants A COMSUMER defines the parameters of the coordinator and creates an execution workflow using a predefined coordinator workflow template This is a different type of workflow with no inputs, outputs and access to data A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute Setting up the Coordinator","title":"Running the Coordinator"},{"location":"architecture/specs/fl/#flow","text":"The CONSUMER / Data Scientist locks the payment for the service The CONSUMER / Data scientist provides a DID for the workflow to execute The gateway could potentially provide specific endpoints for this since the workflow is always the same. The only thing that changes is the parameters to configure the coordinator The Gateway checks if the CONSUMER / Data scientist as the permissions to start a new coordinator The Nevermined compute stack starts a new coordinator The url to connect to the coordinator is published (need to figure out how) In the meantime participants will connect to the coordinator and the coordinator will orchestrate the Federated Learning session After the Federated Learning session is finished the coordinator publishes the resulting trained model and shuts down.","title":"Flow"},{"location":"architecture/specs/fl/#running-the-participants","text":"This section details how a Client/Data Scientist can setup and run a set of Participants using Nevermined Compute. This should be simpler to integrate because it\u2019s very similar to the data in situ computation use case. The main difference being that the algorithm is actually wrapped around the xain python sdk and it needs to be able to perform outgoing network connection to connect to the coordinator. The main requirements are: A PROVIDER defines the conditions that a Compute service supports. It includes: What kind of image (Docker container) can be deployed in the infrastructure What are the infrastructure resources available (CPU, memory, storage) What is the price of using the infrastructure resources A COMPUTE PROVIDER defines a Compute Service in the scope of the Asset (DID/DDO) of the dataset that can be computed A CONSUMER defines the task to execute modeling it in a Workflow (including configuration, input, participant) In this case the transformation is just the participant code It does not need to produce any output since that is handled by the coordinator A workflow is a new type of Asset. It can be resolvable and be used across multiple independent compute services A CONSUMER purchasing a compute service defines which Workflow (DID) is going to execute Running the participants","title":"Running the Participants"},{"location":"architecture/specs/fl/#flow_1","text":"The CONSUMER / Data Scientist locks the payment The CONSUMER / Data Scientist requests the execution of the participant The Gateway checks if the CONSUMER / Data Scientist has the permissions to execute the participant on the data The Nevermined compute sets up the environment The participants access the data and performs the machine learning task The participant needs to be able to communicate with the coordinator throughout the entire Federated Learning session. The coordinator will be external to the Infrastructure Provider The participant does not need to create a new asset since that is handled by the coordinator","title":"Flow"},{"location":"architecture/specs/fl/#federated-learning-session-flow","text":"This section details a high level overview of a Federated Learning Session using two different data providers. Federated Learning Session Flow The Data Scientist starts by finding a provider to run the Coordinator compute job and the data that it requires (possibly using the marketplace). The flow is: The Data Scientist starts by setting the execution parameters for the coordinator and publishes it as a workflow/ddo The Data Scientist purchases data in situ computation for both Data Provider X and Y and defines the workflow/ddo with the code that will run the participants The Data Scientist purchases the Coordinator compute service The Data Scientist starts the Coordinator The Data Scientist starts the participants The Participants work together with the coordinator over the course of multiple rounds as defined in point 1. Once all rounds are finished the Coordinator publishes the final trained model The Data Scientist fetches the trained model.","title":"Federated Learning Session Flow"},{"location":"architecture/specs/fl/#federated-learning-ddos","text":"This section details the both the consumer and provider DDOs for coordinator and participant.","title":"Federated Learning DDOs"},{"location":"architecture/specs/fl/#coordinator-consumer-ddo","text":"{ \"serviceAgreementId\" : \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\" , \"workflow\" : { \"@context\" : \"https://w3id.org/future-method/v1\" , \"authentication\" : [], \"created\" : \"2019-04-09T19:02:11Z\" , \"id\" : \"did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"proof\" : { \"created\" : \"2019-04-09T19:02:11Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"1cd57300733bcbcda0beb59b3e076de6419c0d7674e7befb77820b53c79e3aa8f1776effc64cf088bad8cb694cc4d71ebd74a13b2f75893df5a53f3f318f6cf828\" , \"type\" : \"DDOIntegritySignature\" }, \"publicKey\" : [ { \"id\" : \"did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"owner\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"type\" : \"EthereumECDSAKey\" } ], \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://172.15.0.15:5000/api/v1/metadata/assets/ddo/did:nv:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"dateCreated\" : \"2012-10-10T17:00:00Z\" , \"type\" : \"fl-coordinator\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"parameters\" : { \"minParticipants\" : 1 , \"participantsRatio\" : 1 , \"rounds\" : 10 , } \"workflow\" : { \"stages\" : [ { \"index\" : 0 , \"requirements\" : { \"serverInstances\" : 1 , \"container\" : { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } } } ] } } } } ] } } The main information that needs to be provided is: - tag : The version of the xain-fl image to use - minParticipants : The minimum number of participants required by the coordinator - participantsRation : The ratio of participants that will be selected in every round - rounds : The number of rounds the coordinator should do Note that service.main.type is set to fl-coordinator to indicate this is not a normal workflow","title":"Coordinator Consumer DDO"},{"location":"architecture/specs/fl/#coordinator-provider-ddo","text":"{ \"@context\" : \"https://w3id.org/future-method/v1\" , \"authentication\" : [], \"created\" : \"2019-04-09T19:02:11Z\" , \"id\" : \"did:op:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"proof\" : { \"created\" : \"2019-04-09T19:02:11Z\" , \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"signatureValue\" : \"1cd57300733bcbcda0beb59b3e076de6419c0d7674e7befb77820b53c79e3aa8f1776effc64cf088bad8cb694cc4d71ebd74a13b2f75893df5a53f3f318f6cf828\" , \"type\" : \"DDOIntegritySignature\" }, \"publicKey\" : [ { \"id\" : \"did:op:8d1b4d73e7af4634958f071ab8dfe7ab0df14019755e444090fd392c8ec9c3f4\" , \"owner\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"type\" : \"EthereumECDSAKey\" } ], \"service\" : [ { \"type\" : \"metadata\" , \"index\" : 0 , \"serviceEndpoint\" : \"http://mymetadata-api.org/api/v1/metadata/assets/ddo/{did}\" , \"attributes\" : { \"main\" : {}, \"additionalInformation\" : {} } }, { \"type\" : \"fl-coordinator\" , \"index\" : 2 , \"serviceEndpoint\" : \"http://mygateway.org/api/v1/gateway/services/execute\" , \"templateId\" : \"804932804923850985093485039850349850439583409583404534231321131a\" , \"attributes\" : { \"main\" : { \"creator\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"datePublished\" : \"2019-04-09T19:02:11Z\" , \"price\" : \"10\" , \"timeout\" : 86400 , \"provider\" : { \"type\" : \"Azure\" , \"description\" : \"\" , \"environment\" : { \"cluster\" : { \"type\" : \"Kubernetes\" , \"url\" : \"http://10.0.0.17/xxx\" }, \"supportedContainers\" : [ { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" }, { \"image\" : \"keykoio/xain-fl\" , \"tag\" : \"v1\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } ], \"supportedServers\" : [ { \"serverId\" : \"1\" , \"serverType\" : \"xlsize\" , \"price\" : \"50\" , \"cpu\" : \"16\" , \"gpu\" : \"0\" , \"memory\" : \"128gb\" , \"disk\" : \"160gb\" , \"maxExecutionTime\" : 86400 }, { \"serverId\" : \"2\" , \"serverType\" : \"medium\" , \"price\" : \"10\" , \"cpu\" : \"2\" , \"gpu\" : \"0\" , \"memory\" : \"8gb\" , \"disk\" : \"80gb\" , \"maxExecutionTime\" : 86400 } ] } } }, \"additionalInformation\" : {} }, \"serviceAgreementTemplate\" : { \"contractName\" : \"ServiceExecutionTemplate\" , \"events\" : [ { \"name\" : \"AgreementCreated\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"serviceExecutionTemplate\" , \"functionName\" : \"fulfillLockPaymentCondition\" , \"version\" : \"0.1\" } } ], \"fulfillmentOrder\" : [ \"lockPayment.fulfill\" , \"serviceExecution.fulfill\" , \"escrowPayment.fulfill\" ], \"conditionDependency\" : { \"lockPayment\" : [], \"serviceExecution\" : [], \"releaseReward\" : [ \"lockPayment\" , \"serviceExecution\" ] }, \"conditions\" : [ { \"name\" : \"lockPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"LockPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_rewardAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"lockPaymentConditon\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"execCompute\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"ComputeExecutionCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_grantee\" , \"type\" : \"address\" , \"value\" : \"\" } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } }, { \"name\" : \"TimedOut\" , \"actorType\" : \"consumer\" , \"handler\" : { \"moduleName\" : \"execCompute\" , \"functionName\" : \"fulfillServiceExecutionCondition\" , \"version\" : \"0.1\" } } ] }, { \"name\" : \"escrowPayment\" , \"timelock\" : 0 , \"timeout\" : 0 , \"contractName\" : \"EscrowPaymentCondition\" , \"functionName\" : \"fulfill\" , \"parameters\" : [ { \"name\" : \"_did\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_amounts\" , \"type\" : \"uint256[]\" , \"value\" : [] }, { \"name\" : \"_receivers\" , \"type\" : \"address[]\" , \"value\" : [] }, { \"name\" : \"_sender\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_tokenAddress\" , \"type\" : \"address\" , \"value\" : \"\" }, { \"name\" : \"_lockCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" }, { \"name\" : \"_releaseCondition\" , \"type\" : \"bytes32\" , \"value\" : \"\" } ], \"events\" : [ { \"name\" : \"Fulfilled\" , \"actorType\" : \"publisher\" , \"handler\" : { \"moduleName\" : \"escrowPaymentConditon\" , \"functionName\" : \"verifyRewardTokens\" , \"version\" : \"0.1\" } } ] } ] } } ] }","title":"Coordinator Provider DDO"},{"location":"architecture/specs/fl/#participant-consumer-ddo","text":"{ \"serviceAgreementId\" : \"bb23s87856d59867503f80a690357406857698570b964ac8dcc9d86da4ada010\" , \"workflow\" : { \"@context\" : \"https://w3id.org/did/v1\" , \"authentication\" : [ { \"type\" : \"RsaSignatureAuthentication2018\" , \"publicKey\" : \"did:nv:0ebed8226ada17fde24b6bf2b95d27f8f05fcce09139ff5cec31f6d81a7cd2ea\" } ], \"created\" : \"2019-02-08T08:13:49Z\" , \"updated\" : \"2019-06-30T14:53:09Z\" , \"id\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"proof\" : { \"created\" : \"2019-02-08T08:13:41Z\" , \"creator\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"signatureValue\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"type\" : \"DDOIntegritySignature\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"1\" : \"0x999999952b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3\" } }, \"publicKey\" : [ { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-1\" , \"type\" : \"RsaVerificationKey2018\" , \"owner\" : \"did:nv:6027c1e7cbae06a91fce0557ee53195284825f56a7100be0c53cbf4391aa26cc\" , \"publicKeyPem\" : \"-----BEGIN PUBLIC KEY...END PUBLIC KEY-----\\r\\n\" }, { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-2\" , \"type\" : \"Ed25519VerificationKey2018\" , \"owner\" : \"did:nv:4c27a254e607cdf91a1206480e7eb8c74856102316c1a462277d4f21c02373b6\" , \"publicKeyBase58\" : \"H3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\" }, { \"id\" : \"did:nv:b6e2eb5eff1a093ced9826315d5a4ef6c5b5c8bd3c49890ee284231d7e1d0aaa#keys-3\" , \"type\" : \"RsaPublicKeyExchangeKey2018\" , \"owner\" : \"did:nv:5f6b885202ffb9643874be529302eb00d55e226959f1fbacaeda592c5b5c9484\" , \"publicKeyPem\" : \"-----BEGIN PUBLIC KEY...END PUBLIC KEY-----\\r\\n\" } ], \"verifiableCredential\" : [ { \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://www.w3.org/2018/credentials/examples/v1\" ], \"id\" : \"1872\" , \"type\" : [ \"read\" , \"update\" , \"deactivate\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : { \"id\" : \"0x89328493849328493284932\" }, \"proof\" : { \"type\" : \"RsaSignature2018\" , \"created\" : \"2019-01-01T19:73:24Z\" , \"proofPurpose\" : \"assertionMethod\" , \"signatureValue\" : \"ABCJSDAO23...1tzjn4w==\" } } ], \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"author\" : \"John Doe\" , \"checksum\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"datePublished\" : \"2019-05-08T08:13:49Z\" , \"license\" : \"CC-BY\" , \"name\" : \"My workflow\" , \"price\" : \"1\" , \"type\" : \"workflow\" , \"workflow\" : { \"stages\" : [ { \"index\" : 0 , \"stageType\" : \"Participant\" , \"requirements\" : { \"container\" : { \"image\" : \"keykoio/xain-participant\" , \"tag\" : \"latest\" , \"checksum\" : \"sha256:cb57ecfa6ebbefd8ffc7f75c0f00e57a7fa739578a429b6f72a0df19315deadc\" } }, \"input\" : [ { \"index\" : 0 , \"id\" : \"did:nv:12345\" } ], \"transformation\" : { \"id\" : \"did:nv:abcde\" }, \"output\" : { } } ] } }, \"additionalInformation\" : { \"description\" : \"Workflow to aggregate weather information\" , \"tags\" : [ \"weather\" , \"uk\" , \"2011\" , \"workflow\" , \"aggregation\" ], \"copyrightHolder\" : \"John Doe\" } } } ] } } This is a normal data in situ computation workflow with one stage, a set of inputs, one transformation and no output since the participant shouldn't need to generate any data.","title":"Participant Consumer DDO"},{"location":"architecture/specs/fl/#participant-provider-ddo","text":"","title":"Participant Provider DDO"},{"location":"architecture/specs/id_management/","text":"Identity management with on-chain access control \u00b6 shortname: IDM name: Identity management with on-chain access control type: Draft status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: - Identity management with on-chain access control - Introduction - Motivation - Concepts - Specifications - Actors - Use Case - Preconditions - Requirements - Architecture - Identity Management - Verifiable Credentials associated with Nevermined assets - Json Web Tokens (JWT) - JWT Structure - JWT Payload - Identity Gateways - Interactions between the actors - Gateway JWT implementation - JWT Authorization Grants - Adding and Revoking Permissions - Annex - Serializing DID Documents - Examples of JWT Grant Tokens This SPEC introduces a pattern for integrating independent Domain Controller system to manage the identity authorization with the Nevermined Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") as contracts between parties interacting in a transaction. Introduction \u00b6 Corporate environments utilize complex identity management and access control via Domain Controllers (i.e Active Directory). These solutions allow to authenticate and authorize corporate users of a specific domain or network. Implementations like Active Directory enable the management of individual or group permissions within the organization assigning security policies. At the same time, decentralized ecosystems allow the interaction and collaboration between different users part of the network using Decentralized Ledger Technologies (DLT) as source of truth of the shared network. In the data ecosystems where different organizations are members of the same network or consortia, it\u2019s a challenge to handle how the identity is managed within the organization (centralized) and how these different organizations can interact with each other re-using their existing Domain Controllers without moving all the existing identity management rules to a new silo or environment (centralized or decentralized). The intention of this document is to detail how independent organizations can integrate their existing corporate Domain Controllers in a Decentralized data ecosystem allowing the decentralized access control without replicating the existing organization permissions to the decentralized network. Motivation \u00b6 The main motivations of the solution described are: Understand how in a decentralized environment, different organizations with totally independent (and probably incompatible) Domain controllers can manage the permissions of the their decentralized assets (subjects) without replicating the permission policies in a new solution Understand what are the different actors involved and how these actors interact Identify the main interfaces required for the interactions Identify the credentials generation and management Understand how the credentials issued can map to a DLT user identity via keys Facilitate the interoperability between actors in the system Concepts \u00b6 Specifications \u00b6 Nevermined Identity Management solution is designed based on the Verifiable Credentials & Decentralized Identifiers specifications as building block in the design of the solution. So some of the terms and concepts used are based on these specifications. Actors \u00b6 The actors identified in the solution described are: Holder - An actor possessing one or more credentials. This user presents these credentials for identification purposes Issuer - The actors asserting the claims about different organization subjects and creating the credentials for that claims and transmitting to the Holder Verifier - The actors receiving credential presentations from Holders for further verification Verifiable data registry - The actors associated with the organizations managing the internal user and groups permissions W3C Actors in Verifiable Credentials Use Case \u00b6 Preconditions \u00b6 The specification and architecture designed is based in some environment preconditions. These preconditions need to be taken into account in order to adapt the solution designed to the environment where this solution is going to be used. The main environment characteristics are: Multiple and independent organizations participate in a decentralized data ecosystem Each organization have independent Identity Services (like Active Directory) to manage the internal authentication and authorization of their users and groups Users belonging to the organizations need to make use of the decentralized ecosystem authenticating via their Identity Services Different organizations could use totally independent and different infrastructure and technical solutions The rules governing the authorization of users within the organization are kept in the Domain Controllers. It\u2019s not recommended to replicate that information in a different centralized or decentralized repository Users belonging to an organization don\u2019t want to add a new mechanism to authenticate. They are already using their single sign-on (SSO) solution within the organization DLT networks use credentials for identifying, authenticate and authorize users in a decentralized environment Users need to make a friction-less interaction with the decentralized applications connected to the ecosystem without knowing the underlying credentials management (DLT wallets) Requirements \u00b6 The main requirements used to designed the solution are: Multiple and independent organizations need to manage the access control to the assets registered in a decentralized ecosystem A Subject manager or Admin wants to manage the access control to the subjects he/she controls using the Domain Controller solution used in the organization The Admin needs to manage the subjects access control via users and groups The users of a organization need to operate in the DLT network to interact with the subjects registered in that network The users of the decentralized ecosystem are identified in that network via credentials based in the Wallet technologies used in the DLT network The users need have a mapping between their organization identity and their decentralized ecosystem identity The Users or Holders keep their identity that only belongs to them. They need to present the credentials issued by the organizations they belong to verify their identity. The users can belong to one or many groups in one or many different organizations A user of the organization A wants to give permissions of a user or group of the organization B for making use of a subject or asset registered in a decentralized environment Users managing permissions on these decentralized assets should be able to add and revoke permissions The schemas and data existing in the individual deployments of the Identity Services shouldn't be replicated in the decentralized ecosystem. The source of truth are the Identity Services instances Information kept about the users and groups in the DLT network must be minimal and never store PI. Ideally only ids and hashes The decentralized ecosystem register assets and the conditions for who can interact and what is possible to do with these assets is kept on-chain Public information about users like users public keys should be available. User information should be resolvable via decentralized identifiers Architecture \u00b6 Identity Management \u00b6 The proposed solution involves the deployment of a component called Identity Gateway . Each Domain Controller in the Ecosystem needs to provide one Identity Gateway in charge of bridge the internals domain authorization policies with the rest of the world. So it\u2019s assumed for each independent Domain Controller available in the network, there should be at least one Identity Gateway resolving for the Domain Controller policies. W3C Actors in Verifiable Credentials In this scenario each Domain Controller keeps control of the identities of his domain. The only actions that are done by the Domain Controllers are: They identify users as in part of the domain They identify users as part of a group within the domain They are network isolated and respond to authorization queries to the associated Identity Gateway Verifiable Credentials associated with Nevermined assets \u00b6 In Nevermined an Asset can represent any kind of subject registered in the network. Typically assets represent datasets, algorithms, services, etc. Any registered asset within Nevermined always has associated a Decentralized Identifier (DID) that can be resolved into a DID Object (DDO). Typically a DDO includes metadata information describing the asset and the services that are offered by that asset to the rest of the network (access, computation, etc.). In addition to this, a DDO can include a portion describing the users and/or groups that can interact with the asset. This is modeled in the DDO in the shape of W3C Verifiable Credentials. Here you can see an example of a fragment of a DDO including the credentials of an asset for different subjects: { \"@context\" : \"https://www.w3.org/2018/credentials/v1\" , \"type\" : [ \"access\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : [{ \"id\" : \"0x1234\" , \"type\" : \"User\" }, { \"id\" : \"0x5678\" , \"type\" : \"User\" }, { \"id\" : \"Group XXX\" , \"type\" : \"Group\" }] } In the above verifiable credential fragment we are associating access permissions to any holder of the credentials able to authorize the users \u201c0x1234\u201d or \u201c0x5678\u201d or as part of the group \u201cGroup XXX\u201d of the domain. Json Web Tokens (JWT) \u00b6 JSON Web Tokens (JWT) is a compact URL-safe means of representing claims to be transferred between two parties. The claims in a JSON Web Tokens are encoded as a JavaScript Object Notation (JSON) object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or MACed and/or encrypted. JSON Web Token (JWT) is an open standard RFC 7519 that defines a compact and self-contained way for securely transmitting information between parties as a JSON Object. This information can be verified and trusted because it is digitally signed. JSON Web Tokens can be signed using a secret (with HMAC algorithm) or a public/private key pair using RSA. In the architecture design we use JWT for encapsulating the messages between the different parties. JSON Web Tokens consist of three parts separated by dots (.), which are: Header Payload Signature Therefore, a JWT typically looks like the following: Xxxxx.yyyyy.zzzzz In this architecture document, all the JWT messages sent from a client to a server are using the HTTP Authorization header with the Bearer scheme. Example: HTTP GET /api/v1/gateway/resource Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ JWT Structure \u00b6 The header contains the metadata for the token and at a minimal contains the type of the signature and/or encryption algorithm: \"typ\" - the type of the token, which is JWT \"alg\" - the hashing algorithm such as ES256. We are using ECDSA with SHA256. \"cty\" - Header Parameter defined by JSON Web Signature and JSON Web Encryption is used by this specification to convey structural information about the JWT. In our case the header is gonna look like this: { \"typ\" : \"JWT\" , \"alg\" : \"ES256\" , \"cty\" : \"arbitrary\" } JWT Payload \u00b6 The payload contains the claims. Claims are statements about an entity (typically, the user) and additional metadata. There are three types of claims: Reserved claims: These are a set of predefined claims, which are not mandatory but recommended, thought to provide a set of useful, interoperable claims. Public claims: These can be defined at will by those using JWTs. But to avoid collisions they should be defined in the IANA JSON Web Token Registry or be defined as a URI that contains a collision resistant namespace. Private claims: These are the custom claims created to share information between parties that agree on using them. In our case the payload will have the following attributes: iss - Issuer. address of the holder sub - Subject, id of the service agreement aud - Audience, address of the gateway Here an example of the payload: { \"iss\" : \"0x123456\" , \"sub\" : \"did:nv:abcde\" , \"aud\" : \"0xffffff\" } Identity Gateways \u00b6 In this architecture the Identity Gateway is in charge of: Expose to the network the interface allowing to ask for the details of a Domain Controller. Resolve a Domain Controller DID into a DDO describing it. Each Domain Controller should have associated a unique Decentralized Identifier (DID) that resolves into URL where is kept the Decentralized Document (DDO) describing the Domain Controller. Verify the identity of a Holder. When a Holder presents a digital identity it authenticates the Holder. Typically this is happening verifying the signature given by the Holder for a specific Subject Check the authorization of a Holder over a Subject. When a Holder claims authorization for a Subject it integrates with the Domain Controller for verifying the authorization of that Holder. Generates, Signs and Issues credentials Can present some emitted credentials on-chain Interactions between the actors \u00b6 The following flow describes the interaction between actors allowing a Holder to present credentials related to a subject authorized by a Domain Controller. Identity Management Flow The different steps are: The Holder presents a credentials request related to a subject HTTP GET /api/v1/gateway/services/oauth2/token Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ Where the JWT payload is: { \"iss\" : \"0x123456\" , // address o f t he holder \"sub\" : \"0xabcde\" , // id o f t he service agreeme nt \"aud\" : \"0xffffff\" // address o f t he ga te way } The Gateway decodes the JWT message, and validates the identity of the Holder checking the signature and the issuer address provided The Gateway queries the domain controller checking the access permissions of the Holder for a specific Subject. The identity Gateway could integrate different kinds of backends like Active Directory, LDAP, databases, etc. The verifiable credentials can include user or group types of credentials subjects. The identity gateway must validate if the user just authenticated fulfill any of the following: If is a user part of the Domain Controller If the user is part of any of the credential groups within the Domain If the Domain Controller validates the Holder has access permissions, the Identity Gateway will generate and sign a credential The credential is issued to the Holder in the JWT format included in the access_token response parameter: { \"access_token\" : \"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiIweDEyMzQ1NiIsInN1YiI6ImRpZDpudjphYmNkZSIsImF1ZCI6IjB4ZmZmZmZmIiwiaWF0IjoxNTE2MjM5MDIyLCJleHAiOjE1MTYyNTAwMjJ9.fiOSfeQwSiDi0ECFuDrHmhx8BHTHMl6MiyiJgJ6BIntjHvcFDFjPwtSYJrhYpeTcBPQ1FO5-fT-n4fQXBF92Vw\" } Which decoded has the following payload: json { \"iss\": \"0x123456\", \"sub\": \"0xabcde\", \"aud\": \"0xffffff\", \"iat\": 1516239022, \"exp\": 1516250022 } In this case it includes the \u201ciat\u201d (when the token was emitted) and \u201cexp\u201d (when the token is expiring). The Holder can present the credentials to a Smart Contract or Optionally the Identity Gateway could present the credentials to a Smart Contract on behalf of the Holder. Gateway JWT implementation \u00b6 The gateway implements the RFC6749: The OAuth 2.0 Authorization Framework framework using JWTs as Authorization Grants and JWTs as Access Tokens JWT Authorization Grants \u00b6 The claims that should be contained in a JWT Authorization Grant depend on the action that we want to perform on the gateway. The claims validation follow RFC7523 . Overall the claim options look like this: Registered name claims { \"iss\" : { \"essential\" : true }, \"sub\" : { \"essential\" : false }, \"aud\" : { \"essential\" : true , \"values\" : [ \"/api/v1/gateway/services/access\" , \"/api/v1/gateway/services/compute\" , \"/api/v1/gateway/services/download\" , \"/api/v1/gateway/services/execute\" ], }, \"exp\" : { \"essential\" : true }, } iss : Is the ethereum address of the consumer sub : (optional): Is the Service Agreement Id if applicable aud : Is the path of the endpoint being called exp : Is the expiration time Private name claims These claims are specific to Nevermined { \"did\" : { \"essential\" : false }, \"execution_id\" : { \"essential\" : false } } did (optional): Is the DID of the related asset execution_id (optional): Is the execution id of the related compute job To request a JWT access token a client needs to make a request to the token endpoint ( /api/v1/services/oauth2/token ) by sendinf the following parameters using application/x-www-form-urlencoded format as per RFC6749 with: grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer : The grant type as per RFC7523 assertion=<jwt grant token> : The assertion with a single JWT grant token as per RFC7523 For examples JWT Grant tokens check Examples of JWT Grant Tokens in the Annex . Adding and Revoking Permissions \u00b6 The administrator of the Domain typically uses the Domain Controller as a unique source of truth for the access control of users and groups. Because the identity gateway asks the Domain Controller for the belonging of users and groups as part of the domain, any modification of the permissions in the Domain Controller policies will be extended automatically to the new authorization queries responded by the Identity Gateway. For the cases where an access token was already given to a user, this will be valid during the lifetime of the credentials assigned to the user. During that period of time, the credentials will be valid for access to the resources granted. Because of that it is recommended to configure the identity gateway to not emit credentials with very long expiration time. To complement this, the Identity Gateway could integrate a cache system to keep track of the credentials granted during their life-cycle, and expose a method for revoking credentials immediately. In that scenario if a Domain Account needs to revoke some credentials related to a Holder and a Subject, it should send a request to the Identity Gateway using the following format: HTTP DELETE /api/v1/gateway/services/domain/credentials Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ Where the JWT payload is: { \"iss\" : \"0x123456\" , // address o f t he domai n co ntr oller \"sub\" : \"0xabcd\" , // id o f t he service agreeme nt \"aud\" : \"0xffffff\" // address o f t he ga te way } For this request the Identity Gateway needs to authenticate the Domain Account via the signature. If all the validations are correct the Identity Gateway needs to send a revoke request to the Smart Contract keeping the authorization permissions on-chain. This scenario is valid when the Identity Gateway integrates a DLT network to backup the authorization permissions. If the Identity Gateway performs the validation for each request, this revocation won\u2019t be necessary because the next authorization request via the Gateway will query the Domain Controller that should have already revoked the authorization permissions. Annex \u00b6 Serializing DID Documents \u00b6 Having a standard JSON document or subtract, the common operations used to serialize fragments of DID Documents is as follows: The object is sorted alphabetically by key, of the existing nested levels In the JSON generated, all the characters between entries are removed (\\n, \\t, \\r, whitespaces, etc.) As a result must be generated a string of only one line After serializing a DID Document or a fragment into a string line, typically it\u2019s necessary to hash that line to include as part of a different document or adding it on-chain. The common method used to do that is using the SHA3-256 (Keccak-256) algorithm (you might have to convert the string to bytes first.) , making sure that final hash generated is prefixed by 0x . Examples of JWT Grant Tokens \u00b6 /api/v1/gateway/services/access // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/access\" , \"sub\" : \"0xf527a6bbc35547f782dda34d64bb9070e743531107994899b1f97d4451aacbe1\" , \"iat\" : 1607967375 , \"exp\" : 1607970975 , \"did\" : \"did:nv:5c19aaf5f7c12ef0a9d898d5a89ca5428f3d0315b0f0a36f5b5d097166e53788\" } /api/v1/gateway/services/compute // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/compute\" , \"sub\" : \"0x3228c55d6e444cdc87bd5425896d5cdfa1e42e0734d04866a6c4386ef4f20144\" , \"iat\" : 1607968935 , \"exp\" : 1607972535 , \"execution_id\" : \"nevermined-compute-82v5j\" } /api/v1/gateway/services/download // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"aud\" : \"/api/v1/gateway/services/download\" , \"iat\" : 1607969122 , \"exp\" : 1607972722 , \"did\" : \"did:nv:2379d3e2d03f25b8e5fb2fae6e6adeb45cd7674d20905fc172d84915ff68cc73\" } /api/v1/gateway/services/execute // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/execute\" , \"sub\" : \"0x715954fd8a9b48968983ae9b9813e169b4be0d861ccb4bbd8489298cda59c6a9\" , \"iat\" : 1607969247 , \"exp\" : 1607972847 , \"did\" : \"did:nv:e689ed382b15e190a5937f5c070843cce249a692ff09931d570e288bd91e5b81\" }","title":"Identity Management"},{"location":"architecture/specs/id_management/#identity-management-with-on-chain-access-control","text":"shortname: IDM name: Identity management with on-chain access control type: Draft status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: - Identity management with on-chain access control - Introduction - Motivation - Concepts - Specifications - Actors - Use Case - Preconditions - Requirements - Architecture - Identity Management - Verifiable Credentials associated with Nevermined assets - Json Web Tokens (JWT) - JWT Structure - JWT Payload - Identity Gateways - Interactions between the actors - Gateway JWT implementation - JWT Authorization Grants - Adding and Revoking Permissions - Annex - Serializing DID Documents - Examples of JWT Grant Tokens This SPEC introduces a pattern for integrating independent Domain Controller system to manage the identity authorization with the Nevermined Service Execution Agreements (SEAs) (also called \"Service Agreements\" or \"Agreements\") as contracts between parties interacting in a transaction.","title":"Identity management with on-chain access control"},{"location":"architecture/specs/id_management/#introduction","text":"Corporate environments utilize complex identity management and access control via Domain Controllers (i.e Active Directory). These solutions allow to authenticate and authorize corporate users of a specific domain or network. Implementations like Active Directory enable the management of individual or group permissions within the organization assigning security policies. At the same time, decentralized ecosystems allow the interaction and collaboration between different users part of the network using Decentralized Ledger Technologies (DLT) as source of truth of the shared network. In the data ecosystems where different organizations are members of the same network or consortia, it\u2019s a challenge to handle how the identity is managed within the organization (centralized) and how these different organizations can interact with each other re-using their existing Domain Controllers without moving all the existing identity management rules to a new silo or environment (centralized or decentralized). The intention of this document is to detail how independent organizations can integrate their existing corporate Domain Controllers in a Decentralized data ecosystem allowing the decentralized access control without replicating the existing organization permissions to the decentralized network.","title":"Introduction"},{"location":"architecture/specs/id_management/#motivation","text":"The main motivations of the solution described are: Understand how in a decentralized environment, different organizations with totally independent (and probably incompatible) Domain controllers can manage the permissions of the their decentralized assets (subjects) without replicating the permission policies in a new solution Understand what are the different actors involved and how these actors interact Identify the main interfaces required for the interactions Identify the credentials generation and management Understand how the credentials issued can map to a DLT user identity via keys Facilitate the interoperability between actors in the system","title":"Motivation"},{"location":"architecture/specs/id_management/#concepts","text":"","title":"Concepts"},{"location":"architecture/specs/id_management/#specifications","text":"Nevermined Identity Management solution is designed based on the Verifiable Credentials & Decentralized Identifiers specifications as building block in the design of the solution. So some of the terms and concepts used are based on these specifications.","title":"Specifications"},{"location":"architecture/specs/id_management/#actors","text":"The actors identified in the solution described are: Holder - An actor possessing one or more credentials. This user presents these credentials for identification purposes Issuer - The actors asserting the claims about different organization subjects and creating the credentials for that claims and transmitting to the Holder Verifier - The actors receiving credential presentations from Holders for further verification Verifiable data registry - The actors associated with the organizations managing the internal user and groups permissions W3C Actors in Verifiable Credentials","title":"Actors"},{"location":"architecture/specs/id_management/#use-case","text":"","title":"Use Case"},{"location":"architecture/specs/id_management/#preconditions","text":"The specification and architecture designed is based in some environment preconditions. These preconditions need to be taken into account in order to adapt the solution designed to the environment where this solution is going to be used. The main environment characteristics are: Multiple and independent organizations participate in a decentralized data ecosystem Each organization have independent Identity Services (like Active Directory) to manage the internal authentication and authorization of their users and groups Users belonging to the organizations need to make use of the decentralized ecosystem authenticating via their Identity Services Different organizations could use totally independent and different infrastructure and technical solutions The rules governing the authorization of users within the organization are kept in the Domain Controllers. It\u2019s not recommended to replicate that information in a different centralized or decentralized repository Users belonging to an organization don\u2019t want to add a new mechanism to authenticate. They are already using their single sign-on (SSO) solution within the organization DLT networks use credentials for identifying, authenticate and authorize users in a decentralized environment Users need to make a friction-less interaction with the decentralized applications connected to the ecosystem without knowing the underlying credentials management (DLT wallets)","title":"Preconditions"},{"location":"architecture/specs/id_management/#requirements","text":"The main requirements used to designed the solution are: Multiple and independent organizations need to manage the access control to the assets registered in a decentralized ecosystem A Subject manager or Admin wants to manage the access control to the subjects he/she controls using the Domain Controller solution used in the organization The Admin needs to manage the subjects access control via users and groups The users of a organization need to operate in the DLT network to interact with the subjects registered in that network The users of the decentralized ecosystem are identified in that network via credentials based in the Wallet technologies used in the DLT network The users need have a mapping between their organization identity and their decentralized ecosystem identity The Users or Holders keep their identity that only belongs to them. They need to present the credentials issued by the organizations they belong to verify their identity. The users can belong to one or many groups in one or many different organizations A user of the organization A wants to give permissions of a user or group of the organization B for making use of a subject or asset registered in a decentralized environment Users managing permissions on these decentralized assets should be able to add and revoke permissions The schemas and data existing in the individual deployments of the Identity Services shouldn't be replicated in the decentralized ecosystem. The source of truth are the Identity Services instances Information kept about the users and groups in the DLT network must be minimal and never store PI. Ideally only ids and hashes The decentralized ecosystem register assets and the conditions for who can interact and what is possible to do with these assets is kept on-chain Public information about users like users public keys should be available. User information should be resolvable via decentralized identifiers","title":"Requirements"},{"location":"architecture/specs/id_management/#architecture","text":"","title":"Architecture"},{"location":"architecture/specs/id_management/#identity-management","text":"The proposed solution involves the deployment of a component called Identity Gateway . Each Domain Controller in the Ecosystem needs to provide one Identity Gateway in charge of bridge the internals domain authorization policies with the rest of the world. So it\u2019s assumed for each independent Domain Controller available in the network, there should be at least one Identity Gateway resolving for the Domain Controller policies. W3C Actors in Verifiable Credentials In this scenario each Domain Controller keeps control of the identities of his domain. The only actions that are done by the Domain Controllers are: They identify users as in part of the domain They identify users as part of a group within the domain They are network isolated and respond to authorization queries to the associated Identity Gateway","title":"Identity Management"},{"location":"architecture/specs/id_management/#verifiable-credentials-associated-with-nevermined-assets","text":"In Nevermined an Asset can represent any kind of subject registered in the network. Typically assets represent datasets, algorithms, services, etc. Any registered asset within Nevermined always has associated a Decentralized Identifier (DID) that can be resolved into a DID Object (DDO). Typically a DDO includes metadata information describing the asset and the services that are offered by that asset to the rest of the network (access, computation, etc.). In addition to this, a DDO can include a portion describing the users and/or groups that can interact with the asset. This is modeled in the DDO in the shape of W3C Verifiable Credentials. Here you can see an example of a fragment of a DDO including the credentials of an asset for different subjects: { \"@context\" : \"https://www.w3.org/2018/credentials/v1\" , \"type\" : [ \"access\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : [{ \"id\" : \"0x1234\" , \"type\" : \"User\" }, { \"id\" : \"0x5678\" , \"type\" : \"User\" }, { \"id\" : \"Group XXX\" , \"type\" : \"Group\" }] } In the above verifiable credential fragment we are associating access permissions to any holder of the credentials able to authorize the users \u201c0x1234\u201d or \u201c0x5678\u201d or as part of the group \u201cGroup XXX\u201d of the domain.","title":"Verifiable Credentials associated with Nevermined assets"},{"location":"architecture/specs/id_management/#json-web-tokens-jwt","text":"JSON Web Tokens (JWT) is a compact URL-safe means of representing claims to be transferred between two parties. The claims in a JSON Web Tokens are encoded as a JavaScript Object Notation (JSON) object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or MACed and/or encrypted. JSON Web Token (JWT) is an open standard RFC 7519 that defines a compact and self-contained way for securely transmitting information between parties as a JSON Object. This information can be verified and trusted because it is digitally signed. JSON Web Tokens can be signed using a secret (with HMAC algorithm) or a public/private key pair using RSA. In the architecture design we use JWT for encapsulating the messages between the different parties. JSON Web Tokens consist of three parts separated by dots (.), which are: Header Payload Signature Therefore, a JWT typically looks like the following: Xxxxx.yyyyy.zzzzz In this architecture document, all the JWT messages sent from a client to a server are using the HTTP Authorization header with the Bearer scheme. Example: HTTP GET /api/v1/gateway/resource Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ","title":"Json Web Tokens (JWT)"},{"location":"architecture/specs/id_management/#jwt-structure","text":"The header contains the metadata for the token and at a minimal contains the type of the signature and/or encryption algorithm: \"typ\" - the type of the token, which is JWT \"alg\" - the hashing algorithm such as ES256. We are using ECDSA with SHA256. \"cty\" - Header Parameter defined by JSON Web Signature and JSON Web Encryption is used by this specification to convey structural information about the JWT. In our case the header is gonna look like this: { \"typ\" : \"JWT\" , \"alg\" : \"ES256\" , \"cty\" : \"arbitrary\" }","title":"JWT Structure"},{"location":"architecture/specs/id_management/#jwt-payload","text":"The payload contains the claims. Claims are statements about an entity (typically, the user) and additional metadata. There are three types of claims: Reserved claims: These are a set of predefined claims, which are not mandatory but recommended, thought to provide a set of useful, interoperable claims. Public claims: These can be defined at will by those using JWTs. But to avoid collisions they should be defined in the IANA JSON Web Token Registry or be defined as a URI that contains a collision resistant namespace. Private claims: These are the custom claims created to share information between parties that agree on using them. In our case the payload will have the following attributes: iss - Issuer. address of the holder sub - Subject, id of the service agreement aud - Audience, address of the gateway Here an example of the payload: { \"iss\" : \"0x123456\" , \"sub\" : \"did:nv:abcde\" , \"aud\" : \"0xffffff\" }","title":"JWT Payload"},{"location":"architecture/specs/id_management/#identity-gateways","text":"In this architecture the Identity Gateway is in charge of: Expose to the network the interface allowing to ask for the details of a Domain Controller. Resolve a Domain Controller DID into a DDO describing it. Each Domain Controller should have associated a unique Decentralized Identifier (DID) that resolves into URL where is kept the Decentralized Document (DDO) describing the Domain Controller. Verify the identity of a Holder. When a Holder presents a digital identity it authenticates the Holder. Typically this is happening verifying the signature given by the Holder for a specific Subject Check the authorization of a Holder over a Subject. When a Holder claims authorization for a Subject it integrates with the Domain Controller for verifying the authorization of that Holder. Generates, Signs and Issues credentials Can present some emitted credentials on-chain","title":"Identity Gateways"},{"location":"architecture/specs/id_management/#interactions-between-the-actors","text":"The following flow describes the interaction between actors allowing a Holder to present credentials related to a subject authorized by a Domain Controller. Identity Management Flow The different steps are: The Holder presents a credentials request related to a subject HTTP GET /api/v1/gateway/services/oauth2/token Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ Where the JWT payload is: { \"iss\" : \"0x123456\" , // address o f t he holder \"sub\" : \"0xabcde\" , // id o f t he service agreeme nt \"aud\" : \"0xffffff\" // address o f t he ga te way } The Gateway decodes the JWT message, and validates the identity of the Holder checking the signature and the issuer address provided The Gateway queries the domain controller checking the access permissions of the Holder for a specific Subject. The identity Gateway could integrate different kinds of backends like Active Directory, LDAP, databases, etc. The verifiable credentials can include user or group types of credentials subjects. The identity gateway must validate if the user just authenticated fulfill any of the following: If is a user part of the Domain Controller If the user is part of any of the credential groups within the Domain If the Domain Controller validates the Holder has access permissions, the Identity Gateway will generate and sign a credential The credential is issued to the Holder in the JWT format included in the access_token response parameter: { \"access_token\" : \"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiIweDEyMzQ1NiIsInN1YiI6ImRpZDpudjphYmNkZSIsImF1ZCI6IjB4ZmZmZmZmIiwiaWF0IjoxNTE2MjM5MDIyLCJleHAiOjE1MTYyNTAwMjJ9.fiOSfeQwSiDi0ECFuDrHmhx8BHTHMl6MiyiJgJ6BIntjHvcFDFjPwtSYJrhYpeTcBPQ1FO5-fT-n4fQXBF92Vw\" } Which decoded has the following payload: json { \"iss\": \"0x123456\", \"sub\": \"0xabcde\", \"aud\": \"0xffffff\", \"iat\": 1516239022, \"exp\": 1516250022 } In this case it includes the \u201ciat\u201d (when the token was emitted) and \u201cexp\u201d (when the token is expiring). The Holder can present the credentials to a Smart Contract or Optionally the Identity Gateway could present the credentials to a Smart Contract on behalf of the Holder.","title":"Interactions between the actors"},{"location":"architecture/specs/id_management/#gateway-jwt-implementation","text":"The gateway implements the RFC6749: The OAuth 2.0 Authorization Framework framework using JWTs as Authorization Grants and JWTs as Access Tokens","title":"Gateway JWT implementation"},{"location":"architecture/specs/id_management/#jwt-authorization-grants","text":"The claims that should be contained in a JWT Authorization Grant depend on the action that we want to perform on the gateway. The claims validation follow RFC7523 . Overall the claim options look like this: Registered name claims { \"iss\" : { \"essential\" : true }, \"sub\" : { \"essential\" : false }, \"aud\" : { \"essential\" : true , \"values\" : [ \"/api/v1/gateway/services/access\" , \"/api/v1/gateway/services/compute\" , \"/api/v1/gateway/services/download\" , \"/api/v1/gateway/services/execute\" ], }, \"exp\" : { \"essential\" : true }, } iss : Is the ethereum address of the consumer sub : (optional): Is the Service Agreement Id if applicable aud : Is the path of the endpoint being called exp : Is the expiration time Private name claims These claims are specific to Nevermined { \"did\" : { \"essential\" : false }, \"execution_id\" : { \"essential\" : false } } did (optional): Is the DID of the related asset execution_id (optional): Is the execution id of the related compute job To request a JWT access token a client needs to make a request to the token endpoint ( /api/v1/services/oauth2/token ) by sendinf the following parameters using application/x-www-form-urlencoded format as per RFC6749 with: grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer : The grant type as per RFC7523 assertion=<jwt grant token> : The assertion with a single JWT grant token as per RFC7523 For examples JWT Grant tokens check Examples of JWT Grant Tokens in the Annex .","title":"JWT Authorization Grants"},{"location":"architecture/specs/id_management/#adding-and-revoking-permissions","text":"The administrator of the Domain typically uses the Domain Controller as a unique source of truth for the access control of users and groups. Because the identity gateway asks the Domain Controller for the belonging of users and groups as part of the domain, any modification of the permissions in the Domain Controller policies will be extended automatically to the new authorization queries responded by the Identity Gateway. For the cases where an access token was already given to a user, this will be valid during the lifetime of the credentials assigned to the user. During that period of time, the credentials will be valid for access to the resources granted. Because of that it is recommended to configure the identity gateway to not emit credentials with very long expiration time. To complement this, the Identity Gateway could integrate a cache system to keep track of the credentials granted during their life-cycle, and expose a method for revoking credentials immediately. In that scenario if a Domain Account needs to revoke some credentials related to a Holder and a Subject, it should send a request to the Identity Gateway using the following format: HTTP DELETE /api/v1/gateway/services/domain/credentials Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV...r7E20RMHrHDcEfxjoYZgeFONFh7HgQ Where the JWT payload is: { \"iss\" : \"0x123456\" , // address o f t he domai n co ntr oller \"sub\" : \"0xabcd\" , // id o f t he service agreeme nt \"aud\" : \"0xffffff\" // address o f t he ga te way } For this request the Identity Gateway needs to authenticate the Domain Account via the signature. If all the validations are correct the Identity Gateway needs to send a revoke request to the Smart Contract keeping the authorization permissions on-chain. This scenario is valid when the Identity Gateway integrates a DLT network to backup the authorization permissions. If the Identity Gateway performs the validation for each request, this revocation won\u2019t be necessary because the next authorization request via the Gateway will query the Domain Controller that should have already revoked the authorization permissions.","title":"Adding and Revoking Permissions"},{"location":"architecture/specs/id_management/#annex","text":"","title":"Annex"},{"location":"architecture/specs/id_management/#serializing-did-documents","text":"Having a standard JSON document or subtract, the common operations used to serialize fragments of DID Documents is as follows: The object is sorted alphabetically by key, of the existing nested levels In the JSON generated, all the characters between entries are removed (\\n, \\t, \\r, whitespaces, etc.) As a result must be generated a string of only one line After serializing a DID Document or a fragment into a string line, typically it\u2019s necessary to hash that line to include as part of a different document or adding it on-chain. The common method used to do that is using the SHA3-256 (Keccak-256) algorithm (you might have to convert the string to bytes first.) , making sure that final hash generated is prefixed by 0x .","title":"Serializing DID Documents"},{"location":"architecture/specs/id_management/#examples-of-jwt-grant-tokens","text":"/api/v1/gateway/services/access // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/access\" , \"sub\" : \"0xf527a6bbc35547f782dda34d64bb9070e743531107994899b1f97d4451aacbe1\" , \"iat\" : 1607967375 , \"exp\" : 1607970975 , \"did\" : \"did:nv:5c19aaf5f7c12ef0a9d898d5a89ca5428f3d0315b0f0a36f5b5d097166e53788\" } /api/v1/gateway/services/compute // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/compute\" , \"sub\" : \"0x3228c55d6e444cdc87bd5425896d5cdfa1e42e0734d04866a6c4386ef4f20144\" , \"iat\" : 1607968935 , \"exp\" : 1607972535 , \"execution_id\" : \"nevermined-compute-82v5j\" } /api/v1/gateway/services/download // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\" , \"aud\" : \"/api/v1/gateway/services/download\" , \"iat\" : 1607969122 , \"exp\" : 1607972722 , \"did\" : \"did:nv:2379d3e2d03f25b8e5fb2fae6e6adeb45cd7674d20905fc172d84915ff68cc73\" } /api/v1/gateway/services/execute // header { \"alg\" : \"ES256K\" , \"typ\" : \"JWT\" } // asser t io n { \"iss\" : \"0x068Ed00cF0441e4829D9784fCBe7b9e26D4BD8d0\" , \"aud\" : \"/api/v1/gateway/services/execute\" , \"sub\" : \"0x715954fd8a9b48968983ae9b9813e169b4be0d861ccb4bbd8489298cda59c6a9\" , \"iat\" : 1607969247 , \"exp\" : 1607972847 , \"did\" : \"did:nv:e689ed382b15e190a5937f5c070843cce249a692ff09931d570e288bd91e5b81\" }","title":"Examples of JWT Grant Tokens"},{"location":"architecture/specs/metadata/","text":"META SPEC: Metadata Ontology \u00b6 shortname: DID name: Metadata Ontology type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: META SPEC: Metadata Ontology Motivation Life Cycle of Metadata Local Metadata Remote Metadata Metadata Attributes Main Attributes File Attributes Additional Attributes Other Suggested Additional Attributes Curation Attributes Example of Local Metadata Example of Remote Metadata Specific attributes per asset type Algorithm attributes References Motivation \u00b6 Every asset (dataset, algorithm) in Nevermined has an associated Decentralized Identifier (DID) and DID document / DID Descriptor Object (DDO). Because assets without proper descriptive metadata have poor visibility and discoverability. See DID SPEC for information about the overall structure of Nevermined DDOs and DIDs.This OEP is about one particular part of Nevermined DDOs: the asset metadata, a JSON object with information about the asset. This SPEC defines the assets metadata ontology, i.e. the schema for the asset metadata. It's based on the public schema.org DataSet schema . This SPEC doesn't detail the exact method of registering assets on-chain or storing DDOs. The main motivations of this SPEC are to: Specify the common attributes that MUST be included in any asset metadata stored in Nevermined networks Normalize the attributes to use in any curation process, to provide a common structure to sort and filter the DDOs Identify the recommended additional attributes that SHOULD be included in a DDO to facilitate asset search Provide an example of an asset metadata object and additional links for reference Life Cycle of Metadata \u00b6 Local Metadata \u00b6 Metadata is first created by the publisher of the asset. The publisher has knowledge of the file URLs, and they are stored in plaintext in the files object. This initial metadata is the local metadata . Remote Metadata \u00b6 A publisher publishes (registers) an asset using Nevermined SDKs, which might be running on their local machine or remotely. When they do, the local metadata is passed to the SDK, which makes some changes and additions in the metadata, puts it into a DDO, and sends that DDO to a metadata API. The Metadata API may also make some changes and additions to the metadata, such as the datePublished or parts of the curation object. The metadata that finally gets stored by the Metadata API is the remote metadata . A marketplace can and might also act as a publisher. SPEC ACCESS describes the publishing flow in more detail. Metadata Attributes \u00b6 An asset is the representation of different type of resources in Nevermined. Typically can asset could be one of the following asset types: Dataset . An asset representing a dataset or data resource. It could be for example a CSV file or a multiple JPG files. Algorithm . An asset representing a piece of software. It could be a python script using tensorflow, a spark job, etc. Each kind of asset require a different subset of metadata attributes. The distinction between the type of asset (dataset, algorithm) is given by the attribute DDO.services[\"metadata\"].main.type A metadata object has the following attributes, all of which are objects. Attribute Required Description main Yes Main attributes used to calculate the service checksum curation (remote) Curation attributes additionalInformation No Optional attributes encryptedFiles (remote) Encrypted string of the attributes.main.files object. encryptedServices (remote) Encrypted string of the attributes.main.services object. The main , curation and additionalInformation attributes are independent of the asset type, all assets have those metadata sections. Main Attributes \u00b6 This list of attributes can't be modified after creation , because these are considered as the metadata essence of the asset created. This information is used to calculate the unique checksum of the asset. If any change would be necessary in the following attributes, it would be necessary to create a new asset derived from the existing one. The main object has the following attributes, not all are required. Some are required by only the metadata store ( remote ) and others are mandatory for local metadata only. If required or not by both, they are marked with Yes/No in the Required column. Attribute Type Required Description name Text Yes Descriptive name or title of the asset. type Text Yes Type of the asset. Helps to filter by the type of asset. It could be for example (\"dataset\", \"algorithm\"). dateCreated DateTime Yes The date on which the asset was created by the originator. ISO 8601 format, Coordinated Universal Time, e.g. 2019-01-31T08:38:32Z . datePublished DateTime (remote) The date on which the asset DDO is registered into the metadata store (Metadata API) author Text Yes Name of the entity generating this data (e.g. Tfl, Disney Corp, etc.). license Text Yes Short name referencing the license of the asset (e.g. Public Domain, CC-0, CC-BY, No License Specified, etc. ). If it's not specified, the following value will be added: \"No License Specified\". price String Yes Price of the asset. It must be an integer encoded as a string, e.g. \"123000000000000000000\" . files Array of files object Yes Array of File objects including the encrypted file urls. Further metadata about each file is stored, see File Attributes File Attributes \u00b6 File attributes are a subset of the main section. A file object has the following attributes, with the details necessary to consume and validate the data. Attribute Required Description url (local) Content URL. Omitted from the remote metadata. Supports http(s):// and ipfs:// URLs. name no File name. index yes Index number starting from 0 of the file. contentType yes File format. checksum no Checksum of the file using your preferred format (i.e. MD5). Format specified in checksumType . If it's not provided can't be validated if the file was not modified after registering. checksumType no Format of the provided checksum. Can vary according to server (i.e Amazon vs. Azure) contentLength no Size of the file in bytes. encoding no File encoding (e.g. UTF-8). compression no File compression (e.g. no, gzip, bzip2, etc). encrypted no Boolean. Is the file encrypted? If is not set is assumed the file is not encrypted encryptionMode no Encryption mode used. Just valid if encrypted=true resourceId no Remote identifier of the file in the external provider. It is typically the remote id in the cloud provider. attributes no Key-Value hash map with additional attributes describing the asset file. It could include details like the Amazon S3 bucket, region, etc. Additional Attributes \u00b6 All the additional information will be stored as part of the additionalInformation section. Attribute Type Required categories Array of Text No tags Array of Text No description Text No copyrightHolder Text No workExample Text No links Array of Link No inLanguage Text No Other Suggested Additional Attributes \u00b6 These are examples of attributes that can enhance the discoverability of a resource: Attribute Description sla Service Level Agreement. industry updateFrequency An indication of update latency - i.e. How often are updates expected (seldom, annually, quarterly, etc.), or is the resource static that is never expected to get updated. termsOfService privacy keyword A list of keywords/tags describing a dataset. structuredMarkup A link to machine-readable structured markup (such as ttl/json-ld/rdf) describing the dataset. The publisher of a DDO MAY add additional attributes or change the above object definition. Curation Attributes \u00b6 A curation object has the following attributes. Attribute Type Required Description rating Number (decimal) Yes Decimal value between 0 and 1. 0 is the default value. numVotes Integer Yes Number of votes. 0 is the default value. schema Text No Schema applied to calculate the rating. isListed Boolean No Flag unsuitable content. False by default. If it's true, the content must not be returned. Example of Local Metadata \u00b6 { \"main\" : { \"name\" : \"Madrid Weather forecast\" , \"dateCreated\" : \"2019-05-16T12:36:14.535Z\" , \"author\" : \"Norwegian Meteorological Institute\" , \"type\" : \"dataset\" , \"license\" : \"Public Domain\" , \"price\" : \"123000000000000000000\" , \"files\" : [ { \"index\" : 0 , \"url\" : \"https://example-url.net/weather/forecast/madrid/350750305731.xml\" , \"contentLength\" : \"0\" , \"contentType\" : \"text/xml\" , \"compression\" : \"none\" } ] }, \"additionalInformation\" :{ \"description\" : \"Weather forecast of Europe/Madrid in XML format\" , \"copyrightHolder\" : \"Norwegian Meteorological Institute\" , \"categories\" : [ \"Other\" ], \"links\" : [], \"tags\" : [], \"updateFrequency\" : null , \"structuredMarkup\" : [] } } Example of Remote Metadata \u00b6 Similarly, this is how the metadata file would look as a response to querying Metadata API (remote metadata). Note that url is removed from all objects in the files array, and encryptedFiles & curation are added. { \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://metadata:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"type\" : \"dataset\" , \"name\" : \"Madrid Weather forecast\" , \"dateCreated\" : \"2019-05-16T12:36:14.535Z\" , \"author\" : \"Norwegian Meteorological Institute\" , \"license\" : \"Public Domain\" , \"price\" : \"123000000000000000000\" , \"files\" :[ { \"contentLength\" : \"0\" , \"contentType\" : \"text/xml\" , \"compression\" : \"none\" , \"index\" : 0 } ], \"datePublished\" : \"2019-05-16T12:41:01Z\" }, \"encryptedFiles\" : \"0x7a0d1c66ae861\u2026df43aa9\" , \"curation\" :{ \"rating\" : 1 , \"numVotes\" : 7 , \"schema\" : \"BINARY\" , \"isListed\" : true }, \"additionalInformation\" : { \"description\" : \"Weather forecast of Europe/Madrid in XML format\" , \"copyrightHolder\" : \"Norwegian Meteorological Institute\" , \"categories\" : [ \"Other\" ], \"links\" : [], \"tags\" : [], \"updateFrequency\" : null , \"structuredMarkup\" : [] } } } ] } Specific attributes per asset type \u00b6 Depending on the asset type (dataset, algorithm), there are different metadata attributes supported: Algorithm attributes \u00b6 An asset of type algorithm has the following additional attributes under main.algorithm : Attribute Type Required Description language string no Language used to implement the software format string no Packaging format of the software. version string no Version of the software. container Object yes Object describing the Docker container image. The container object has the following attributes: Attribute Type Required Description entrypoint string yes The command to execute, or script to run inside the Docker image. image string yes Name of the Docker image. tag string yes Tag of the Docker image. { \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"author\" : \"John Doe\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"license\" : \"CC-BY\" , \"name\" : \"My super algorithm\" , \"price\" : \"1\" , \"type\" : \"algorithm\" , \"algorithm\" : { \"language\" : \"scala\" , \"format\" : \"docker-image\" , \"version\" : \"0.1\" , \"container\" : { \"entrypoint\" : \"node $ALGO\" , \"image\" : \"node\" , \"tag\" : \"10\" } }, \"files\" : [ { \"name\" : \"build_model\" , \"url\" : \"https://raw.githubusercontent.com/keyko-io/test-algorithm/master/javascript/algo.js\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"contentType\" : \"text/plain\" , \"encoding\" : \"UTF-8\" , \"compression\" : \"zip\" } ] }, \"additionalInformation\" : { \"description\" : \"Workflow to aggregate weather information\" , \"tags\" : [ \"weather\" , \"uk\" , \"2011\" , \"workflow\" , \"aggregation\" ], \"copyrightHolder\" : \"John Doe\" } } } References \u00b6 Schema.org is a collaborative, community activity with a mission to create, maintain, and promote schemas for structured data on the Internet. Data types use the Schema.org primitive data types . Schema.org: DataSet Schema.org: FileSize Common license types for datasets","title":"Metadata"},{"location":"architecture/specs/metadata/#meta-spec-metadata-ontology","text":"shortname: DID name: Metadata Ontology type: Standard status: Valid version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: META SPEC: Metadata Ontology Motivation Life Cycle of Metadata Local Metadata Remote Metadata Metadata Attributes Main Attributes File Attributes Additional Attributes Other Suggested Additional Attributes Curation Attributes Example of Local Metadata Example of Remote Metadata Specific attributes per asset type Algorithm attributes References","title":"META SPEC: Metadata Ontology"},{"location":"architecture/specs/metadata/#motivation","text":"Every asset (dataset, algorithm) in Nevermined has an associated Decentralized Identifier (DID) and DID document / DID Descriptor Object (DDO). Because assets without proper descriptive metadata have poor visibility and discoverability. See DID SPEC for information about the overall structure of Nevermined DDOs and DIDs.This OEP is about one particular part of Nevermined DDOs: the asset metadata, a JSON object with information about the asset. This SPEC defines the assets metadata ontology, i.e. the schema for the asset metadata. It's based on the public schema.org DataSet schema . This SPEC doesn't detail the exact method of registering assets on-chain or storing DDOs. The main motivations of this SPEC are to: Specify the common attributes that MUST be included in any asset metadata stored in Nevermined networks Normalize the attributes to use in any curation process, to provide a common structure to sort and filter the DDOs Identify the recommended additional attributes that SHOULD be included in a DDO to facilitate asset search Provide an example of an asset metadata object and additional links for reference","title":"Motivation"},{"location":"architecture/specs/metadata/#life-cycle-of-metadata","text":"","title":"Life Cycle of Metadata"},{"location":"architecture/specs/metadata/#local-metadata","text":"Metadata is first created by the publisher of the asset. The publisher has knowledge of the file URLs, and they are stored in plaintext in the files object. This initial metadata is the local metadata .","title":"Local Metadata"},{"location":"architecture/specs/metadata/#remote-metadata","text":"A publisher publishes (registers) an asset using Nevermined SDKs, which might be running on their local machine or remotely. When they do, the local metadata is passed to the SDK, which makes some changes and additions in the metadata, puts it into a DDO, and sends that DDO to a metadata API. The Metadata API may also make some changes and additions to the metadata, such as the datePublished or parts of the curation object. The metadata that finally gets stored by the Metadata API is the remote metadata . A marketplace can and might also act as a publisher. SPEC ACCESS describes the publishing flow in more detail.","title":"Remote Metadata"},{"location":"architecture/specs/metadata/#metadata-attributes","text":"An asset is the representation of different type of resources in Nevermined. Typically can asset could be one of the following asset types: Dataset . An asset representing a dataset or data resource. It could be for example a CSV file or a multiple JPG files. Algorithm . An asset representing a piece of software. It could be a python script using tensorflow, a spark job, etc. Each kind of asset require a different subset of metadata attributes. The distinction between the type of asset (dataset, algorithm) is given by the attribute DDO.services[\"metadata\"].main.type A metadata object has the following attributes, all of which are objects. Attribute Required Description main Yes Main attributes used to calculate the service checksum curation (remote) Curation attributes additionalInformation No Optional attributes encryptedFiles (remote) Encrypted string of the attributes.main.files object. encryptedServices (remote) Encrypted string of the attributes.main.services object. The main , curation and additionalInformation attributes are independent of the asset type, all assets have those metadata sections.","title":"Metadata Attributes"},{"location":"architecture/specs/metadata/#main-attributes","text":"This list of attributes can't be modified after creation , because these are considered as the metadata essence of the asset created. This information is used to calculate the unique checksum of the asset. If any change would be necessary in the following attributes, it would be necessary to create a new asset derived from the existing one. The main object has the following attributes, not all are required. Some are required by only the metadata store ( remote ) and others are mandatory for local metadata only. If required or not by both, they are marked with Yes/No in the Required column. Attribute Type Required Description name Text Yes Descriptive name or title of the asset. type Text Yes Type of the asset. Helps to filter by the type of asset. It could be for example (\"dataset\", \"algorithm\"). dateCreated DateTime Yes The date on which the asset was created by the originator. ISO 8601 format, Coordinated Universal Time, e.g. 2019-01-31T08:38:32Z . datePublished DateTime (remote) The date on which the asset DDO is registered into the metadata store (Metadata API) author Text Yes Name of the entity generating this data (e.g. Tfl, Disney Corp, etc.). license Text Yes Short name referencing the license of the asset (e.g. Public Domain, CC-0, CC-BY, No License Specified, etc. ). If it's not specified, the following value will be added: \"No License Specified\". price String Yes Price of the asset. It must be an integer encoded as a string, e.g. \"123000000000000000000\" . files Array of files object Yes Array of File objects including the encrypted file urls. Further metadata about each file is stored, see File Attributes","title":"Main Attributes"},{"location":"architecture/specs/metadata/#file-attributes","text":"File attributes are a subset of the main section. A file object has the following attributes, with the details necessary to consume and validate the data. Attribute Required Description url (local) Content URL. Omitted from the remote metadata. Supports http(s):// and ipfs:// URLs. name no File name. index yes Index number starting from 0 of the file. contentType yes File format. checksum no Checksum of the file using your preferred format (i.e. MD5). Format specified in checksumType . If it's not provided can't be validated if the file was not modified after registering. checksumType no Format of the provided checksum. Can vary according to server (i.e Amazon vs. Azure) contentLength no Size of the file in bytes. encoding no File encoding (e.g. UTF-8). compression no File compression (e.g. no, gzip, bzip2, etc). encrypted no Boolean. Is the file encrypted? If is not set is assumed the file is not encrypted encryptionMode no Encryption mode used. Just valid if encrypted=true resourceId no Remote identifier of the file in the external provider. It is typically the remote id in the cloud provider. attributes no Key-Value hash map with additional attributes describing the asset file. It could include details like the Amazon S3 bucket, region, etc.","title":"File Attributes"},{"location":"architecture/specs/metadata/#additional-attributes","text":"All the additional information will be stored as part of the additionalInformation section. Attribute Type Required categories Array of Text No tags Array of Text No description Text No copyrightHolder Text No workExample Text No links Array of Link No inLanguage Text No","title":"Additional Attributes"},{"location":"architecture/specs/metadata/#other-suggested-additional-attributes","text":"These are examples of attributes that can enhance the discoverability of a resource: Attribute Description sla Service Level Agreement. industry updateFrequency An indication of update latency - i.e. How often are updates expected (seldom, annually, quarterly, etc.), or is the resource static that is never expected to get updated. termsOfService privacy keyword A list of keywords/tags describing a dataset. structuredMarkup A link to machine-readable structured markup (such as ttl/json-ld/rdf) describing the dataset. The publisher of a DDO MAY add additional attributes or change the above object definition.","title":"Other Suggested Additional Attributes"},{"location":"architecture/specs/metadata/#curation-attributes","text":"A curation object has the following attributes. Attribute Type Required Description rating Number (decimal) Yes Decimal value between 0 and 1. 0 is the default value. numVotes Integer Yes Number of votes. 0 is the default value. schema Text No Schema applied to calculate the rating. isListed Boolean No Flag unsuitable content. False by default. If it's true, the content must not be returned.","title":"Curation Attributes"},{"location":"architecture/specs/metadata/#example-of-local-metadata","text":"{ \"main\" : { \"name\" : \"Madrid Weather forecast\" , \"dateCreated\" : \"2019-05-16T12:36:14.535Z\" , \"author\" : \"Norwegian Meteorological Institute\" , \"type\" : \"dataset\" , \"license\" : \"Public Domain\" , \"price\" : \"123000000000000000000\" , \"files\" : [ { \"index\" : 0 , \"url\" : \"https://example-url.net/weather/forecast/madrid/350750305731.xml\" , \"contentLength\" : \"0\" , \"contentType\" : \"text/xml\" , \"compression\" : \"none\" } ] }, \"additionalInformation\" :{ \"description\" : \"Weather forecast of Europe/Madrid in XML format\" , \"copyrightHolder\" : \"Norwegian Meteorological Institute\" , \"categories\" : [ \"Other\" ], \"links\" : [], \"tags\" : [], \"updateFrequency\" : null , \"structuredMarkup\" : [] } }","title":"Example of Local Metadata"},{"location":"architecture/specs/metadata/#example-of-remote-metadata","text":"Similarly, this is how the metadata file would look as a response to querying Metadata API (remote metadata). Note that url is removed from all objects in the files array, and encryptedFiles & curation are added. { \"service\" : [ { \"index\" : 0 , \"serviceEndpoint\" : \"http://metadata:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"type\" : \"dataset\" , \"name\" : \"Madrid Weather forecast\" , \"dateCreated\" : \"2019-05-16T12:36:14.535Z\" , \"author\" : \"Norwegian Meteorological Institute\" , \"license\" : \"Public Domain\" , \"price\" : \"123000000000000000000\" , \"files\" :[ { \"contentLength\" : \"0\" , \"contentType\" : \"text/xml\" , \"compression\" : \"none\" , \"index\" : 0 } ], \"datePublished\" : \"2019-05-16T12:41:01Z\" }, \"encryptedFiles\" : \"0x7a0d1c66ae861\u2026df43aa9\" , \"curation\" :{ \"rating\" : 1 , \"numVotes\" : 7 , \"schema\" : \"BINARY\" , \"isListed\" : true }, \"additionalInformation\" : { \"description\" : \"Weather forecast of Europe/Madrid in XML format\" , \"copyrightHolder\" : \"Norwegian Meteorological Institute\" , \"categories\" : [ \"Other\" ], \"links\" : [], \"tags\" : [], \"updateFrequency\" : null , \"structuredMarkup\" : [] } } } ] }","title":"Example of Remote Metadata"},{"location":"architecture/specs/metadata/#specific-attributes-per-asset-type","text":"Depending on the asset type (dataset, algorithm), there are different metadata attributes supported:","title":"Specific attributes per asset type"},{"location":"architecture/specs/metadata/#algorithm-attributes","text":"An asset of type algorithm has the following additional attributes under main.algorithm : Attribute Type Required Description language string no Language used to implement the software format string no Packaging format of the software. version string no Version of the software. container Object yes Object describing the Docker container image. The container object has the following attributes: Attribute Type Required Description entrypoint string yes The command to execute, or script to run inside the Docker image. image string yes Name of the Docker image. tag string yes Tag of the Docker image. { \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/assets/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"author\" : \"John Doe\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"license\" : \"CC-BY\" , \"name\" : \"My super algorithm\" , \"price\" : \"1\" , \"type\" : \"algorithm\" , \"algorithm\" : { \"language\" : \"scala\" , \"format\" : \"docker-image\" , \"version\" : \"0.1\" , \"container\" : { \"entrypoint\" : \"node $ALGO\" , \"image\" : \"node\" , \"tag\" : \"10\" } }, \"files\" : [ { \"name\" : \"build_model\" , \"url\" : \"https://raw.githubusercontent.com/keyko-io/test-algorithm/master/javascript/algo.js\" , \"index\" : 0 , \"checksum\" : \"efb2c764274b745f5fc37f97c6b0e761\" , \"contentLength\" : \"4535431\" , \"contentType\" : \"text/plain\" , \"encoding\" : \"UTF-8\" , \"compression\" : \"zip\" } ] }, \"additionalInformation\" : { \"description\" : \"Workflow to aggregate weather information\" , \"tags\" : [ \"weather\" , \"uk\" , \"2011\" , \"workflow\" , \"aggregation\" ], \"copyrightHolder\" : \"John Doe\" } } }","title":"Algorithm attributes"},{"location":"architecture/specs/metadata/#references","text":"Schema.org is a collaborative, community activity with a mission to create, maintain, and promote schemas for structured data on the Internet. Data types use the Schema.org primitive data types . Schema.org: DataSet Schema.org: FileSize Common license types for datasets","title":"References"},{"location":"architecture/specs/nft/","text":"NFT SPEC: Non Fungible Tokens Engine \u00b6 shortname: NFT name: Non Fungible Tokens Engine type: Standard status: Draft version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: NFT SPEC: Non Fungible Tokens Engine Motivation Use Case Publisher Consumer Facilitator Concepts Building Blocks NFT Specs (via ERC-1155) Architecture NFTs Principles Implementation Flows Publishing an Asset tokenized via NFTs Purchase and usage of a NFT Templates Template for selling a tokenized asset via NFTs Access to contents holding a NFT Template for selling an Asset Provenance Links This SPEC introduces Non Fungible Tokens (NFTs) as part of Nevermined architecture allowing the tokenization of assets, sales with secondary market royalties support and exclusive access to NFT holders. Motivation \u00b6 With this Specification we want to add to Nevermined the technical capabilities allowing the users to have a platform where digital and physical assets can be represented and traded between people openly, but keeping security, integrity, provenance and content creator's attribution. With that objective in mind, Nevermined must facilitate the execution of use cases like the following: Art publishing, exhibition, selling. Secondary market Collection of objects Tokenization of digital and physical assets (real estate, etc.) etc The intention of this document is to discuss how a fully functional NFT engine can be established in a decentralized system, to allow the support of complex use cases related with assets tokenization. The main objectives of this SPEC are: Understand the main use cases we can to implement Understand how assets can be tokenized using NFTs Understand how asset and NFTs sales can be established between creators, owners and consumers Identify how NFTs rely in some other Nevermined building blocks Specify how NFTs associated to assets (DIDs) can be minted and burner Allow the definition of royalties that enable the retribution of original creators in the secondary market Specify how NFT holders can get access to existing services Understand what provenance information needs to be tracked Use Case \u00b6 The following use case helps to understand the scope of the problem driving the technical implementation to put in place. For this use case we have to take into account the following target users: Publishers (an artists for example) Consumers (a collector) Facilitators (an art gallery for example) Publisher \u00b6 As a Publisher : I want to register digitally an asset I want to associate some metadata information to the assets I register I want to show my track record as publisher (bio, what I created, what I sold, etc.) I want to sell a digital representation of an asset for some price I want to limit the number of copies of an asset for sale I want to be rewarded via royalties in the secondary market for further sales I want to be able to delegate or loan some of my assets to a Facilitator user (gallery, etc.) Consumer \u00b6 As a Consumer : I want to discover relevant assets filtering by multiple parameters I appreciate curated assets avoiding me to waste time searching for high quality I want to see a digital representation of an asset and detailed information of it I want to check the ownership of an asset and full provenance record I want to see how many pieces of an specific assets were created I want to purchase an asset or part of an asset series I want to see and share my list of purchased assets I want to be able the sell any of my purchased assets to others Facilitator \u00b6 As a Facilitator : I want to explore all the assets existing in a the general market I want to invite publishers to expose in my space I want to to receive exhibition requests in my space and curate the assets and publishers to list I want to negotiate with publishers the conditions (sell commission) for listing in my space I want to maximize my sales online I want to provide my track record curating, selling, collecting and listing assets Concepts \u00b6 Building Blocks \u00b6 Nevermined is based in the following building blocks: Decentralized Identifiers (DID) - To identify items across on-chain and off-chain networks Access Control - To control who can do what and under what conditions Provenance - To track all the actions associated with every registered asset Tokenized Payment Gateway - To allow direct payment Integrity - To provide proof that everything is correct Identity Management - To allow to define fine access control policies On top of all of that, this Specification augments Nevermined with the support of Non Fungible Tokens (NFTs). The main intention of this is to allow the tokenization, transfer, mint and burn of any existing asset published in a Nevermined ecosystem. In Nevermined, any registered asset is a DID registered via the DIDRegistry Smart Contract. This contract provides a generic way to represent the creation of a digital asset in a Nevermined ecosystem. This digital asset can be the representation of anything in the real world, a data set in a big data lake, a vaccine shipment in a supply chain process, an artwork in a virtual (or physical) gallery or anything else. The DIDRegistry tracks that registration in an immutable way, associating this digital asset with the creator of that representation in a Nevermined ecosystem. This Specification assocites directly the standard NFT capabilities to any existing asset registered via the DIDRegistry . It allows without friction the possibility of tokenize via NFTs any existing DID. NFT Specs (via ERC-1155) \u00b6 Nowadays the main standard for providing NFTs functionality in Ethereum networks is ERC-721. ERC-721 require a separate contract to be deployed for each token type or collection. This places a lot of redundant bytecode on the Ethereum blockchain and limits certain functionality by the nature of separating each token contract into its own permissioned address. This means high cost, complexity, etc. Additionaly to ERC-721, ERC-1155 implements a multi-token factory allowing to register and tokenize multiple and independent assets in the same contract instance without multiple deployments. ERC-1155 design permits transferring multiple token types at once, saving on transaction costs.It is also easy to describe and mix multiple fungible or non-fungible token types in a single contract. Because of these advantages the following NFT integration will be based in the ERC-1155 foundations. Architecture \u00b6 NFTs Principles \u00b6 The NFTs engine is based in the following principles: Every asset has a Decentralized Identifier (aka DID) attached, and every DID as a identifier representing a digital entity can have associated multiple NFTs, allowing the tokenization of any kind of digital asset independently of the physical asset behind of it The user registering a DID can decide if he wants to enable or not the tokenization of the asset via NFTs When the tokenization is enabled for a specific asset, the user registering the asset can define a minting cap. This minting cap can not be changed afterward, because modifying the number of existing items of an asset will affect the further value of them for the NFTs holders. If the minting cap is set to zero, it means the DID minting is uncapped. The user registering an asset can specify the royalties that are rewarding the original creator in the secondary market. This royalties must be between 0 and 100 percent. The royalties can not be changed after they are initialized. This protects the buyers of a NFT to have to pay for a different commission to the one agreed during the purchase of a NFT. The payment and transfer of NFTs must always respect the original creators attribution and rewards Users giving or selling NFTs can have a mechanism to facilitate exclusive services to NFT holders Implementation \u00b6 From a Smart Contracts point of view, the DIDRegistry now extends a new NFTUpgradeable smart contract. This new contract implements the ERC-1155 standard and it's based in OpenZeppelin implementation. With this change, when a new Asset is registered via the DIDRegistry, it can automatically mint , burn and transfer NFTs attached to the Asset. Example: await didRegistry . registerMintableDID ( did , checksum , [], url , cappedAmount , royalties , constants . activities . GENERATED , '' ) await didRegistry . mint ( did , 5 ) await didRegistry . burn ( did , 1 ) await didRegistry . balanceOf ( someone , did ) The registerMintableDID is a new method that facilitates a couple new things for users registering assets who want to attach a NFT to them: They enable the NFT functionality for the asset registered. By default, the assets registered via the registerDID method do not have the NFTs functionality enabled. It setups a minting cap for the asset It specify the percentage of royalties (between 0 and 100) that the original creator of the Asset wants in the secondary market for a further sale. When a DID is registered via the traditional registerDID method, the same functionality can be obtained calling the enableAndMintDidNft method. Example: await didRegistry . registerAttribute ( did , checksum , [], url ) await didRegistry . enableAndMintDidNft ( did , 5 , 0 , true ) Flows \u00b6 Publishing an Asset tokenized via NFTs \u00b6 The publishing of an asset (with NFTs associated) involves: Filling and publishing the asset metadata and price The publisher defines the metadata in a DDO object, the number of NFTs to mint, their price and royalties in the secondary market. Association of unique Decentralized Identifiers (DID) and register on-chain The publisher register on-chain via DIDRegistry the new asset id (DID) Adding provenance event about content creation The Contracts track the provenance event of a new Asset registered The publisher initialize the NFT setup associated to the Asset Optionally defining the royalties to receive in further sales in the secondary market Optionally define the limited items of the serie. NFT minting for a DID can be capped The contract mint the NFTs associated to the asset (DID) limited serie All the NFTs minted are locked ready to be used in sales Publishing Flow Purchase and usage of a NFT \u00b6 The purchase of a NFT associated to an asset involves: The consumer discover an interesting asset with NFTs attached to it (offchain) via marketplace, catalog, gallery, etc. The consumer initialize a service agreement on-chain with the intention of purchase a NFT The consumer lock the funds required to purchase a NFT. In case the NFT is being sold by a user that is not the original asset creator, the price must include the original creator royalties The owner or a provider can trigger the TransferNFTCondition condition to approve the purchase and make the transfer of the NFT Anyone can call the new EscrowPayment condition. It will be in charge of: Distribute the rewards to the publisher or seller Distribute the royalties to the original creator (if is not the same than the seller) Using the existing NFTHolder condition it will be possible to the new NFT owner to get access to Nevermined services Publishing Flow Templates \u00b6 The Nevermined Service Execution Agreements provide standard scenarios for providing access and trigger remote computation. To complement those, this Spec detail 3 additional templates to support the following flows: NFT Sale. An asset owner tokenized an asset and sell one or many of the NFTs to a different user. NFT Access. A NFT holder can get access to exclusive contents for holding that NFT DID Sale. An asset owner wants to sell it totally. Template for selling a tokenized asset via NFTs \u00b6 The NFT Sales template supports an scenario where an Asset owner wants to tokenize an asset and sell pieces of it via NFTs. Owners buying a new NFT can sell them later to others in a secondary market. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing a NFT owner to transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer NFT Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the transfer of the NFT from the current owner for a specific DID. The DID Sales template is provided by the NFTSalesTemplate Smart Contract. Access to contents holding a NFT \u00b6 The NFT Access template is a use case specific template that allows a NFT owner to get access to exclusive contents provided by the original asset creator associated to the NFT. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing NFT holders to get access to Nevermined services. The template is a composite of 2 basic conditions: - NFT Holding Condition - Access Condition Once the agreement is created, the consumer can demonstrate he is holding a NFT for a specific DID. If that's the case the Access condition can be fulfilled by the asset owner or provider and all the agreement is fulfilled. This can be used in scenarios where a data or services owner, can allow users to get access to exclusive services only when they demonstrate they are holding a specific number of NFTs of a DID. The DID Sales template is provided by the NFTAccessTemplate Smart Contract. Template for selling an Asset \u00b6 It supports a scenario where an Asset owner can sell that asset to a new Owner. It is important to say the ownership of the asset is transfered to a new owner but there is always a reference on-chain about the original creator of the asset. This original creator can't be changed and is used to reward later to this user in the secondary market. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing an Asset owner to transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer DID Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the ownership transfer of an asset from the current owner for a specific DID. The DID Sales template is provided by the DIDSalesTemplate Smart Contract. DID Sale. An asset owner can put this asset for sale for a price. This not only gives access to the asset, also transfer ownership to the buyer. Further sales reward the creator in the secondary market. NFT Sale. An asset owner tokenize an asset using NFTs and sell them to others for a price. Further sales reward the creator in the secondary market. NFT access. An asset owner can mint, sell and transfer NFTs associated to a DID. Further NFT holders can get access to contents showing the NFT they hold. Provenance \u00b6 All the actions associated with the usual tokenization flow provided by NFTs register on-chain the relevant provenance entries allowing to track all that happened related to an asset. When a new asset is created it registers the provenance entry wasGeneratedBy When the asset owner initialize the asset tokenization via NFTs it raise the used provenance entry When the asset owner mint a NFT associated to an asset it raise the used provenance entry When the asset owner burn a NFT associated to an asset it raise the used provenance entry Links \u00b6 The Multi Token Standard OpenZeppelin ERC1155 Smart Contract implementation","title":"NFTs Engine"},{"location":"architecture/specs/nft/#nft-spec-non-fungible-tokens-engine","text":"shortname: NFT name: Non Fungible Tokens Engine type: Standard status: Draft version: 0.1 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: NFT SPEC: Non Fungible Tokens Engine Motivation Use Case Publisher Consumer Facilitator Concepts Building Blocks NFT Specs (via ERC-1155) Architecture NFTs Principles Implementation Flows Publishing an Asset tokenized via NFTs Purchase and usage of a NFT Templates Template for selling a tokenized asset via NFTs Access to contents holding a NFT Template for selling an Asset Provenance Links This SPEC introduces Non Fungible Tokens (NFTs) as part of Nevermined architecture allowing the tokenization of assets, sales with secondary market royalties support and exclusive access to NFT holders.","title":"NFT SPEC: Non Fungible Tokens Engine"},{"location":"architecture/specs/nft/#motivation","text":"With this Specification we want to add to Nevermined the technical capabilities allowing the users to have a platform where digital and physical assets can be represented and traded between people openly, but keeping security, integrity, provenance and content creator's attribution. With that objective in mind, Nevermined must facilitate the execution of use cases like the following: Art publishing, exhibition, selling. Secondary market Collection of objects Tokenization of digital and physical assets (real estate, etc.) etc The intention of this document is to discuss how a fully functional NFT engine can be established in a decentralized system, to allow the support of complex use cases related with assets tokenization. The main objectives of this SPEC are: Understand the main use cases we can to implement Understand how assets can be tokenized using NFTs Understand how asset and NFTs sales can be established between creators, owners and consumers Identify how NFTs rely in some other Nevermined building blocks Specify how NFTs associated to assets (DIDs) can be minted and burner Allow the definition of royalties that enable the retribution of original creators in the secondary market Specify how NFT holders can get access to existing services Understand what provenance information needs to be tracked","title":"Motivation"},{"location":"architecture/specs/nft/#use-case","text":"The following use case helps to understand the scope of the problem driving the technical implementation to put in place. For this use case we have to take into account the following target users: Publishers (an artists for example) Consumers (a collector) Facilitators (an art gallery for example)","title":"Use Case"},{"location":"architecture/specs/nft/#publisher","text":"As a Publisher : I want to register digitally an asset I want to associate some metadata information to the assets I register I want to show my track record as publisher (bio, what I created, what I sold, etc.) I want to sell a digital representation of an asset for some price I want to limit the number of copies of an asset for sale I want to be rewarded via royalties in the secondary market for further sales I want to be able to delegate or loan some of my assets to a Facilitator user (gallery, etc.)","title":"Publisher"},{"location":"architecture/specs/nft/#consumer","text":"As a Consumer : I want to discover relevant assets filtering by multiple parameters I appreciate curated assets avoiding me to waste time searching for high quality I want to see a digital representation of an asset and detailed information of it I want to check the ownership of an asset and full provenance record I want to see how many pieces of an specific assets were created I want to purchase an asset or part of an asset series I want to see and share my list of purchased assets I want to be able the sell any of my purchased assets to others","title":"Consumer"},{"location":"architecture/specs/nft/#facilitator","text":"As a Facilitator : I want to explore all the assets existing in a the general market I want to invite publishers to expose in my space I want to to receive exhibition requests in my space and curate the assets and publishers to list I want to negotiate with publishers the conditions (sell commission) for listing in my space I want to maximize my sales online I want to provide my track record curating, selling, collecting and listing assets","title":"Facilitator"},{"location":"architecture/specs/nft/#concepts","text":"","title":"Concepts"},{"location":"architecture/specs/nft/#building-blocks","text":"Nevermined is based in the following building blocks: Decentralized Identifiers (DID) - To identify items across on-chain and off-chain networks Access Control - To control who can do what and under what conditions Provenance - To track all the actions associated with every registered asset Tokenized Payment Gateway - To allow direct payment Integrity - To provide proof that everything is correct Identity Management - To allow to define fine access control policies On top of all of that, this Specification augments Nevermined with the support of Non Fungible Tokens (NFTs). The main intention of this is to allow the tokenization, transfer, mint and burn of any existing asset published in a Nevermined ecosystem. In Nevermined, any registered asset is a DID registered via the DIDRegistry Smart Contract. This contract provides a generic way to represent the creation of a digital asset in a Nevermined ecosystem. This digital asset can be the representation of anything in the real world, a data set in a big data lake, a vaccine shipment in a supply chain process, an artwork in a virtual (or physical) gallery or anything else. The DIDRegistry tracks that registration in an immutable way, associating this digital asset with the creator of that representation in a Nevermined ecosystem. This Specification assocites directly the standard NFT capabilities to any existing asset registered via the DIDRegistry . It allows without friction the possibility of tokenize via NFTs any existing DID.","title":"Building Blocks"},{"location":"architecture/specs/nft/#nft-specs-via-erc-1155","text":"Nowadays the main standard for providing NFTs functionality in Ethereum networks is ERC-721. ERC-721 require a separate contract to be deployed for each token type or collection. This places a lot of redundant bytecode on the Ethereum blockchain and limits certain functionality by the nature of separating each token contract into its own permissioned address. This means high cost, complexity, etc. Additionaly to ERC-721, ERC-1155 implements a multi-token factory allowing to register and tokenize multiple and independent assets in the same contract instance without multiple deployments. ERC-1155 design permits transferring multiple token types at once, saving on transaction costs.It is also easy to describe and mix multiple fungible or non-fungible token types in a single contract. Because of these advantages the following NFT integration will be based in the ERC-1155 foundations.","title":"NFT Specs (via ERC-1155)"},{"location":"architecture/specs/nft/#architecture","text":"","title":"Architecture"},{"location":"architecture/specs/nft/#nfts-principles","text":"The NFTs engine is based in the following principles: Every asset has a Decentralized Identifier (aka DID) attached, and every DID as a identifier representing a digital entity can have associated multiple NFTs, allowing the tokenization of any kind of digital asset independently of the physical asset behind of it The user registering a DID can decide if he wants to enable or not the tokenization of the asset via NFTs When the tokenization is enabled for a specific asset, the user registering the asset can define a minting cap. This minting cap can not be changed afterward, because modifying the number of existing items of an asset will affect the further value of them for the NFTs holders. If the minting cap is set to zero, it means the DID minting is uncapped. The user registering an asset can specify the royalties that are rewarding the original creator in the secondary market. This royalties must be between 0 and 100 percent. The royalties can not be changed after they are initialized. This protects the buyers of a NFT to have to pay for a different commission to the one agreed during the purchase of a NFT. The payment and transfer of NFTs must always respect the original creators attribution and rewards Users giving or selling NFTs can have a mechanism to facilitate exclusive services to NFT holders","title":"NFTs Principles"},{"location":"architecture/specs/nft/#implementation","text":"From a Smart Contracts point of view, the DIDRegistry now extends a new NFTUpgradeable smart contract. This new contract implements the ERC-1155 standard and it's based in OpenZeppelin implementation. With this change, when a new Asset is registered via the DIDRegistry, it can automatically mint , burn and transfer NFTs attached to the Asset. Example: await didRegistry . registerMintableDID ( did , checksum , [], url , cappedAmount , royalties , constants . activities . GENERATED , '' ) await didRegistry . mint ( did , 5 ) await didRegistry . burn ( did , 1 ) await didRegistry . balanceOf ( someone , did ) The registerMintableDID is a new method that facilitates a couple new things for users registering assets who want to attach a NFT to them: They enable the NFT functionality for the asset registered. By default, the assets registered via the registerDID method do not have the NFTs functionality enabled. It setups a minting cap for the asset It specify the percentage of royalties (between 0 and 100) that the original creator of the Asset wants in the secondary market for a further sale. When a DID is registered via the traditional registerDID method, the same functionality can be obtained calling the enableAndMintDidNft method. Example: await didRegistry . registerAttribute ( did , checksum , [], url ) await didRegistry . enableAndMintDidNft ( did , 5 , 0 , true )","title":"Implementation"},{"location":"architecture/specs/nft/#flows","text":"","title":"Flows"},{"location":"architecture/specs/nft/#publishing-an-asset-tokenized-via-nfts","text":"The publishing of an asset (with NFTs associated) involves: Filling and publishing the asset metadata and price The publisher defines the metadata in a DDO object, the number of NFTs to mint, their price and royalties in the secondary market. Association of unique Decentralized Identifiers (DID) and register on-chain The publisher register on-chain via DIDRegistry the new asset id (DID) Adding provenance event about content creation The Contracts track the provenance event of a new Asset registered The publisher initialize the NFT setup associated to the Asset Optionally defining the royalties to receive in further sales in the secondary market Optionally define the limited items of the serie. NFT minting for a DID can be capped The contract mint the NFTs associated to the asset (DID) limited serie All the NFTs minted are locked ready to be used in sales Publishing Flow","title":"Publishing an Asset tokenized via NFTs"},{"location":"architecture/specs/nft/#purchase-and-usage-of-a-nft","text":"The purchase of a NFT associated to an asset involves: The consumer discover an interesting asset with NFTs attached to it (offchain) via marketplace, catalog, gallery, etc. The consumer initialize a service agreement on-chain with the intention of purchase a NFT The consumer lock the funds required to purchase a NFT. In case the NFT is being sold by a user that is not the original asset creator, the price must include the original creator royalties The owner or a provider can trigger the TransferNFTCondition condition to approve the purchase and make the transfer of the NFT Anyone can call the new EscrowPayment condition. It will be in charge of: Distribute the rewards to the publisher or seller Distribute the royalties to the original creator (if is not the same than the seller) Using the existing NFTHolder condition it will be possible to the new NFT owner to get access to Nevermined services Publishing Flow","title":"Purchase and usage of a NFT"},{"location":"architecture/specs/nft/#templates","text":"The Nevermined Service Execution Agreements provide standard scenarios for providing access and trigger remote computation. To complement those, this Spec detail 3 additional templates to support the following flows: NFT Sale. An asset owner tokenized an asset and sell one or many of the NFTs to a different user. NFT Access. A NFT holder can get access to exclusive contents for holding that NFT DID Sale. An asset owner wants to sell it totally.","title":"Templates"},{"location":"architecture/specs/nft/#template-for-selling-a-tokenized-asset-via-nfts","text":"The NFT Sales template supports an scenario where an Asset owner wants to tokenize an asset and sell pieces of it via NFTs. Owners buying a new NFT can sell them later to others in a secondary market. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing a NFT owner to transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer NFT Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the transfer of the NFT from the current owner for a specific DID. The DID Sales template is provided by the NFTSalesTemplate Smart Contract.","title":"Template for selling a tokenized asset via NFTs"},{"location":"architecture/specs/nft/#access-to-contents-holding-a-nft","text":"The NFT Access template is a use case specific template that allows a NFT owner to get access to exclusive contents provided by the original asset creator associated to the NFT. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing NFT holders to get access to Nevermined services. The template is a composite of 2 basic conditions: - NFT Holding Condition - Access Condition Once the agreement is created, the consumer can demonstrate he is holding a NFT for a specific DID. If that's the case the Access condition can be fulfilled by the asset owner or provider and all the agreement is fulfilled. This can be used in scenarios where a data or services owner, can allow users to get access to exclusive services only when they demonstrate they are holding a specific number of NFTs of a DID. The DID Sales template is provided by the NFTAccessTemplate Smart Contract.","title":"Access to contents holding a NFT"},{"location":"architecture/specs/nft/#template-for-selling-an-asset","text":"It supports a scenario where an Asset owner can sell that asset to a new Owner. It is important to say the ownership of the asset is transfered to a new owner but there is always a reference on-chain about the original creator of the asset. This original creator can't be changed and is used to reward later to this user in the secondary market. Anyone (consumer/provider/publisher) can use this template in order to setup an agreement allowing an Asset owner to transfer the asset ownership after some payment. The template is a composite of 3 basic conditions: - Lock Payment Condition - Transfer DID Condition - Escrow Reward Condition This scenario takes into account royalties for original creators in the secondary market. Once the agreement is created, the consumer after payment can request the ownership transfer of an asset from the current owner for a specific DID. The DID Sales template is provided by the DIDSalesTemplate Smart Contract. DID Sale. An asset owner can put this asset for sale for a price. This not only gives access to the asset, also transfer ownership to the buyer. Further sales reward the creator in the secondary market. NFT Sale. An asset owner tokenize an asset using NFTs and sell them to others for a price. Further sales reward the creator in the secondary market. NFT access. An asset owner can mint, sell and transfer NFTs associated to a DID. Further NFT holders can get access to contents showing the NFT they hold.","title":"Template for selling an Asset"},{"location":"architecture/specs/nft/#provenance","text":"All the actions associated with the usual tokenization flow provided by NFTs register on-chain the relevant provenance entries allowing to track all that happened related to an asset. When a new asset is created it registers the provenance entry wasGeneratedBy When the asset owner initialize the asset tokenization via NFTs it raise the used provenance entry When the asset owner mint a NFT associated to an asset it raise the used provenance entry When the asset owner burn a NFT associated to an asset it raise the used provenance entry","title":"Provenance"},{"location":"architecture/specs/nft/#links","text":"The Multi Token Standard OpenZeppelin ERC1155 Smart Contract implementation","title":"Links"},{"location":"architecture/specs/provenance/","text":"PROV SPEC: Decentralized Data Provenance \u00b6 shortname: PROV name: Decentralized Data Provenance type: Standard status: Valid version: 0.2 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: PROV SPEC: Decentralized Data Provenance Motivation Concepts Specifications Provenance Model Provenance Types Entities Agents Activities Provenance Relations Generation: Register a new entity generated by an agent (wasGeneratedBy) Derivation: register relationship between source and derived entities (wasDerivedFrom) Association (wasAssociatedWith) Delegation (actedOnBehalfOf) Usage (used) Activity: Register activities Examples Scenario Actors Flow Architecture Data Process Good Manufacturing Handover to Carrier Handover to the end recipient Registry Provenance Registry Metadata Registry Agents Registry Entities Registry Provenance metadata integrity How to compute the provenance checksum Links This SPEC introduces the concept of asset Data Provenance in Nevermined platform based on the W3C Provenance specification. Motivation \u00b6 The intention of this document is to discuss how data provenance can be established in a decentralized system, permitting integrity validation of this provenance information. The main objectives of this SPEC are: Understand what provenance information needs to be tracked Specify how the provenance integrity check is stored on-chain Identify the actors involved in the publishing and visualization of provenance information Detail how to register relationships between source and derived entities Detail how to register activities Understand how to associate activities with the input and output entities in a workflow Validate cryptographically that an entity was generated from a specific input entity in a specific activity Concepts \u00b6 Specifications \u00b6 Nevermined Data Provenance solution is designed based on the W3C Provenance specifications . In addition to this, Nevermined uses Decentralized Identifiers following the W3C DID specification . The design of Nevermined using both specifications is critical because it enables the construction of a complete and decentralized provenance solution where independent parties can collaborate in the common problem of delivering goods without relying on a central party, and providing transparency, complete traceability, efficiency and a unique source of truth. Provenance Model \u00b6 The W3C PROV specification defines Provenance as: Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness. The W3C PROV data model includes a core set of types and relations commonly found in provenance tracking for more specific uses. In particular, the data model includes both Type and Relation categories. Type category contains entity , activity and agent which are core components. Relations category defines key relationships between different types of components, which can be mapped into specific PROV model relations. PROV Mapping Provenance Types \u00b6 Provenance information can be modeled as the interaction between Agents and Entities related via the Activities between them: Entities \u00b6 In PROV, physical, digital, conceptual, or other kinds of things are called entities. Examples of such entities are assets, a web page, a chart, a spellchecker, etc. Agents \u00b6 An agent takes a role in an activity such that the agent can be assigned some degree of responsibility for the activity taking place. An agent can be a person, a piece of software, an inanimate object, an organization, or other entities that may be ascribed responsibility. Activities \u00b6 Activities are how entities come into existence and how their attributes change to become new entities, often making use of previously existing entities to achieve this. They are dynamic aspects of the world, such as actions, processes, etc. For example, if the second version of document D was generated by a translation from the first version of the document in another language, then this translation is an activity. PROV E-R Provenance Relations \u00b6 Relations between agents and entities are open but there are some common relations that can be used as reference: Generation: Register a new entity generated by an agent (wasGeneratedBy) \u00b6 Generation is the completion of production of a new entity by an activity. This entity did not exist before generation and becomes available for usage after this generation. Generation , written wasGeneratedBy(id; e, a, t, attrs) in PROV-N (a notation for provenance aimed at human consumption), has: id : an optional identifier for a generation; entity : an identifier (e) for a created entity. In Nevermined a DID ; activity : an optional identifier (a) for the activity that creates the entity. In Nevermined a DID ; time : an optional \"generation time\" (t), the time at which the entity was completely created; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this generation. While each of id , activity , time , and attributes are optional, at least one of them must be present. PROV uses qualified names to identify things for data provenance, which is essentially a shortened representation of a URI in the form of prefix:localpart . Example: wasGeneratedBy(did:nv:e1, did:nv:a1, 2019-10-26T21:32:52) wasGeneratedBy(did:nv:e2, did:nv:a1, 2019-10-26T10:00:00) The above example shows the existence of two generations (with respective times 2019-10-26T21:32:52 and 2001-10-26T10:00:00), at which new entities, identified by did:nv:e1 and did:nv:e2 , were created by an activity, identified by did:nv:a1 . Derivation: register relationship between source and derived entities (wasDerivedFrom) \u00b6 Derivation is a transformation of an entity into another, an update of an entity resulting in a new one, or the construction of a new entity based on a pre-existing entity. A derivation , written wasDerivedFrom(id; e2, e1, a, g2, u1, attrs) in PROV-N, has: id : an optional identifier for a derivation; generatedEntity : the identifier (e2) of the derived entity generated by the derivation. In Nevermined a DID ; usedEntity : the identifier (e1) of the source entity used by the derivation. In Nevermined a DID ; activity : an optional identifier (a) for the activity using and generating the above entities. In Nevermined a DID ; generation : an optional identifier (g2) for the generation involving the generated entity (e2) and activity (a). In Nevermined a DID ; usage : an optional identifier (u1) for the usage involving the used entity (e1) and activity (a). In Nevermined a DID ; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this derivation. The following descriptions are about derivations between did:nv:e1 and did:nv:e2 , but no information is provided as to the identity of the activity (and usage and generation) underpinning the derivation. In the second line, a type attribute is also provided. wasDerivedFrom(did:nv:e2, did:nv:e1) wasDerivedFrom(did:nv:e2, did:nv:e1, [ prov:type=\"physical transform\" ]) The following description expresses that activity did:nv:a , using the entity did:nv:e1 according to usage did:nv:01 , derived the entity did:nv:e2 and generated it according to generation did:nv:02 . It is followed by descriptions for generation did:nv:02 and usage did:nv:01 . wasDerivedFrom(did:nv:e2, did:nv:e1, did:nv:a, did:nv:02, did:nv:01) wasGeneratedBy(did:nv:02; did:nv:e2, did:nv:a, -) used(did:nv:01; did:nv:a, did:nv:e1, -) With such a comprehensive description of derivation, a program that analyzes provenance can identify the activity underpinning the derivation, it can identify how the preceding entity did:nv:e1 was used by the activity (e.g. for instance, which argument it was passed, if the activity is the result of a function invocation), and which output the derived entity did:nv:e2 was obtained from (say, for a function returning multiple results). Association (wasAssociatedWith) \u00b6 Association is an assignment of responsibility to an agent for an activity, indicating that the agent had a role in the activity. An association, written wasAssociatedWith(id; a, ag, pl, attrs) in PROV-N, has: id : an optional identifier for the association between an activity and an agent; activity : an identifier (a) for the activity; agent : an optional identifier (ag) for the agent associated with the activity; plan : an optional identifier (pl) for the plan the agent relied on in the context of this activity; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this association of this activity with this agent. The following examples are about the association between one activity did:nv:ac1 and one agent did:nv:a00 . In the second example, a type attribute is also provided. wasAssociatedWith(did:nv:ac1, did:nv:a00) wasAssociatedWith(did:nv:ac1, did:nv:a00, [ prov:type=\"manufacturing\" ]) Delegation (actedOnBehalfOf) \u00b6 Delegation is the assignment of authority and responsibility to an agent (by itself or by another agent) to carry out a specific activity as a delegate or representative, while the agent it acts on behalf of retains some responsibility for the outcome of the delegated work. A delegation link, written actedOnBehalfOf(id; ag2, ag1, a, attrs) in PROV-N, has: id : an optional identifier for the delegation link between delegate and responsible; delegate : an identifier (ag2) for the agent associated with an activity, acting on behalf of the responsible agent; responsible : an identifier (ag1) for the agent, on behalf of which the delegate agent acted; activity : an optional identifier (a) of an activity for which the delegation link holds; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this delegation link. In the following example we can see how the agent delegated did:nv:a1 acts on behalf of the did:nv:a2 responsible. actedOnBehalfOf(did:nv:a1, did:nv:a2) actedOnBehalfOf(did:nv:a1, did:nv:a2, [ prov:type=\"ground transportation\" ]) Usage (used) \u00b6 Usage is the beginning of utilizing an entity by an activity. Before usage, the activity had not begun to utilize this entity and could not have been affected by the entity. (Note: This definition is formulated for a given usage; it is permitted for an activity to use the same entity multiple times.) Given that a usage is the beginning of utilizing an entity, it is instantaneous. Usage, written used(id; a, e, t, attrs) in PROV-N, has: id : an optional identifier for a usage; activity : an identifier (a) for the activity that used an entity; entity : an optional identifier (e) for the entity being used; time : an optional \"usage time\" (t), the time at which the entity started to be used; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this usage. In the following example we can see how to associate the activity did:nv:ac1 with the usage of the entity did:nv:e1 in some specific moment. usage(did:nv:ac1, did:nv:e1, now()) usage(did:nv:ac1, did:nv:e1, now(), [ prov:type=\"shipping\" ]) Activity: Register activities \u00b6 An activity is something that occurs over a period of time and acts upon or with entities; it may include consuming, processing, transforming, modifying, relocating, using, or generating entities. An activity , written activity(id, st, et, [attr1=val1, ...]) in PROV-N, has: id : an identifier for an activity; startTime : an optional time (st) for the start of the activity; endTime : an optional time (et) for the end of the activity; attributes : an optional set of attribute-value pairs ((attr1, val1), ...) representing additional information about this activity. Example: activity(a1, 2011-11-16T16:05:00, 2011-11-16T16:06:00, [ ex:host=\"server.example.org\", prov:type='ex:edit' ]) The above example shows the existence of an activity with identifier a1 , start time 2011-11-16T16:05:00 , and end time 2011-11-16T16:06:00 , running on host server.example.org , and of type edit . Examples \u00b6 Taking into account the relations examples, the scenario where a new asset (entity) is created (generation), modified (derivation) and used by a third-party entity can be translated into this: // Entity X is associated with the activity of goodCreation wasAssociatedWith(goodCreation, entityX) // Entity Y is associated with the activity of goodModification wasAssociatedWith(goodModification, entityY) // Entity Z is associated with the activity of goodShipping wasAssociatedWith(goodShipping, entityZ) // A newAsset was created yesterday via goodCreation activity (Entity X) wasGeneratedBy(newAsset goodCreation, yesterday()) // The newDerivedAsset was created today from the newAsset via goodModification activity (Entity Y) wasDerivedFrom(newDerivedAsset, newAsset, goodModification, today()) // The newDerivedAsset is shipped by Entity Z used(goodShipping, newDerivedAsset, now()) Scenario \u00b6 For describing the architecture we are gonna use as a reference a supply chain use case. In this scenario a company manufacturing some goods needs to deliver them to the final customer. To do that the goods need to be transported by different shipping companies until the goods are handed over to the final recipient. Actors \u00b6 As an example to illustrate the architecture we are gonna describe the scenario with the following 4 different actors: Acme Co . International medical company manufacturing different kind of drugs in the their manufacturing center Armadillo Shipping . Courier doing ground and sea transportation of goods. Pigeon Carriers . Company doing air transportation of goods. John Doe . The end recipient of the goods Flow \u00b6 The end to end scenario includes the following steps: Acme Co. manufactures the drug at their manufacturing center Acme Co. hands off the product for transfer from Acme to ground transport (Armadillo Shipping) to begin the journey Armadillo transports the product from the manufacturer to the air freight provider for overseas shipping This may or may not go through a distribution center Armadillo hands off the freight to the air freight provider ( Pigeon Carriers) The air freight provider will take over the shipping and move the freight to their distribution center at the airport to wait for the cargo to be loaded. The cargo is loaded into the plane and transferred to the destination The air freight provider will hand off the cargo to the end recipient (John Doe) Provenance Example Use Case Architecture \u00b6 Data \u00b6 Across the complete supply chain scenario described above different parts of data are generated since the good is manufactured until it is delivered to the end recipient. Here some details about that: When the good is created, the manufacturer generates some additional information about the physical asset. This could include documents with asset specifications, details of manufacturing, certificates of quality, etc. When the good is handed over to the shipping company there are also other pieces of data generated. For example the receipt signed between the agent handing over the goods and the courier. During the transportation process, some additional data could be generated including temperature, humidity, coordinates, etc. When the good is delivered to the end user, both parties sign a delivery receipt. This data is also relevant and necessary for further control. Taking into account the above details we can distinguish different kind of data generated: Files. Including goods specs, receipts, etc. Each agent in the scenario needs to keep track of files or get access to the files created by others. Metadata. Describing the goods or the activities related with the goods during the delivery life-cycle. Nevermined provides a decentralized ecosystem where all this data can be registered and shared between all the agents participating during the supply chain process. It enables the registering of the files generated by the supply chain flow, making them available between the agents independently on the underlying technology. Also enable the registering of the metadata associated with the complete flow allowing to provide a complete lineage of the whole process. All this information is recorded in a decentralized backbone that works as a source of truth for all the parties. Nevermined doesn\u2019t require to replace the existing supply chain software platforms each agent in the system has. It integrates to them and augments their existing capabilities allowing to make available the relevant data generated to the agents participating during the supply process. Process \u00b6 Taking into account the Scenario described before, the end to end flow can be detailed in the following steps: Good Manufacturing \u00b6 Acme Corp. (Manufacturer) has created some goods that need to be delivered to John Doe (End Recipient). Acme uses the supply chain management Oracle SCM platform. When the good is created some relevant data (files, certificates, etc.) is created in the SCM platform. As a complement to that, the good created is registered into Nevermined (via SDK integration). This allows to: Identify unequivocally the good created within the supply chain network. This associates a unique Decentralized Identifier (DID) to the good and identifies Acme Corp. as the unique manufacturer of the good, providing the genesis of the goods lineage. Register some metadata related with the good created, including date of manufacturing, description, conditions, etc. This metadata is hashed and becomes part of the DID created, avoiding further modifications (like date of manufacturing tamper) without breaking the integrity check of the DID. Register the data files as part of the metadata. Typically these files will be stored as part of Acme Corp. SCM system. Nevermined provides a gateway that can integrate different backends. These files registered, equally to the metadata are part of the Nevermined integrity check. Handover to Carrier \u00b6 Acme Corp. needs to send the goods manufactured to John Doe. This delivery process needs to involve 2 independent transport companies, Armadillo Shipping that is doing local ground transportation and Pigeon Carriers that is doing air transportation. Pigeon Carriers will deliver the goods to the end recipient. During this process the following things happen: * Acme Corp. hands over the goods to Armadillo Shipping. During this process there is a digital signature process where Acme Corp. gets the signature from Armadillo of this hand over process. Acme Corp. registers this in the Nevermined Provenance Registry. * Armadillo Shipping transports the goods to the airport to hand over to Pigeon Carriers. During the transportation process some data is created including the temperature of the cargo and the coordinates of the complete trip from the Acme factory to the airport. The files with the data generated are uploaded automatically to the Armadillo SCM system. In addition to this the files are registered into Nevermined with a new DID. When Armadillo hands over the goods to Pigeon Carriers, the digital signature accepting the handover is registered in the Provenance Registry. The handover between carriers could include multiple steps and companies. Also intermediate storage in delivery centers, goods validation or certification, etc. For sake of simplicity here we only describe a simplistic end to end flow, but in essence a complete scenario involving additional steps could be very similar. Handover to the end recipient \u00b6 Pigeon Carriers needs to deliver the goods to John Doe (End Recipient). During this process and very similarly to the above described the following things happens: * John Doe sings digitally the delivery receipt. Pigeon Carriers. registers this in the Nevermined Provenance Registry. * John Doe, having the DID of the goods can track end to end the complete provenance record of the asset. Also for each intermediate step can retrieve the data assets associated with the goods and created during the delivery process. This makes it possible to track end to end the complete cargo flow involving independent agents. The provenance record is immutable and cryptographically secure, providing a transparent and unique source of truth that can be consulted by all the agents involved during and after the completion of the flow. This could allow John Doe to validate that the temperature of the goods were correct during transportation and using the GPS coordinates the cargo never went through unexpected locations. Provenance Architecture Registry \u00b6 Smart Contract \u00b6 struct DIDRegisterList { mapping(bytes32 => DIDRegister) didRegisters; bytes32[] didRegisterIds; } struct DIDRegister { address owner; bytes32 lastChecksum; string url; address lastUpdatedBy; uint256 blockNumberUpdated; address[] providers; address[] delegates; } struct ProvenanceRegistryList { mapping(bytes32 => ProvenanceRegistry) provenanceRegistry; } struct ProvenanceRegistry { bytes32 did; bytes32 relatedDid; bytes32 activityId; address agentId; address agentInvolvedId; uint8 method; address lastUpdatedBy; uint256 blockNumberUpdated; } # DIDRegister owner | lastChecksum | URL | lastUpdatedBy | blockNumber | providers | delegates -------|--------------|-----------------------|-----------------|---------------|---------------|------------------- 0x1234 | 00001 | http://nevermined.io | 2010 | 100 | [0x10] | [] 0xabab | 12213 | http://nevermined.io | 2011 | 100 | [] | [0xaa] # ProvenanceRegistry did | relatedDid | activityId | agentId | agentInvolvedId | method | lastUpdatedBy | blockNumber -------|--------------|-------------------|-------------------|--------------------|-----------|-------------------|----------------- 0x1234 | 0x5678 | 0xaabb | 0xccdd | 0xccbb | 0 | 2010 | 100 0xdddd | | 0xaabb | 0xccdd | | 1 | 2011 | 190 Provenance Registry \u00b6 The Provenance Registry provides a unique source truth of the provenance information registered in the Nevermined network. It is a generic record where the entities (digital or physical assets) represent their complete life-cycle. When it\u2019s necessary to represent the interaction between independent agents (Acme Corp. hands over a good to Armadillo Shipping), it\u2019s necessary to provide the digital signature of the agents participating in the transaction. Using the scenario already described and the W3C PROV specification the complete flow could be described as follows: // Acme Corp. manufacture some stuff wasAssociatedWith(acmeStuffManufacturing, Acme) // Armadillo does ground transportation wasAssociatedWith(armadilloGroundTransport, Armadillo) // Pigeon does air transportation wasAssociatedWith(pigeonAirTransport, Pigeon) // Stuff X is created by the action acmeStuffManufacturing wasGeneratedBy(stuffX, acmeStuffManufacturing, timestamp) // Acme hands off the drugs to Armadillo for ground transportation actedOnBehalfOf(Armadillo, Acme, [prov:type=\"ground transportation\" ]) // Armadillo transport the stuff used(armadilloGroundTransport, stuffX) // Armadillo hands off the drugs to Pigeon for air transportation actedOnBehalfOf(Pigeon, Armadillo, [prov:type=\"air transportation\" ]) // Pigeon transport the stuff used(pigeonGroundTransport, stuffX) // Pigeon delivers the stuff to John actedOnBehalfOf(John, Pigeon, [prov:type=\"delivery\" ]) Metadata Registry \u00b6 Agents Registry \u00b6 All the different actors (Agents in PROV terminology) have associated a digital identity allowing their identification and further authorization and authentication in the network. In Nevermined all the different entities can be registered as a DID. In our example: Acme Corp - did:nv:acme Armadillo Shipping - did:nv:armadillo Pigeon Carriers - did:nv:pigeon John Doe - did:nv:john The different agents DIDs can be resolved to DDOs including the user metadata: { \"@context\" : \"https://www.w3.org/ns/did/v1\" , \"id\" : \"did:nv:acme\" , \"proof\" : { \"created\" : \"2019-02-08T08:13:41Z\" , \"creator\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"signatureValue\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"type\" : \"DDOIntegritySignature\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" } }, \"verifiableCredential\" : [{ \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://www.w3.org/2018/credentials/examples/v1\" ], \"id\" : \"1872\" , \"type\" : [ \"read\" , \"update\" , \"deactivate\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : { \"id\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" }, \"proof\" : { \"type\" : \"RsaSignature2018\" , \"created\" : \"2019-01-01T19:73:24Z\" , \"proofPurpose\" : \"assertionMethod\" , \"signatureValue\" : \"ABCJSDAO23...1tzjn4w==\" } }], \"service\" : [{ \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/agents/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"name\" : \"Acme Corp\" , \"subjectAddress\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"datePublished\" : \"2019-02-08T08:13:49Z\" } } }] } The registration of an identity in the network requires the following steps: Generates the agent DDO Generates the DID using the DDO main metadata Register the DDO off-chain in any kind of metadata service using the Nevermined Metadata interface Register the DID on-chain calling the Smart Contract DIDRegistry associating the DID with the url where the DDO is resolved Using this method, different and totally independent actors of the supply chain scenario can register their digital identity in the network and be discovered/resolvable via the DID on-chain and the agent metadata. Entities Registry \u00b6 In the same way that agents are registered in Nevermined, all the different assets (Entities in PROV terminology) are registered as part of the network and have associated a DID and some metadata in DDO format. This inherits all the benefits of using Decentralized Identifiers, including the integrity validation of metadata associated with an entity. In the Nevermined Metadata specification , a DDO includes some services that are included in the entity/asset registered in the network. Typically this list of services can include: Metadata - Information describing the entity. Depending on the type of entity this could be information of a dataset, a physical object, etc. Some attributes here could be description of the entity, owner, date of creation, author, etc. Digital Access - For digital entities allowing sharing between agents of the network. This service includes the conditions allowing this transaction to happen. Computation - For digital entities with privacy constraints where the agent owner of the digital asset allows to execute a computation where the digital entity is. This could be a Federated Learning job or a classical data pipeline. Provenance. It allows to register the activities and metadata related with an entity. The provenance information is associated with the DDO and is part of the integrity signature of the asset. This provenance metadata is complemented with the on-chain provenance registry. Provenance metadata integrity \u00b6 To guarantee the integrity of the provenance information, the complete provenance JSON object inside of the Provenance service is serialized and hashed using keccak256 . This generated checksum will be stored as part of the Provenance service in the checksum attribute. Additionally, this checksum can be registered on-chain to prevent the tampering of provenance information. Also this checksum can be used as part of the DID computation. How to compute the provenance checksum \u00b6 To generate the checksum in a way that can be computed and verified multiple times, the JSON object must be serialized using the following rules: All the \\n, \\t, \\r characters must be removed All the whitespaces out of the Json entities names or values must be removed The Json document and all the nested objects must be sort alphabetically This must generate a compact JSON object of only one line that can be hashed and the verification of the hash can be re-calculated. Links \u00b6 W3C PROV-O - The Provenance Ontology: https://www.w3.org/TR/2013/NOTE-prov-xml-20130430/ W3C PROV-DM - The Provenance Data Model: https://www.w3.org/TR/2013/REC-prov-dm-20130430/ W3C PROV-XML: https://www.w3.org/TR/2013/NOTE-prov-xml-20130430/ W3C PROV-JSON Serialization: https://www.w3.org/Submission/prov-json/ Resource: Open Provenance Model (OPM) \u00b6 The Open Provenance Model ( OPM ) defines a data model that is open from an inter-operability viewpoint but also with respect to the community of its contributors, reviewers and users. Open Provenance Model It has several tools & libraries: ProvToolbox - a Java toolbox for handling PROV Tutorial Prov Python - a Python implementation of the PROV data model tutorial ipynb notebook example document ProvJS - a JavaScript implementation of the PROV data model ProvStore - Provenance storage and distribution ProvExtract - for dealing with PROV embedded in web pages ProvVis - experimental visualizations of PROV PROV-N Editor - a text editor with PROV-N syntax highlighted","title":"Provenance"},{"location":"architecture/specs/provenance/#prov-spec-decentralized-data-provenance","text":"shortname: PROV name: Decentralized Data Provenance type: Standard status: Valid version: 0.2 editor: Aitor Argomaniz <aitor@nevermined.io> contributors: PROV SPEC: Decentralized Data Provenance Motivation Concepts Specifications Provenance Model Provenance Types Entities Agents Activities Provenance Relations Generation: Register a new entity generated by an agent (wasGeneratedBy) Derivation: register relationship between source and derived entities (wasDerivedFrom) Association (wasAssociatedWith) Delegation (actedOnBehalfOf) Usage (used) Activity: Register activities Examples Scenario Actors Flow Architecture Data Process Good Manufacturing Handover to Carrier Handover to the end recipient Registry Provenance Registry Metadata Registry Agents Registry Entities Registry Provenance metadata integrity How to compute the provenance checksum Links This SPEC introduces the concept of asset Data Provenance in Nevermined platform based on the W3C Provenance specification.","title":"PROV SPEC: Decentralized Data Provenance"},{"location":"architecture/specs/provenance/#motivation","text":"The intention of this document is to discuss how data provenance can be established in a decentralized system, permitting integrity validation of this provenance information. The main objectives of this SPEC are: Understand what provenance information needs to be tracked Specify how the provenance integrity check is stored on-chain Identify the actors involved in the publishing and visualization of provenance information Detail how to register relationships between source and derived entities Detail how to register activities Understand how to associate activities with the input and output entities in a workflow Validate cryptographically that an entity was generated from a specific input entity in a specific activity","title":"Motivation"},{"location":"architecture/specs/provenance/#concepts","text":"","title":"Concepts"},{"location":"architecture/specs/provenance/#specifications","text":"Nevermined Data Provenance solution is designed based on the W3C Provenance specifications . In addition to this, Nevermined uses Decentralized Identifiers following the W3C DID specification . The design of Nevermined using both specifications is critical because it enables the construction of a complete and decentralized provenance solution where independent parties can collaborate in the common problem of delivering goods without relying on a central party, and providing transparency, complete traceability, efficiency and a unique source of truth.","title":"Specifications"},{"location":"architecture/specs/provenance/#provenance-model","text":"The W3C PROV specification defines Provenance as: Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness. The W3C PROV data model includes a core set of types and relations commonly found in provenance tracking for more specific uses. In particular, the data model includes both Type and Relation categories. Type category contains entity , activity and agent which are core components. Relations category defines key relationships between different types of components, which can be mapped into specific PROV model relations. PROV Mapping","title":"Provenance Model"},{"location":"architecture/specs/provenance/#provenance-types","text":"Provenance information can be modeled as the interaction between Agents and Entities related via the Activities between them:","title":"Provenance Types"},{"location":"architecture/specs/provenance/#entities","text":"In PROV, physical, digital, conceptual, or other kinds of things are called entities. Examples of such entities are assets, a web page, a chart, a spellchecker, etc.","title":"Entities"},{"location":"architecture/specs/provenance/#agents","text":"An agent takes a role in an activity such that the agent can be assigned some degree of responsibility for the activity taking place. An agent can be a person, a piece of software, an inanimate object, an organization, or other entities that may be ascribed responsibility.","title":"Agents"},{"location":"architecture/specs/provenance/#activities","text":"Activities are how entities come into existence and how their attributes change to become new entities, often making use of previously existing entities to achieve this. They are dynamic aspects of the world, such as actions, processes, etc. For example, if the second version of document D was generated by a translation from the first version of the document in another language, then this translation is an activity. PROV E-R","title":"Activities"},{"location":"architecture/specs/provenance/#provenance-relations","text":"Relations between agents and entities are open but there are some common relations that can be used as reference:","title":"Provenance Relations"},{"location":"architecture/specs/provenance/#generation-register-a-new-entity-generated-by-an-agent-wasgeneratedby","text":"Generation is the completion of production of a new entity by an activity. This entity did not exist before generation and becomes available for usage after this generation. Generation , written wasGeneratedBy(id; e, a, t, attrs) in PROV-N (a notation for provenance aimed at human consumption), has: id : an optional identifier for a generation; entity : an identifier (e) for a created entity. In Nevermined a DID ; activity : an optional identifier (a) for the activity that creates the entity. In Nevermined a DID ; time : an optional \"generation time\" (t), the time at which the entity was completely created; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this generation. While each of id , activity , time , and attributes are optional, at least one of them must be present. PROV uses qualified names to identify things for data provenance, which is essentially a shortened representation of a URI in the form of prefix:localpart . Example: wasGeneratedBy(did:nv:e1, did:nv:a1, 2019-10-26T21:32:52) wasGeneratedBy(did:nv:e2, did:nv:a1, 2019-10-26T10:00:00) The above example shows the existence of two generations (with respective times 2019-10-26T21:32:52 and 2001-10-26T10:00:00), at which new entities, identified by did:nv:e1 and did:nv:e2 , were created by an activity, identified by did:nv:a1 .","title":"Generation: Register a new entity generated by an agent (wasGeneratedBy)"},{"location":"architecture/specs/provenance/#derivation-register-relationship-between-source-and-derived-entities-wasderivedfrom","text":"Derivation is a transformation of an entity into another, an update of an entity resulting in a new one, or the construction of a new entity based on a pre-existing entity. A derivation , written wasDerivedFrom(id; e2, e1, a, g2, u1, attrs) in PROV-N, has: id : an optional identifier for a derivation; generatedEntity : the identifier (e2) of the derived entity generated by the derivation. In Nevermined a DID ; usedEntity : the identifier (e1) of the source entity used by the derivation. In Nevermined a DID ; activity : an optional identifier (a) for the activity using and generating the above entities. In Nevermined a DID ; generation : an optional identifier (g2) for the generation involving the generated entity (e2) and activity (a). In Nevermined a DID ; usage : an optional identifier (u1) for the usage involving the used entity (e1) and activity (a). In Nevermined a DID ; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this derivation. The following descriptions are about derivations between did:nv:e1 and did:nv:e2 , but no information is provided as to the identity of the activity (and usage and generation) underpinning the derivation. In the second line, a type attribute is also provided. wasDerivedFrom(did:nv:e2, did:nv:e1) wasDerivedFrom(did:nv:e2, did:nv:e1, [ prov:type=\"physical transform\" ]) The following description expresses that activity did:nv:a , using the entity did:nv:e1 according to usage did:nv:01 , derived the entity did:nv:e2 and generated it according to generation did:nv:02 . It is followed by descriptions for generation did:nv:02 and usage did:nv:01 . wasDerivedFrom(did:nv:e2, did:nv:e1, did:nv:a, did:nv:02, did:nv:01) wasGeneratedBy(did:nv:02; did:nv:e2, did:nv:a, -) used(did:nv:01; did:nv:a, did:nv:e1, -) With such a comprehensive description of derivation, a program that analyzes provenance can identify the activity underpinning the derivation, it can identify how the preceding entity did:nv:e1 was used by the activity (e.g. for instance, which argument it was passed, if the activity is the result of a function invocation), and which output the derived entity did:nv:e2 was obtained from (say, for a function returning multiple results).","title":"Derivation: register relationship between source and derived entities (wasDerivedFrom)"},{"location":"architecture/specs/provenance/#association-wasassociatedwith","text":"Association is an assignment of responsibility to an agent for an activity, indicating that the agent had a role in the activity. An association, written wasAssociatedWith(id; a, ag, pl, attrs) in PROV-N, has: id : an optional identifier for the association between an activity and an agent; activity : an identifier (a) for the activity; agent : an optional identifier (ag) for the agent associated with the activity; plan : an optional identifier (pl) for the plan the agent relied on in the context of this activity; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this association of this activity with this agent. The following examples are about the association between one activity did:nv:ac1 and one agent did:nv:a00 . In the second example, a type attribute is also provided. wasAssociatedWith(did:nv:ac1, did:nv:a00) wasAssociatedWith(did:nv:ac1, did:nv:a00, [ prov:type=\"manufacturing\" ])","title":"Association (wasAssociatedWith)"},{"location":"architecture/specs/provenance/#delegation-actedonbehalfof","text":"Delegation is the assignment of authority and responsibility to an agent (by itself or by another agent) to carry out a specific activity as a delegate or representative, while the agent it acts on behalf of retains some responsibility for the outcome of the delegated work. A delegation link, written actedOnBehalfOf(id; ag2, ag1, a, attrs) in PROV-N, has: id : an optional identifier for the delegation link between delegate and responsible; delegate : an identifier (ag2) for the agent associated with an activity, acting on behalf of the responsible agent; responsible : an identifier (ag1) for the agent, on behalf of which the delegate agent acted; activity : an optional identifier (a) of an activity for which the delegation link holds; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this delegation link. In the following example we can see how the agent delegated did:nv:a1 acts on behalf of the did:nv:a2 responsible. actedOnBehalfOf(did:nv:a1, did:nv:a2) actedOnBehalfOf(did:nv:a1, did:nv:a2, [ prov:type=\"ground transportation\" ])","title":"Delegation (actedOnBehalfOf)"},{"location":"architecture/specs/provenance/#usage-used","text":"Usage is the beginning of utilizing an entity by an activity. Before usage, the activity had not begun to utilize this entity and could not have been affected by the entity. (Note: This definition is formulated for a given usage; it is permitted for an activity to use the same entity multiple times.) Given that a usage is the beginning of utilizing an entity, it is instantaneous. Usage, written used(id; a, e, t, attrs) in PROV-N, has: id : an optional identifier for a usage; activity : an identifier (a) for the activity that used an entity; entity : an optional identifier (e) for the entity being used; time : an optional \"usage time\" (t), the time at which the entity started to be used; attributes : an optional set (attrs) of attribute-value pairs representing additional information about this usage. In the following example we can see how to associate the activity did:nv:ac1 with the usage of the entity did:nv:e1 in some specific moment. usage(did:nv:ac1, did:nv:e1, now()) usage(did:nv:ac1, did:nv:e1, now(), [ prov:type=\"shipping\" ])","title":"Usage (used)"},{"location":"architecture/specs/provenance/#activity-register-activities","text":"An activity is something that occurs over a period of time and acts upon or with entities; it may include consuming, processing, transforming, modifying, relocating, using, or generating entities. An activity , written activity(id, st, et, [attr1=val1, ...]) in PROV-N, has: id : an identifier for an activity; startTime : an optional time (st) for the start of the activity; endTime : an optional time (et) for the end of the activity; attributes : an optional set of attribute-value pairs ((attr1, val1), ...) representing additional information about this activity. Example: activity(a1, 2011-11-16T16:05:00, 2011-11-16T16:06:00, [ ex:host=\"server.example.org\", prov:type='ex:edit' ]) The above example shows the existence of an activity with identifier a1 , start time 2011-11-16T16:05:00 , and end time 2011-11-16T16:06:00 , running on host server.example.org , and of type edit .","title":"Activity: Register activities"},{"location":"architecture/specs/provenance/#examples","text":"Taking into account the relations examples, the scenario where a new asset (entity) is created (generation), modified (derivation) and used by a third-party entity can be translated into this: // Entity X is associated with the activity of goodCreation wasAssociatedWith(goodCreation, entityX) // Entity Y is associated with the activity of goodModification wasAssociatedWith(goodModification, entityY) // Entity Z is associated with the activity of goodShipping wasAssociatedWith(goodShipping, entityZ) // A newAsset was created yesterday via goodCreation activity (Entity X) wasGeneratedBy(newAsset goodCreation, yesterday()) // The newDerivedAsset was created today from the newAsset via goodModification activity (Entity Y) wasDerivedFrom(newDerivedAsset, newAsset, goodModification, today()) // The newDerivedAsset is shipped by Entity Z used(goodShipping, newDerivedAsset, now())","title":"Examples"},{"location":"architecture/specs/provenance/#scenario","text":"For describing the architecture we are gonna use as a reference a supply chain use case. In this scenario a company manufacturing some goods needs to deliver them to the final customer. To do that the goods need to be transported by different shipping companies until the goods are handed over to the final recipient.","title":"Scenario"},{"location":"architecture/specs/provenance/#actors","text":"As an example to illustrate the architecture we are gonna describe the scenario with the following 4 different actors: Acme Co . International medical company manufacturing different kind of drugs in the their manufacturing center Armadillo Shipping . Courier doing ground and sea transportation of goods. Pigeon Carriers . Company doing air transportation of goods. John Doe . The end recipient of the goods","title":"Actors"},{"location":"architecture/specs/provenance/#flow","text":"The end to end scenario includes the following steps: Acme Co. manufactures the drug at their manufacturing center Acme Co. hands off the product for transfer from Acme to ground transport (Armadillo Shipping) to begin the journey Armadillo transports the product from the manufacturer to the air freight provider for overseas shipping This may or may not go through a distribution center Armadillo hands off the freight to the air freight provider ( Pigeon Carriers) The air freight provider will take over the shipping and move the freight to their distribution center at the airport to wait for the cargo to be loaded. The cargo is loaded into the plane and transferred to the destination The air freight provider will hand off the cargo to the end recipient (John Doe) Provenance Example Use Case","title":"Flow"},{"location":"architecture/specs/provenance/#architecture","text":"","title":"Architecture"},{"location":"architecture/specs/provenance/#data","text":"Across the complete supply chain scenario described above different parts of data are generated since the good is manufactured until it is delivered to the end recipient. Here some details about that: When the good is created, the manufacturer generates some additional information about the physical asset. This could include documents with asset specifications, details of manufacturing, certificates of quality, etc. When the good is handed over to the shipping company there are also other pieces of data generated. For example the receipt signed between the agent handing over the goods and the courier. During the transportation process, some additional data could be generated including temperature, humidity, coordinates, etc. When the good is delivered to the end user, both parties sign a delivery receipt. This data is also relevant and necessary for further control. Taking into account the above details we can distinguish different kind of data generated: Files. Including goods specs, receipts, etc. Each agent in the scenario needs to keep track of files or get access to the files created by others. Metadata. Describing the goods or the activities related with the goods during the delivery life-cycle. Nevermined provides a decentralized ecosystem where all this data can be registered and shared between all the agents participating during the supply chain process. It enables the registering of the files generated by the supply chain flow, making them available between the agents independently on the underlying technology. Also enable the registering of the metadata associated with the complete flow allowing to provide a complete lineage of the whole process. All this information is recorded in a decentralized backbone that works as a source of truth for all the parties. Nevermined doesn\u2019t require to replace the existing supply chain software platforms each agent in the system has. It integrates to them and augments their existing capabilities allowing to make available the relevant data generated to the agents participating during the supply process.","title":"Data"},{"location":"architecture/specs/provenance/#process","text":"Taking into account the Scenario described before, the end to end flow can be detailed in the following steps:","title":"Process"},{"location":"architecture/specs/provenance/#good-manufacturing","text":"Acme Corp. (Manufacturer) has created some goods that need to be delivered to John Doe (End Recipient). Acme uses the supply chain management Oracle SCM platform. When the good is created some relevant data (files, certificates, etc.) is created in the SCM platform. As a complement to that, the good created is registered into Nevermined (via SDK integration). This allows to: Identify unequivocally the good created within the supply chain network. This associates a unique Decentralized Identifier (DID) to the good and identifies Acme Corp. as the unique manufacturer of the good, providing the genesis of the goods lineage. Register some metadata related with the good created, including date of manufacturing, description, conditions, etc. This metadata is hashed and becomes part of the DID created, avoiding further modifications (like date of manufacturing tamper) without breaking the integrity check of the DID. Register the data files as part of the metadata. Typically these files will be stored as part of Acme Corp. SCM system. Nevermined provides a gateway that can integrate different backends. These files registered, equally to the metadata are part of the Nevermined integrity check.","title":"Good Manufacturing"},{"location":"architecture/specs/provenance/#handover-to-carrier","text":"Acme Corp. needs to send the goods manufactured to John Doe. This delivery process needs to involve 2 independent transport companies, Armadillo Shipping that is doing local ground transportation and Pigeon Carriers that is doing air transportation. Pigeon Carriers will deliver the goods to the end recipient. During this process the following things happen: * Acme Corp. hands over the goods to Armadillo Shipping. During this process there is a digital signature process where Acme Corp. gets the signature from Armadillo of this hand over process. Acme Corp. registers this in the Nevermined Provenance Registry. * Armadillo Shipping transports the goods to the airport to hand over to Pigeon Carriers. During the transportation process some data is created including the temperature of the cargo and the coordinates of the complete trip from the Acme factory to the airport. The files with the data generated are uploaded automatically to the Armadillo SCM system. In addition to this the files are registered into Nevermined with a new DID. When Armadillo hands over the goods to Pigeon Carriers, the digital signature accepting the handover is registered in the Provenance Registry. The handover between carriers could include multiple steps and companies. Also intermediate storage in delivery centers, goods validation or certification, etc. For sake of simplicity here we only describe a simplistic end to end flow, but in essence a complete scenario involving additional steps could be very similar.","title":"Handover to Carrier"},{"location":"architecture/specs/provenance/#handover-to-the-end-recipient","text":"Pigeon Carriers needs to deliver the goods to John Doe (End Recipient). During this process and very similarly to the above described the following things happens: * John Doe sings digitally the delivery receipt. Pigeon Carriers. registers this in the Nevermined Provenance Registry. * John Doe, having the DID of the goods can track end to end the complete provenance record of the asset. Also for each intermediate step can retrieve the data assets associated with the goods and created during the delivery process. This makes it possible to track end to end the complete cargo flow involving independent agents. The provenance record is immutable and cryptographically secure, providing a transparent and unique source of truth that can be consulted by all the agents involved during and after the completion of the flow. This could allow John Doe to validate that the temperature of the goods were correct during transportation and using the GPS coordinates the cargo never went through unexpected locations. Provenance Architecture","title":"Handover to the end recipient"},{"location":"architecture/specs/provenance/#registry","text":"","title":"Registry"},{"location":"architecture/specs/provenance/#smart-contract","text":"struct DIDRegisterList { mapping(bytes32 => DIDRegister) didRegisters; bytes32[] didRegisterIds; } struct DIDRegister { address owner; bytes32 lastChecksum; string url; address lastUpdatedBy; uint256 blockNumberUpdated; address[] providers; address[] delegates; } struct ProvenanceRegistryList { mapping(bytes32 => ProvenanceRegistry) provenanceRegistry; } struct ProvenanceRegistry { bytes32 did; bytes32 relatedDid; bytes32 activityId; address agentId; address agentInvolvedId; uint8 method; address lastUpdatedBy; uint256 blockNumberUpdated; } # DIDRegister owner | lastChecksum | URL | lastUpdatedBy | blockNumber | providers | delegates -------|--------------|-----------------------|-----------------|---------------|---------------|------------------- 0x1234 | 00001 | http://nevermined.io | 2010 | 100 | [0x10] | [] 0xabab | 12213 | http://nevermined.io | 2011 | 100 | [] | [0xaa] # ProvenanceRegistry did | relatedDid | activityId | agentId | agentInvolvedId | method | lastUpdatedBy | blockNumber -------|--------------|-------------------|-------------------|--------------------|-----------|-------------------|----------------- 0x1234 | 0x5678 | 0xaabb | 0xccdd | 0xccbb | 0 | 2010 | 100 0xdddd | | 0xaabb | 0xccdd | | 1 | 2011 | 190","title":"Smart Contract"},{"location":"architecture/specs/provenance/#provenance-registry","text":"The Provenance Registry provides a unique source truth of the provenance information registered in the Nevermined network. It is a generic record where the entities (digital or physical assets) represent their complete life-cycle. When it\u2019s necessary to represent the interaction between independent agents (Acme Corp. hands over a good to Armadillo Shipping), it\u2019s necessary to provide the digital signature of the agents participating in the transaction. Using the scenario already described and the W3C PROV specification the complete flow could be described as follows: // Acme Corp. manufacture some stuff wasAssociatedWith(acmeStuffManufacturing, Acme) // Armadillo does ground transportation wasAssociatedWith(armadilloGroundTransport, Armadillo) // Pigeon does air transportation wasAssociatedWith(pigeonAirTransport, Pigeon) // Stuff X is created by the action acmeStuffManufacturing wasGeneratedBy(stuffX, acmeStuffManufacturing, timestamp) // Acme hands off the drugs to Armadillo for ground transportation actedOnBehalfOf(Armadillo, Acme, [prov:type=\"ground transportation\" ]) // Armadillo transport the stuff used(armadilloGroundTransport, stuffX) // Armadillo hands off the drugs to Pigeon for air transportation actedOnBehalfOf(Pigeon, Armadillo, [prov:type=\"air transportation\" ]) // Pigeon transport the stuff used(pigeonGroundTransport, stuffX) // Pigeon delivers the stuff to John actedOnBehalfOf(John, Pigeon, [prov:type=\"delivery\" ])","title":"Provenance Registry"},{"location":"architecture/specs/provenance/#metadata-registry","text":"","title":"Metadata Registry"},{"location":"architecture/specs/provenance/#agents-registry","text":"All the different actors (Agents in PROV terminology) have associated a digital identity allowing their identification and further authorization and authentication in the network. In Nevermined all the different entities can be registered as a DID. In our example: Acme Corp - did:nv:acme Armadillo Shipping - did:nv:armadillo Pigeon Carriers - did:nv:pigeon John Doe - did:nv:john The different agents DIDs can be resolved to DDOs including the user metadata: { \"@context\" : \"https://www.w3.org/ns/did/v1\" , \"id\" : \"did:nv:acme\" , \"proof\" : { \"created\" : \"2019-02-08T08:13:41Z\" , \"creator\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"signatureValue\" : \"did:nv:0bc278fee025464f8012b811d1bce8e22094d0984e4e49139df5d5ff7a028bdf\" , \"type\" : \"DDOIntegritySignature\" , \"checksum\" : { \"0\" : \"0x52b5c93b82dd9e7ecc3d9fdf4755f7f69a54484941897dc517b4adfe3bbc3377\" } }, \"verifiableCredential\" : [{ \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://www.w3.org/2018/credentials/examples/v1\" ], \"id\" : \"1872\" , \"type\" : [ \"read\" , \"update\" , \"deactivate\" ], \"issuer\" : \"0x610D9314EDF2ced7681BA1633C33fdb8cF365a12\" , \"issuanceDate\" : \"2019-01-01T19:73:24Z\" , \"credentialSubject\" : { \"id\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" }, \"proof\" : { \"type\" : \"RsaSignature2018\" , \"created\" : \"2019-01-01T19:73:24Z\" , \"proofPurpose\" : \"assertionMethod\" , \"signatureValue\" : \"ABCJSDAO23...1tzjn4w==\" } }], \"service\" : [{ \"index\" : 0 , \"serviceEndpoint\" : \"http://localhost:5000/api/v1/metadata/agents/ddo/{did}\" , \"type\" : \"metadata\" , \"attributes\" : { \"main\" : { \"name\" : \"Acme Corp\" , \"subjectAddress\" : \"0x37BB53e3d293494DE59fBe1FF78500423dcFd43B\" , \"dateCreated\" : \"2019-02-08T08:13:49Z\" , \"datePublished\" : \"2019-02-08T08:13:49Z\" } } }] } The registration of an identity in the network requires the following steps: Generates the agent DDO Generates the DID using the DDO main metadata Register the DDO off-chain in any kind of metadata service using the Nevermined Metadata interface Register the DID on-chain calling the Smart Contract DIDRegistry associating the DID with the url where the DDO is resolved Using this method, different and totally independent actors of the supply chain scenario can register their digital identity in the network and be discovered/resolvable via the DID on-chain and the agent metadata.","title":"Agents Registry"},{"location":"architecture/specs/provenance/#entities-registry","text":"In the same way that agents are registered in Nevermined, all the different assets (Entities in PROV terminology) are registered as part of the network and have associated a DID and some metadata in DDO format. This inherits all the benefits of using Decentralized Identifiers, including the integrity validation of metadata associated with an entity. In the Nevermined Metadata specification , a DDO includes some services that are included in the entity/asset registered in the network. Typically this list of services can include: Metadata - Information describing the entity. Depending on the type of entity this could be information of a dataset, a physical object, etc. Some attributes here could be description of the entity, owner, date of creation, author, etc. Digital Access - For digital entities allowing sharing between agents of the network. This service includes the conditions allowing this transaction to happen. Computation - For digital entities with privacy constraints where the agent owner of the digital asset allows to execute a computation where the digital entity is. This could be a Federated Learning job or a classical data pipeline. Provenance. It allows to register the activities and metadata related with an entity. The provenance information is associated with the DDO and is part of the integrity signature of the asset. This provenance metadata is complemented with the on-chain provenance registry.","title":"Entities Registry"},{"location":"architecture/specs/provenance/#provenance-metadata-integrity","text":"To guarantee the integrity of the provenance information, the complete provenance JSON object inside of the Provenance service is serialized and hashed using keccak256 . This generated checksum will be stored as part of the Provenance service in the checksum attribute. Additionally, this checksum can be registered on-chain to prevent the tampering of provenance information. Also this checksum can be used as part of the DID computation.","title":"Provenance metadata integrity"},{"location":"architecture/specs/provenance/#how-to-compute-the-provenance-checksum","text":"To generate the checksum in a way that can be computed and verified multiple times, the JSON object must be serialized using the following rules: All the \\n, \\t, \\r characters must be removed All the whitespaces out of the Json entities names or values must be removed The Json document and all the nested objects must be sort alphabetically This must generate a compact JSON object of only one line that can be hashed and the verification of the hash can be re-calculated.","title":"How to compute the provenance checksum"},{"location":"architecture/specs/provenance/#links","text":"W3C PROV-O - The Provenance Ontology: https://www.w3.org/TR/2013/NOTE-prov-xml-20130430/ W3C PROV-DM - The Provenance Data Model: https://www.w3.org/TR/2013/REC-prov-dm-20130430/ W3C PROV-XML: https://www.w3.org/TR/2013/NOTE-prov-xml-20130430/ W3C PROV-JSON Serialization: https://www.w3.org/Submission/prov-json/","title":"Links"},{"location":"architecture/specs/provenance/#resource-open-provenance-model-opm","text":"The Open Provenance Model ( OPM ) defines a data model that is open from an inter-operability viewpoint but also with respect to the community of its contributors, reviewers and users. Open Provenance Model It has several tools & libraries: ProvToolbox - a Java toolbox for handling PROV Tutorial Prov Python - a Python implementation of the PROV data model tutorial ipynb notebook example document ProvJS - a JavaScript implementation of the PROV data model ProvStore - Provenance storage and distribution ProvExtract - for dealing with PROV embedded in web pages ProvVis - experimental visualizations of PROV PROV-N Editor - a text editor with PROV-N syntax highlighted","title":"Resource: Open Provenance Model (OPM)"}]}